
==> Audit <==
|------------|---------------------------------|----------|------------|---------|---------------------|---------------------|
|  Command   |              Args               | Profile  |    User    | Version |     Start Time      |      End Time       |
|------------|---------------------------------|----------|------------|---------|---------------------|---------------------|
| start      | --driver=virtualbox             | minikube | mindbowser | v1.33.1 | 29 Jul 24 19:24 IST | 29 Jul 24 19:29 IST |
| dashboard  |                                 | minikube | mindbowser | v1.33.1 | 29 Jul 24 19:33 IST |                     |
| service    | hello-minikube --url            | minikube | mindbowser | v1.33.1 | 29 Jul 24 19:52 IST |                     |
| service    | hello-minikube --url            | minikube | mindbowser | v1.33.1 | 29 Jul 24 19:53 IST |                     |
| start      |                                 | minikube | mindbowser | v1.33.1 | 30 Jul 24 10:22 IST | 30 Jul 24 10:24 IST |
| config     | set                             | minikube | mindbowser | v1.33.1 | 30 Jul 24 10:30 IST | 30 Jul 24 10:30 IST |
|            | WantVirtualBoxDriverWarning     |          |            |         |                     |                     |
|            | false                           |          |            |         |                     |                     |
| start      |                                 | minikube | mindbowser | v1.33.1 | 30 Jul 24 10:30 IST | 30 Jul 24 10:32 IST |
| stop       |                                 | minikube | mindbowser | v1.33.1 | 30 Jul 24 10:39 IST | 30 Jul 24 10:39 IST |
| start      |                                 | minikube | mindbowser | v1.33.1 | 30 Jul 24 11:43 IST | 30 Jul 24 11:45 IST |
| service    | hello-minikube                  | minikube | mindbowser | v1.33.1 | 30 Jul 24 11:47 IST |                     |
| addons     | list                            | minikube | mindbowser | v1.33.1 | 30 Jul 24 14:45 IST | 30 Jul 24 14:45 IST |
| service    | hello-minikube                  | minikube | mindbowser | v1.33.1 | 30 Jul 24 14:46 IST |                     |
| service    | hello-minikube --url            | minikube | mindbowser | v1.33.1 | 30 Jul 24 14:49 IST |                     |
| service    | hello-minikube --url            | minikube | mindbowser | v1.33.1 | 30 Jul 24 14:52 IST |                     |
| kubectl    | -- get po -A                    | minikube | mindbowser | v1.33.1 | 30 Jul 24 14:56 IST | 30 Jul 24 14:57 IST |
| kubectl    | -- create deployment            | minikube | mindbowser | v1.33.1 | 30 Jul 24 14:58 IST | 30 Jul 24 14:58 IST |
|            | hello-minikube                  |          |            |         |                     |                     |
|            | --image=kicbase/echo-server:1.0 |          |            |         |                     |                     |
| kubectl    | -- expose deployment            | minikube | mindbowser | v1.33.1 | 30 Jul 24 14:58 IST | 30 Jul 24 14:58 IST |
|            | hello-minikube --type=NodePort  |          |            |         |                     |                     |
|            | --port=8080                     |          |            |         |                     |                     |
| kubectl    | -- get services hello-minikube  | minikube | mindbowser | v1.33.1 | 30 Jul 24 14:58 IST | 30 Jul 24 14:58 IST |
| service    | hello-minikube                  | minikube | mindbowser | v1.33.1 | 30 Jul 24 14:58 IST | 30 Jul 24 14:58 IST |
| kubectl    | -- port-forward                 | minikube | mindbowser | v1.33.1 | 30 Jul 24 14:59 IST |                     |
|            | service/hello-minikube          |          |            |         |                     |                     |
|            | 7080:8080                       |          |            |         |                     |                     |
| kubectl    | -- get services                 | minikube | mindbowser | v1.33.1 | 30 Jul 24 15:01 IST | 30 Jul 24 15:01 IST |
| stop       |                                 | minikube | mindbowser | v1.33.1 | 30 Jul 24 16:54 IST | 30 Jul 24 16:54 IST |
| start      |                                 | minikube | mindbowser | v1.33.1 | 04 Aug 24 12:02 IST |                     |
| stop       |                                 | minikube | mindbowser | v1.33.1 | 04 Aug 24 12:03 IST | 04 Aug 24 12:03 IST |
| delete     |                                 | minikube | mindbowser | v1.33.1 | 04 Aug 24 12:11 IST | 04 Aug 24 12:11 IST |
| start      | --driver=virtualbox             | minikube | mindbowser | v1.33.1 | 04 Aug 24 12:13 IST | 04 Aug 24 12:16 IST |
| ssh        |                                 | minikube | mindbowser | v1.33.1 | 04 Aug 24 13:48 IST | 04 Aug 24 13:49 IST |
| start      |                                 | minikube | mindbowser | v1.33.1 | 12 Sep 24 09:17 IST |                     |
| stop       |                                 | minikube | mindbowser | v1.33.1 | 12 Sep 24 09:18 IST |                     |
| stop       |                                 | minikube | mindbowser | v1.34.0 | 12 Sep 24 10:15 IST | 12 Sep 24 10:15 IST |
| start      |                                 | minikube | mindbowser | v1.34.0 | 13 Sep 24 10:26 IST |                     |
| stop       |                                 | minikube | mindbowser | v1.34.0 | 13 Sep 24 10:27 IST | 13 Sep 24 10:27 IST |
| start      |                                 | minikube | mindbowser | v1.34.0 | 13 Sep 24 10:27 IST |                     |
| stop       |                                 | minikube | mindbowser | v1.34.0 | 13 Sep 24 10:28 IST | 13 Sep 24 10:28 IST |
| start      |                                 | minikube | mindbowser | v1.34.0 | 13 Sep 24 10:30 IST |                     |
| start      |                                 | minikube | mindbowser | v1.34.0 | 13 Sep 24 10:36 IST |                     |
| start      |                                 | minikube | mindbowser | v1.34.0 | 13 Sep 24 10:38 IST |                     |
| start      |                                 | minikube | mindbowser | v1.34.0 | 13 Sep 24 10:45 IST |                     |
| stop       |                                 | minikube | mindbowser | v1.34.0 | 13 Sep 24 10:45 IST |                     |
| delete     |                                 | minikube | mindbowser | v1.34.0 | 13 Sep 24 10:46 IST | 13 Sep 24 10:46 IST |
| start      |                                 | minikube | mindbowser | v1.34.0 | 17 Sep 24 10:27 IST | 17 Sep 24 10:32 IST |
| dashboard  |                                 | minikube | mindbowser | v1.34.0 | 17 Sep 24 10:40 IST |                     |
| addons     | enable metrics-server           | minikube | mindbowser | v1.34.0 | 17 Sep 24 10:42 IST | 17 Sep 24 10:42 IST |
| service    | my-nginx                        | minikube | mindbowser | v1.34.0 | 17 Sep 24 10:47 IST | 17 Sep 24 10:47 IST |
| stop       |                                 | minikube | mindbowser | v1.34.0 | 17 Sep 24 10:50 IST | 17 Sep 24 10:51 IST |
| docker-env |                                 | minikube | mindbowser | v1.34.0 | 22 Sep 24 15:59 IST |                     |
| start      |                                 | minikube | mindbowser | v1.34.0 | 23 Sep 24 16:08 IST | 23 Sep 24 16:08 IST |
| help       |                                 | minikube | mindbowser | v1.34.0 | 23 Sep 24 16:12 IST | 23 Sep 24 16:12 IST |
| start      |                                 | minikube | mindbowser | v1.34.0 | 23 Sep 24 23:26 IST | 23 Sep 24 23:26 IST |
| stop       |                                 | minikube | mindbowser | v1.34.0 | 23 Sep 24 23:27 IST | 23 Sep 24 23:27 IST |
| start      |                                 | minikube | mindbowser | v1.34.0 | 23 Sep 24 23:34 IST |                     |
| start      |                                 | minikube | mindbowser | v1.34.0 | 24 Sep 24 08:55 IST |                     |
| start      |                                 | minikube | mindbowser | v1.34.0 | 24 Sep 24 08:56 IST |                     |
| addons     | enable dashboard                | minikube | mindbowser | v1.34.0 | 24 Sep 24 09:01 IST |                     |
|------------|---------------------------------|----------|------------|---------|---------------------|---------------------|


==> Last Start <==
Log file created at: 2024/09/24 08:56:31
Running on machine: w1
Binary: Built with gc go1.22.5 for linux/amd64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0924 08:56:31.680015   21492 out.go:345] Setting OutFile to fd 1 ...
I0924 08:56:31.680294   21492 out.go:397] isatty.IsTerminal(1) = true
I0924 08:56:31.680305   21492 out.go:358] Setting ErrFile to fd 2...
I0924 08:56:31.680318   21492 out.go:397] isatty.IsTerminal(2) = true
I0924 08:56:31.680755   21492 root.go:338] Updating PATH: /home/mindbowser/.minikube/bin
I0924 08:56:31.681945   21492 out.go:352] Setting JSON to false
I0924 08:56:31.685503   21492 start.go:129] hostinfo: {"hostname":"w1","uptime":509,"bootTime":1727147882,"procs":348,"os":"linux","platform":"ubuntu","platformFamily":"debian","platformVersion":"22.04","kernelVersion":"6.8.0-40-generic","kernelArch":"x86_64","virtualizationSystem":"kvm","virtualizationRole":"host","hostId":"55cb378c-9f3d-43e5-a6e7-004e4fbaeaf7"}
I0924 08:56:31.685677   21492 start.go:139] virtualization: kvm host
I0924 08:56:31.687518   21492 out.go:177] üòÑ  minikube v1.34.0 on Ubuntu 22.04
I0924 08:56:31.689301   21492 notify.go:220] Checking for updates...
I0924 08:56:31.691101   21492 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.31.0
I0924 08:56:31.691470   21492 driver.go:394] Setting default libvirt URI to qemu:///system
I0924 08:56:31.855458   21492 docker.go:123] docker version: linux-24.0.5:
I0924 08:56:31.855686   21492 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0924 08:56:32.223949   21492 info.go:266] docker info: {ID:da0245d4-3187-4122-a36f-3ec48dca51d6 Containers:1 ContainersRunning:1 ContainersPaused:0 ContainersStopped:0 Images:1 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:false CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:23 OomKillDisable:false NGoroutines:40 SystemTime:2024-09-24 08:56:32.176681324 +0530 IST LoggingDriver:json-file CgroupDriver:systemd NEventsListener:0 KernelVersion:6.8.0-40-generic OperatingSystem:Ubuntu Core 22 OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:8 MemTotal:16537112576 GenericResources:<nil> DockerRootDir:/var/snap/docker/common/var-lib-docker HTTPProxy: HTTPSProxy: NoProxy: Name:w1 Labels:[] ExperimentalBuild:false ServerVersion:24.0.5 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:3dce8eb055cbb6872793272b4f20ed16117344f8 Expected:3dce8eb055cbb6872793272b4f20ed16117344f8} RuncCommit:{ID: Expected:} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=apparmor name=seccomp,profile=builtin name=cgroupns] ProductLicense: Warnings:<nil> ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:/usr/lib/docker/cli-plugins/docker-buildx SchemaVersion:0.1.0 ShadowedPaths:[/usr/libexec/docker/cli-plugins/docker-buildx] ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.12.0-desktop.2] map[Name:compose Path:/usr/lib/docker/cli-plugins/docker-compose SchemaVersion:0.1.0 ShadowedPaths:[/usr/libexec/docker/cli-plugins/docker-compose] ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.23.3-desktop.2] map[Name:dev Path:/usr/lib/docker/cli-plugins/docker-dev SchemaVersion:0.1.0 ShortDescription:Docker Dev Environments Vendor:Docker Inc. Version:v0.1.0] map[Name:extension Path:/usr/lib/docker/cli-plugins/docker-extension SchemaVersion:0.1.0 ShortDescription:Manages Docker extensions Vendor:Docker Inc. Version:v0.2.21] map[Name:feedback Path:/usr/lib/docker/cli-plugins/docker-feedback SchemaVersion:0.1.0 ShortDescription:Provide feedback, right in your terminal! Vendor:Docker Inc. Version:0.1] map[Name:init Path:/usr/lib/docker/cli-plugins/docker-init SchemaVersion:0.1.0 ShortDescription:Creates Docker-related starter files for your project Vendor:Docker Inc. Version:v0.1.0-beta.10] map[Name:sbom Path:/usr/lib/docker/cli-plugins/docker-sbom SchemaVersion:0.1.0 ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scan Path:/usr/lib/docker/cli-plugins/docker-scan SchemaVersion:0.1.0 ShortDescription:Docker Scan Vendor:Docker Inc. Version:v0.26.0] map[Name:scout Path:/usr/lib/docker/cli-plugins/docker-scout SchemaVersion:0.1.0 ShortDescription:Docker Scout Vendor:Docker Inc. Version:v1.2.0]] Warnings:<nil>}}
I0924 08:56:32.224537   21492 docker.go:318] overlay module found
I0924 08:56:32.226970   21492 out.go:177] ‚ú®  Using the docker driver based on existing profile
I0924 08:56:32.227963   21492 start.go:297] selected driver: docker
I0924 08:56:32.227984   21492 start.go:901] validating driver "docker" against &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 Memory:3900 CPUs:2 DiskSize:20000 Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.31.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.31.0 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[dashboard:true default-storageclass:true metrics-server:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/mindbowser:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s}
I0924 08:56:32.228347   21492 start.go:912] status for docker: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0924 08:56:32.228702   21492 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0924 08:56:32.618415   21492 info.go:266] docker info: {ID:da0245d4-3187-4122-a36f-3ec48dca51d6 Containers:1 ContainersRunning:1 ContainersPaused:0 ContainersStopped:0 Images:1 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:false CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:23 OomKillDisable:false NGoroutines:40 SystemTime:2024-09-24 08:56:32.583444664 +0530 IST LoggingDriver:json-file CgroupDriver:systemd NEventsListener:0 KernelVersion:6.8.0-40-generic OperatingSystem:Ubuntu Core 22 OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:8 MemTotal:16537112576 GenericResources:<nil> DockerRootDir:/var/snap/docker/common/var-lib-docker HTTPProxy: HTTPSProxy: NoProxy: Name:w1 Labels:[] ExperimentalBuild:false ServerVersion:24.0.5 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:3dce8eb055cbb6872793272b4f20ed16117344f8 Expected:3dce8eb055cbb6872793272b4f20ed16117344f8} RuncCommit:{ID: Expected:} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=apparmor name=seccomp,profile=builtin name=cgroupns] ProductLicense: Warnings:<nil> ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:/usr/lib/docker/cli-plugins/docker-buildx SchemaVersion:0.1.0 ShadowedPaths:[/usr/libexec/docker/cli-plugins/docker-buildx] ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.12.0-desktop.2] map[Name:compose Path:/usr/lib/docker/cli-plugins/docker-compose SchemaVersion:0.1.0 ShadowedPaths:[/usr/libexec/docker/cli-plugins/docker-compose] ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.23.3-desktop.2] map[Name:dev Path:/usr/lib/docker/cli-plugins/docker-dev SchemaVersion:0.1.0 ShortDescription:Docker Dev Environments Vendor:Docker Inc. Version:v0.1.0] map[Name:extension Path:/usr/lib/docker/cli-plugins/docker-extension SchemaVersion:0.1.0 ShortDescription:Manages Docker extensions Vendor:Docker Inc. Version:v0.2.21] map[Name:feedback Path:/usr/lib/docker/cli-plugins/docker-feedback SchemaVersion:0.1.0 ShortDescription:Provide feedback, right in your terminal! Vendor:Docker Inc. Version:0.1] map[Name:init Path:/usr/lib/docker/cli-plugins/docker-init SchemaVersion:0.1.0 ShortDescription:Creates Docker-related starter files for your project Vendor:Docker Inc. Version:v0.1.0-beta.10] map[Name:sbom Path:/usr/lib/docker/cli-plugins/docker-sbom SchemaVersion:0.1.0 ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scan Path:/usr/lib/docker/cli-plugins/docker-scan SchemaVersion:0.1.0 ShortDescription:Docker Scan Vendor:Docker Inc. Version:v0.26.0] map[Name:scout Path:/usr/lib/docker/cli-plugins/docker-scout SchemaVersion:0.1.0 ShortDescription:Docker Scout Vendor:Docker Inc. Version:v1.2.0]] Warnings:<nil>}}
I0924 08:56:32.621976   21492 cni.go:84] Creating CNI manager for ""
I0924 08:56:32.622021   21492 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0924 08:56:32.622172   21492 start.go:340] cluster config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 Memory:3900 CPUs:2 DiskSize:20000 Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.31.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.31.0 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[dashboard:true default-storageclass:true metrics-server:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/mindbowser:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s}
I0924 08:56:32.623740   21492 out.go:177] üëç  Starting "minikube" primary control-plane node in "minikube" cluster
I0924 08:56:32.625173   21492 cache.go:121] Beginning downloading kic base image for docker with docker
I0924 08:56:32.626277   21492 out.go:177] üöú  Pulling base image v0.0.45 ...
I0924 08:56:32.627724   21492 preload.go:131] Checking if preload exists for k8s version v1.31.0 and runtime docker
I0924 08:56:32.627857   21492 preload.go:146] Found local preload: /home/mindbowser/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.31.0-docker-overlay2-amd64.tar.lz4
I0924 08:56:32.627874   21492 cache.go:56] Caching tarball of preloaded images
I0924 08:56:32.627914   21492 image.go:79] Checking for gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 in local docker daemon
I0924 08:56:32.628067   21492 preload.go:172] Found /home/mindbowser/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.31.0-docker-overlay2-amd64.tar.lz4 in cache, skipping download
I0924 08:56:32.628088   21492 cache.go:59] Finished verifying existence of preloaded tar for v1.31.0 on docker
I0924 08:56:32.628316   21492 profile.go:143] Saving config to /home/mindbowser/.minikube/profiles/minikube/config.json ...
W0924 08:56:32.808476   21492 image.go:95] image gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 is of wrong architecture
I0924 08:56:32.808496   21492 cache.go:149] Downloading gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 to local cache
I0924 08:56:32.808886   21492 image.go:63] Checking for gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 in local cache directory
I0924 08:56:32.809492   21492 image.go:66] Found gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 in local cache directory, skipping pull
I0924 08:56:32.809522   21492 image.go:135] gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 exists in cache, skipping pull
I0924 08:56:32.809543   21492 cache.go:152] successfully saved gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 as a tarball
I0924 08:56:32.809555   21492 cache.go:162] Loading gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 from local cache
I0924 08:56:33.861462   21492 cache.go:164] successfully loaded and using gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 from cached tarball
I0924 08:56:33.861540   21492 cache.go:194] Successfully downloaded all kic artifacts
I0924 08:56:33.861597   21492 start.go:360] acquireMachinesLock for minikube: {Name:mk44b4c1373ec1c3b7f82f7aaabaf594c71ab835 Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I0924 08:56:33.861850   21492 start.go:364] duration metric: took 210.366¬µs to acquireMachinesLock for "minikube"
I0924 08:56:33.861897   21492 start.go:96] Skipping create...Using existing machine configuration
I0924 08:56:33.861921   21492 fix.go:54] fixHost starting: 
I0924 08:56:33.862634   21492 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0924 08:56:34.011858   21492 fix.go:112] recreateIfNeeded on minikube: state=Stopped err=<nil>
W0924 08:56:34.011923   21492 fix.go:138] unexpected machine state, will restart: <nil>
I0924 08:56:34.013419   21492 out.go:177] üîÑ  Restarting existing docker container for "minikube" ...
I0924 08:56:34.014435   21492 cli_runner.go:164] Run: docker start minikube
I0924 08:56:35.640697   21492 cli_runner.go:217] Completed: docker start minikube: (1.626200134s)
I0924 08:56:35.640912   21492 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0924 08:56:35.801823   21492 kic.go:430] container "minikube" state is running.
I0924 08:56:35.802938   21492 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0924 08:56:35.972354   21492 profile.go:143] Saving config to /home/mindbowser/.minikube/profiles/minikube/config.json ...
I0924 08:56:35.972987   21492 machine.go:93] provisionDockerMachine start ...
I0924 08:56:35.973137   21492 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0924 08:56:36.185539   21492 main.go:141] libmachine: Using SSH client type: native
I0924 08:56:36.186522   21492 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x82f9c0] 0x832720 <nil>  [] 0s} 127.0.0.1 32772 <nil> <nil>}
I0924 08:56:36.186543   21492 main.go:141] libmachine: About to run SSH command:
hostname
I0924 08:56:36.188111   21492 main.go:141] libmachine: Error dialing TCP: ssh: handshake failed: read tcp 127.0.0.1:56072->127.0.0.1:32772: read: connection reset by peer
I0924 08:56:39.375667   21492 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I0924 08:56:39.375687   21492 ubuntu.go:169] provisioning hostname "minikube"
I0924 08:56:39.375791   21492 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0924 08:56:39.487374   21492 main.go:141] libmachine: Using SSH client type: native
I0924 08:56:39.487915   21492 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x82f9c0] 0x832720 <nil>  [] 0s} 127.0.0.1 32772 <nil> <nil>}
I0924 08:56:39.487936   21492 main.go:141] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I0924 08:56:39.710640   21492 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I0924 08:56:39.710754   21492 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0924 08:56:39.824745   21492 main.go:141] libmachine: Using SSH client type: native
I0924 08:56:39.825129   21492 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x82f9c0] 0x832720 <nil>  [] 0s} 127.0.0.1 32772 <nil> <nil>}
I0924 08:56:39.825157   21492 main.go:141] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube' | sudo tee -a /etc/hosts; 
			fi
		fi
I0924 08:56:40.002388   21492 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0924 08:56:40.002441   21492 ubuntu.go:175] set auth options {CertDir:/home/mindbowser/.minikube CaCertPath:/home/mindbowser/.minikube/certs/ca.pem CaPrivateKeyPath:/home/mindbowser/.minikube/certs/ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:/home/mindbowser/.minikube/machines/server.pem ServerKeyPath:/home/mindbowser/.minikube/machines/server-key.pem ClientKeyPath:/home/mindbowser/.minikube/certs/key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:/home/mindbowser/.minikube/certs/cert.pem ServerCertSANs:[] StorePath:/home/mindbowser/.minikube}
I0924 08:56:40.002475   21492 ubuntu.go:177] setting up certificates
I0924 08:56:40.002489   21492 provision.go:84] configureAuth start
I0924 08:56:40.002590   21492 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0924 08:56:40.122274   21492 provision.go:143] copyHostCerts
I0924 08:56:40.132121   21492 exec_runner.go:144] found /home/mindbowser/.minikube/cert.pem, removing ...
I0924 08:56:40.132142   21492 exec_runner.go:203] rm: /home/mindbowser/.minikube/cert.pem
I0924 08:56:40.132272   21492 exec_runner.go:151] cp: /home/mindbowser/.minikube/certs/cert.pem --> /home/mindbowser/.minikube/cert.pem (1131 bytes)
I0924 08:56:40.132890   21492 exec_runner.go:144] found /home/mindbowser/.minikube/key.pem, removing ...
I0924 08:56:40.132926   21492 exec_runner.go:203] rm: /home/mindbowser/.minikube/key.pem
I0924 08:56:40.133028   21492 exec_runner.go:151] cp: /home/mindbowser/.minikube/certs/key.pem --> /home/mindbowser/.minikube/key.pem (1679 bytes)
I0924 08:56:40.133567   21492 exec_runner.go:144] found /home/mindbowser/.minikube/ca.pem, removing ...
I0924 08:56:40.133580   21492 exec_runner.go:203] rm: /home/mindbowser/.minikube/ca.pem
I0924 08:56:40.133666   21492 exec_runner.go:151] cp: /home/mindbowser/.minikube/certs/ca.pem --> /home/mindbowser/.minikube/ca.pem (1090 bytes)
I0924 08:56:40.133980   21492 provision.go:117] generating server cert: /home/mindbowser/.minikube/machines/server.pem ca-key=/home/mindbowser/.minikube/certs/ca.pem private-key=/home/mindbowser/.minikube/certs/ca-key.pem org=mindbowser.minikube san=[127.0.0.1 192.168.49.2 localhost minikube]
I0924 08:56:40.841443   21492 provision.go:177] copyRemoteCerts
I0924 08:56:40.841551   21492 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I0924 08:56:40.841607   21492 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0924 08:56:40.942534   21492 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32772 SSHKeyPath:/home/mindbowser/.minikube/machines/minikube/id_rsa Username:docker}
I0924 08:56:41.069146   21492 ssh_runner.go:362] scp /home/mindbowser/.minikube/certs/ca.pem --> /etc/docker/ca.pem (1090 bytes)
I0924 08:56:41.120404   21492 ssh_runner.go:362] scp /home/mindbowser/.minikube/machines/server.pem --> /etc/docker/server.pem (1188 bytes)
I0924 08:56:41.179827   21492 ssh_runner.go:362] scp /home/mindbowser/.minikube/machines/server-key.pem --> /etc/docker/server-key.pem (1679 bytes)
I0924 08:56:41.239199   21492 provision.go:87] duration metric: took 1.236686529s to configureAuth
I0924 08:56:41.239230   21492 ubuntu.go:193] setting minikube options for container-runtime
I0924 08:56:41.239593   21492 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.31.0
I0924 08:56:41.239703   21492 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0924 08:56:41.354654   21492 main.go:141] libmachine: Using SSH client type: native
I0924 08:56:41.355023   21492 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x82f9c0] 0x832720 <nil>  [] 0s} 127.0.0.1 32772 <nil> <nil>}
I0924 08:56:41.355038   21492 main.go:141] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I0924 08:56:41.540248   21492 main.go:141] libmachine: SSH cmd err, output: <nil>: overlay

I0924 08:56:41.540271   21492 ubuntu.go:71] root file system type: overlay
I0924 08:56:41.540447   21492 provision.go:314] Updating docker unit: /lib/systemd/system/docker.service ...
I0924 08:56:41.540567   21492 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0924 08:56:41.655031   21492 main.go:141] libmachine: Using SSH client type: native
I0924 08:56:41.655374   21492 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x82f9c0] 0x832720 <nil>  [] 0s} 127.0.0.1 32772 <nil> <nil>}
I0924 08:56:41.655519   21492 main.go:141] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %s "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I0924 08:56:41.872966   21492 main.go:141] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I0924 08:56:41.873101   21492 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0924 08:56:41.998408   21492 main.go:141] libmachine: Using SSH client type: native
I0924 08:56:41.998867   21492 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x82f9c0] 0x832720 <nil>  [] 0s} 127.0.0.1 32772 <nil> <nil>}
I0924 08:56:41.998906   21492 main.go:141] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I0924 08:56:42.212155   21492 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0924 08:56:42.212179   21492 machine.go:96] duration metric: took 6.239176874s to provisionDockerMachine
I0924 08:56:42.212197   21492 start.go:293] postStartSetup for "minikube" (driver="docker")
I0924 08:56:42.212222   21492 start.go:322] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I0924 08:56:42.212369   21492 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I0924 08:56:42.212495   21492 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0924 08:56:42.336182   21492 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32772 SSHKeyPath:/home/mindbowser/.minikube/machines/minikube/id_rsa Username:docker}
I0924 08:56:42.478639   21492 ssh_runner.go:195] Run: cat /etc/os-release
I0924 08:56:42.486860   21492 main.go:141] libmachine: Couldn't set key VERSION_CODENAME, no corresponding struct field found
I0924 08:56:42.486929   21492 main.go:141] libmachine: Couldn't set key PRIVACY_POLICY_URL, no corresponding struct field found
I0924 08:56:42.486951   21492 main.go:141] libmachine: Couldn't set key UBUNTU_CODENAME, no corresponding struct field found
I0924 08:56:42.486964   21492 info.go:137] Remote host: Ubuntu 22.04.4 LTS
I0924 08:56:42.486988   21492 filesync.go:126] Scanning /home/mindbowser/.minikube/addons for local assets ...
I0924 08:56:42.487351   21492 filesync.go:126] Scanning /home/mindbowser/.minikube/files for local assets ...
I0924 08:56:42.487625   21492 start.go:296] duration metric: took 275.414581ms for postStartSetup
I0924 08:56:42.487795   21492 ssh_runner.go:195] Run: sh -c "df -h /var | awk 'NR==2{print $5}'"
I0924 08:56:42.487884   21492 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0924 08:56:42.613888   21492 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32772 SSHKeyPath:/home/mindbowser/.minikube/machines/minikube/id_rsa Username:docker}
I0924 08:56:42.751546   21492 ssh_runner.go:195] Run: sh -c "df -BG /var | awk 'NR==2{print $4}'"
I0924 08:56:42.761863   21492 fix.go:56] duration metric: took 8.899946983s for fixHost
I0924 08:56:42.761891   21492 start.go:83] releasing machines lock for "minikube", held for 8.900020261s
I0924 08:56:42.762035   21492 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0924 08:56:42.886647   21492 ssh_runner.go:195] Run: cat /version.json
I0924 08:56:42.886737   21492 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0924 08:56:42.886890   21492 ssh_runner.go:195] Run: curl -sS -m 2 https://registry.k8s.io/
I0924 08:56:42.887069   21492 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0924 08:56:43.042374   21492 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32772 SSHKeyPath:/home/mindbowser/.minikube/machines/minikube/id_rsa Username:docker}
I0924 08:56:43.043838   21492 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32772 SSHKeyPath:/home/mindbowser/.minikube/machines/minikube/id_rsa Username:docker}
I0924 08:56:43.182344   21492 ssh_runner.go:195] Run: systemctl --version
I0924 08:56:43.874504   21492 ssh_runner.go:195] Run: sh -c "stat /etc/cni/net.d/*loopback.conf*"
I0924 08:56:43.886905   21492 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f -name *loopback.conf* -not -name *.mk_disabled -exec sh -c "grep -q loopback {} && ( grep -q name {} || sudo sed -i '/"type": "loopback"/i \ \ \ \ "name": "loopback",' {} ) && sudo sed -i 's|"cniVersion": ".*"|"cniVersion": "1.0.0"|g' {}" ;
I0924 08:56:43.945284   21492 cni.go:230] loopback cni configuration patched: "/etc/cni/net.d/*loopback.conf*" found
I0924 08:56:43.945476   21492 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f ( ( -name *bridge* -or -name *podman* ) -and -not -name *.mk_disabled ) -printf "%p, " -exec sh -c "sudo mv {} {}.mk_disabled" ;
I0924 08:56:43.973068   21492 cni.go:259] no active bridge cni configs found in "/etc/cni/net.d" - nothing to disable
I0924 08:56:43.973100   21492 start.go:495] detecting cgroup driver to use...
I0924 08:56:43.973153   21492 detect.go:190] detected "systemd" cgroup driver on host os
I0924 08:56:43.973467   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %s "runtime-endpoint: unix:///run/containerd/containerd.sock
" | sudo tee /etc/crictl.yaml"
I0924 08:56:44.040283   21492 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)sandbox_image = .*$|\1sandbox_image = "registry.k8s.io/pause:3.10"|' /etc/containerd/config.toml"
I0924 08:56:44.070737   21492 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)restrict_oom_score_adj = .*$|\1restrict_oom_score_adj = false|' /etc/containerd/config.toml"
I0924 08:56:44.099666   21492 containerd.go:146] configuring containerd to use "systemd" as cgroup driver...
I0924 08:56:44.099869   21492 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)SystemdCgroup = .*$|\1SystemdCgroup = true|g' /etc/containerd/config.toml"
I0924 08:56:44.129065   21492 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runtime.v1.linux"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0924 08:56:44.157718   21492 ssh_runner.go:195] Run: sh -c "sudo sed -i '/systemd_cgroup/d' /etc/containerd/config.toml"
I0924 08:56:44.188193   21492 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runc.v1"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0924 08:56:44.216364   21492 ssh_runner.go:195] Run: sh -c "sudo rm -rf /etc/cni/net.mk"
I0924 08:56:44.242710   21492 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)conf_dir = .*$|\1conf_dir = "/etc/cni/net.d"|g' /etc/containerd/config.toml"
I0924 08:56:44.268838   21492 ssh_runner.go:195] Run: sh -c "sudo sed -i '/^ *enable_unprivileged_ports = .*/d' /etc/containerd/config.toml"
I0924 08:56:44.295203   21492 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)\[plugins."io.containerd.grpc.v1.cri"\]|&\n\1  enable_unprivileged_ports = true|' /etc/containerd/config.toml"
I0924 08:56:44.322871   21492 ssh_runner.go:195] Run: sudo sysctl net.bridge.bridge-nf-call-iptables
I0924 08:56:44.350175   21492 ssh_runner.go:195] Run: sudo sh -c "echo 1 > /proc/sys/net/ipv4/ip_forward"
I0924 08:56:44.372911   21492 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0924 08:56:44.560320   21492 ssh_runner.go:195] Run: sudo systemctl restart containerd
I0924 08:56:44.761542   21492 start.go:495] detecting cgroup driver to use...
I0924 08:56:44.761612   21492 detect.go:190] detected "systemd" cgroup driver on host os
I0924 08:56:44.761751   21492 ssh_runner.go:195] Run: sudo systemctl cat docker.service
I0924 08:56:44.796198   21492 cruntime.go:279] skipping containerd shutdown because we are bound to it
I0924 08:56:44.796379   21492 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I0924 08:56:44.844139   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %s "runtime-endpoint: unix:///var/run/cri-dockerd.sock
" | sudo tee /etc/crictl.yaml"
I0924 08:56:44.896973   21492 ssh_runner.go:195] Run: which cri-dockerd
I0924 08:56:44.908019   21492 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/cri-docker.service.d
I0924 08:56:44.933472   21492 ssh_runner.go:362] scp memory --> /etc/systemd/system/cri-docker.service.d/10-cni.conf (190 bytes)
I0924 08:56:44.994251   21492 ssh_runner.go:195] Run: sudo systemctl unmask docker.service
I0924 08:56:45.220748   21492 ssh_runner.go:195] Run: sudo systemctl enable docker.socket
I0924 08:56:45.421281   21492 docker.go:574] configuring docker to use "systemd" as cgroup driver...
I0924 08:56:45.421588   21492 ssh_runner.go:362] scp memory --> /etc/docker/daemon.json (129 bytes)
I0924 08:56:45.479388   21492 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0924 08:56:45.672055   21492 ssh_runner.go:195] Run: sudo systemctl restart docker
I0924 08:56:47.137184   21492 ssh_runner.go:235] Completed: sudo systemctl restart docker: (1.465075517s)
I0924 08:56:47.137307   21492 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service cri-docker.socket
I0924 08:56:47.165689   21492 ssh_runner.go:195] Run: sudo systemctl stop cri-docker.socket
I0924 08:56:47.200709   21492 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service cri-docker.service
I0924 08:56:47.234370   21492 ssh_runner.go:195] Run: sudo systemctl unmask cri-docker.socket
I0924 08:56:47.423560   21492 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0924 08:56:47.610951   21492 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0924 08:56:47.789964   21492 ssh_runner.go:195] Run: sudo systemctl restart cri-docker.socket
I0924 08:56:47.830511   21492 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service cri-docker.service
I0924 08:56:47.859888   21492 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0924 08:56:48.040222   21492 ssh_runner.go:195] Run: sudo systemctl restart cri-docker.service
I0924 08:56:48.332548   21492 start.go:542] Will wait 60s for socket path /var/run/cri-dockerd.sock
I0924 08:56:48.332807   21492 ssh_runner.go:195] Run: stat /var/run/cri-dockerd.sock
I0924 08:56:48.342666   21492 start.go:563] Will wait 60s for crictl version
I0924 08:56:48.342860   21492 ssh_runner.go:195] Run: which crictl
I0924 08:56:48.352437   21492 ssh_runner.go:195] Run: sudo /usr/bin/crictl version
I0924 08:56:48.504573   21492 start.go:579] Version:  0.1.0
RuntimeName:  docker
RuntimeVersion:  27.2.0
RuntimeApiVersion:  v1
I0924 08:56:48.504679   21492 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0924 08:56:48.624620   21492 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0924 08:56:48.682812   21492 out.go:235] üê≥  Preparing Kubernetes v1.31.0 on Docker 27.2.0 ...
I0924 08:56:48.683393   21492 cli_runner.go:164] Run: docker network inspect minikube --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}"
I0924 08:56:48.830485   21492 ssh_runner.go:195] Run: grep 192.168.49.1	host.minikube.internal$ /etc/hosts
I0924 08:56:48.840277   21492 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\thost.minikube.internal$' "/etc/hosts"; echo "192.168.49.1	host.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0924 08:56:48.879648   21492 kubeadm.go:883] updating cluster {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 Memory:3900 CPUs:2 DiskSize:20000 Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.31.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.31.0 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[dashboard:true default-storageclass:true metrics-server:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/mindbowser:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s} ...
I0924 08:56:48.879950   21492 preload.go:131] Checking if preload exists for k8s version v1.31.0 and runtime docker
I0924 08:56:48.880111   21492 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0924 08:56:48.942272   21492 docker.go:685] Got preloaded images: -- stdout --
<none>:<none>
<none>:<none>
registry.k8s.io/kube-scheduler:v1.31.0
registry.k8s.io/kube-controller-manager:v1.31.0
registry.k8s.io/kube-apiserver:v1.31.0
registry.k8s.io/kube-proxy:v1.31.0
registry.k8s.io/etcd:3.5.15-0
registry.k8s.io/pause:3.10
registry.k8s.io/coredns/coredns:v1.11.1
<none>:<none>
<none>:<none>
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I0924 08:56:48.942293   21492 docker.go:615] Images already preloaded, skipping extraction
I0924 08:56:48.942419   21492 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0924 08:56:48.995705   21492 docker.go:685] Got preloaded images: -- stdout --
<none>:<none>
<none>:<none>
registry.k8s.io/kube-apiserver:v1.31.0
registry.k8s.io/kube-scheduler:v1.31.0
registry.k8s.io/kube-controller-manager:v1.31.0
registry.k8s.io/kube-proxy:v1.31.0
registry.k8s.io/etcd:3.5.15-0
registry.k8s.io/pause:3.10
registry.k8s.io/coredns/coredns:v1.11.1
<none>:<none>
<none>:<none>
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I0924 08:56:48.995743   21492 cache_images.go:84] Images are preloaded, skipping loading
I0924 08:56:48.995759   21492 kubeadm.go:934] updating node { 192.168.49.2 8443 v1.31.0 docker true true} ...
I0924 08:56:48.996055   21492 kubeadm.go:946] kubelet [Unit]
Wants=docker.socket

[Service]
ExecStart=
ExecStart=/var/lib/minikube/binaries/v1.31.0/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --config=/var/lib/kubelet/config.yaml --hostname-override=minikube --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=192.168.49.2

[Install]
 config:
{KubernetesVersion:v1.31.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:}
I0924 08:56:48.996222   21492 ssh_runner.go:195] Run: docker info --format {{.CgroupDriver}}
I0924 08:56:49.291046   21492 cni.go:84] Creating CNI manager for ""
I0924 08:56:49.291089   21492 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0924 08:56:49.291136   21492 kubeadm.go:84] Using pod CIDR: 10.244.0.0/16
I0924 08:56:49.291184   21492 kubeadm.go:181] kubeadm options: {CertDir:/var/lib/minikube/certs ServiceCIDR:10.96.0.0/12 PodSubnet:10.244.0.0/16 AdvertiseAddress:192.168.49.2 APIServerPort:8443 KubernetesVersion:v1.31.0 EtcdDataDir:/var/lib/minikube/etcd EtcdExtraArgs:map[] ClusterName:minikube NodeName:minikube DNSDomain:cluster.local CRISocket:/var/run/cri-dockerd.sock ImageRepository: ComponentOptions:[{Component:apiServer ExtraArgs:map[enable-admission-plugins:NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota] Pairs:map[certSANs:["127.0.0.1", "localhost", "192.168.49.2"]]} {Component:controllerManager ExtraArgs:map[allocate-node-cidrs:true leader-elect:false] Pairs:map[]} {Component:scheduler ExtraArgs:map[leader-elect:false] Pairs:map[]}] FeatureArgs:map[] NodeIP:192.168.49.2 CgroupDriver:systemd ClientCAFile:/var/lib/minikube/certs/ca.crt StaticPodPath:/etc/kubernetes/manifests ControlPlaneAddress:control-plane.minikube.internal KubeProxyOptions:map[] ResolvConfSearchRegression:false KubeletConfigOpts:map[containerRuntimeEndpoint:unix:///var/run/cri-dockerd.sock hairpinMode:hairpin-veth runtimeRequestTimeout:15m] PrependCriSocketUnix:true}
I0924 08:56:49.291471   21492 kubeadm.go:187] kubeadm config:
apiVersion: kubeadm.k8s.io/v1beta3
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.49.2
  bindPort: 8443
bootstrapTokens:
  - groups:
      - system:bootstrappers:kubeadm:default-node-token
    ttl: 24h0m0s
    usages:
      - signing
      - authentication
nodeRegistration:
  criSocket: unix:///var/run/cri-dockerd.sock
  name: "minikube"
  kubeletExtraArgs:
    node-ip: 192.168.49.2
  taints: []
---
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
apiServer:
  certSANs: ["127.0.0.1", "localhost", "192.168.49.2"]
  extraArgs:
    enable-admission-plugins: "NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota"
controllerManager:
  extraArgs:
    allocate-node-cidrs: "true"
    leader-elect: "false"
scheduler:
  extraArgs:
    leader-elect: "false"
certificatesDir: /var/lib/minikube/certs
clusterName: mk
controlPlaneEndpoint: control-plane.minikube.internal:8443
etcd:
  local:
    dataDir: /var/lib/minikube/etcd
    extraArgs:
      proxy-refresh-interval: "70000"
kubernetesVersion: v1.31.0
networking:
  dnsDomain: cluster.local
  podSubnet: "10.244.0.0/16"
  serviceSubnet: 10.96.0.0/12
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
authentication:
  x509:
    clientCAFile: /var/lib/minikube/certs/ca.crt
cgroupDriver: systemd
containerRuntimeEndpoint: unix:///var/run/cri-dockerd.sock
hairpinMode: hairpin-veth
runtimeRequestTimeout: 15m
clusterDomain: "cluster.local"
# disable disk resource management by default
imageGCHighThresholdPercent: 100
evictionHard:
  nodefs.available: "0%"
  nodefs.inodesFree: "0%"
  imagefs.available: "0%"
failSwapOn: false
staticPodPath: /etc/kubernetes/manifests
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
clusterCIDR: "10.244.0.0/16"
metricsBindAddress: 0.0.0.0:10249
conntrack:
  maxPerCore: 0
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_established"
  tcpEstablishedTimeout: 0s
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_close"
  tcpCloseWaitTimeout: 0s

I0924 08:56:49.291609   21492 ssh_runner.go:195] Run: sudo ls /var/lib/minikube/binaries/v1.31.0
I0924 08:56:49.322128   21492 binaries.go:44] Found k8s binaries, skipping transfer
I0924 08:56:49.322276   21492 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/kubelet.service.d /lib/systemd/system /var/tmp/minikube
I0924 08:56:49.348842   21492 ssh_runner.go:362] scp memory --> /etc/systemd/system/kubelet.service.d/10-kubeadm.conf (307 bytes)
I0924 08:56:49.407286   21492 ssh_runner.go:362] scp memory --> /lib/systemd/system/kubelet.service (352 bytes)
I0924 08:56:49.463210   21492 ssh_runner.go:362] scp memory --> /var/tmp/minikube/kubeadm.yaml.new (2149 bytes)
I0924 08:56:49.535937   21492 ssh_runner.go:195] Run: grep 192.168.49.2	control-plane.minikube.internal$ /etc/hosts
I0924 08:56:49.548511   21492 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\tcontrol-plane.minikube.internal$' "/etc/hosts"; echo "192.168.49.2	control-plane.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0924 08:56:49.584102   21492 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0924 08:56:49.810758   21492 ssh_runner.go:195] Run: sudo systemctl start kubelet
I0924 08:56:49.864395   21492 certs.go:68] Setting up /home/mindbowser/.minikube/profiles/minikube for IP: 192.168.49.2
I0924 08:56:49.864422   21492 certs.go:194] generating shared ca certs ...
I0924 08:56:49.864459   21492 certs.go:226] acquiring lock for ca certs: {Name:mkcaca4eefd67a7dbcfc156c268055707adf6919 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0924 08:56:49.866492   21492 certs.go:235] skipping valid "minikubeCA" ca cert: /home/mindbowser/.minikube/ca.key
I0924 08:56:49.866919   21492 certs.go:235] skipping valid "proxyClientCA" ca cert: /home/mindbowser/.minikube/proxy-client-ca.key
I0924 08:56:49.866940   21492 certs.go:256] generating profile certs ...
I0924 08:56:49.867436   21492 certs.go:359] skipping valid signed profile cert regeneration for "minikube-user": /home/mindbowser/.minikube/profiles/minikube/client.key
I0924 08:56:49.867940   21492 certs.go:359] skipping valid signed profile cert regeneration for "minikube": /home/mindbowser/.minikube/profiles/minikube/apiserver.key.7fb57e3c
I0924 08:56:49.868254   21492 certs.go:359] skipping valid signed profile cert regeneration for "aggregator": /home/mindbowser/.minikube/profiles/minikube/proxy-client.key
I0924 08:56:49.868596   21492 certs.go:484] found cert: /home/mindbowser/.minikube/certs/ca-key.pem (1679 bytes)
I0924 08:56:49.868673   21492 certs.go:484] found cert: /home/mindbowser/.minikube/certs/ca.pem (1090 bytes)
I0924 08:56:49.868741   21492 certs.go:484] found cert: /home/mindbowser/.minikube/certs/cert.pem (1131 bytes)
I0924 08:56:49.868827   21492 certs.go:484] found cert: /home/mindbowser/.minikube/certs/key.pem (1679 bytes)
I0924 08:56:49.870902   21492 ssh_runner.go:362] scp /home/mindbowser/.minikube/ca.crt --> /var/lib/minikube/certs/ca.crt (1111 bytes)
I0924 08:56:49.964440   21492 ssh_runner.go:362] scp /home/mindbowser/.minikube/ca.key --> /var/lib/minikube/certs/ca.key (1679 bytes)
I0924 08:56:50.059937   21492 ssh_runner.go:362] scp /home/mindbowser/.minikube/proxy-client-ca.crt --> /var/lib/minikube/certs/proxy-client-ca.crt (1119 bytes)
I0924 08:56:50.141723   21492 ssh_runner.go:362] scp /home/mindbowser/.minikube/proxy-client-ca.key --> /var/lib/minikube/certs/proxy-client-ca.key (1675 bytes)
I0924 08:56:50.222649   21492 ssh_runner.go:362] scp /home/mindbowser/.minikube/profiles/minikube/apiserver.crt --> /var/lib/minikube/certs/apiserver.crt (1411 bytes)
I0924 08:56:50.296881   21492 ssh_runner.go:362] scp /home/mindbowser/.minikube/profiles/minikube/apiserver.key --> /var/lib/minikube/certs/apiserver.key (1679 bytes)
I0924 08:56:50.371161   21492 ssh_runner.go:362] scp /home/mindbowser/.minikube/profiles/minikube/proxy-client.crt --> /var/lib/minikube/certs/proxy-client.crt (1147 bytes)
I0924 08:56:50.448044   21492 ssh_runner.go:362] scp /home/mindbowser/.minikube/profiles/minikube/proxy-client.key --> /var/lib/minikube/certs/proxy-client.key (1679 bytes)
I0924 08:56:50.524359   21492 ssh_runner.go:362] scp /home/mindbowser/.minikube/ca.crt --> /usr/share/ca-certificates/minikubeCA.pem (1111 bytes)
I0924 08:56:50.598356   21492 ssh_runner.go:362] scp memory --> /var/lib/minikube/kubeconfig (738 bytes)
I0924 08:56:50.660972   21492 ssh_runner.go:195] Run: openssl version
I0924 08:56:50.679250   21492 ssh_runner.go:195] Run: sudo /bin/bash -c "test -s /usr/share/ca-certificates/minikubeCA.pem && ln -fs /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem"
I0924 08:56:50.709760   21492 ssh_runner.go:195] Run: ls -la /usr/share/ca-certificates/minikubeCA.pem
I0924 08:56:50.721450   21492 certs.go:528] hashing: -rw-r--r-- 1 root root 1111 Jul 29 13:58 /usr/share/ca-certificates/minikubeCA.pem
I0924 08:56:50.721621   21492 ssh_runner.go:195] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
I0924 08:56:50.746834   21492 ssh_runner.go:195] Run: sudo /bin/bash -c "test -L /etc/ssl/certs/b5213941.0 || ln -fs /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0"
I0924 08:56:50.776171   21492 ssh_runner.go:195] Run: stat /var/lib/minikube/certs/apiserver-kubelet-client.crt
I0924 08:56:50.787654   21492 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/apiserver-etcd-client.crt -checkend 86400
I0924 08:56:50.808255   21492 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/apiserver-kubelet-client.crt -checkend 86400
I0924 08:56:50.832368   21492 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/server.crt -checkend 86400
I0924 08:56:50.855928   21492 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/healthcheck-client.crt -checkend 86400
I0924 08:56:50.877571   21492 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/peer.crt -checkend 86400
I0924 08:56:50.900349   21492 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/front-proxy-client.crt -checkend 86400
I0924 08:56:50.931509   21492 kubeadm.go:392] StartCluster: {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 Memory:3900 CPUs:2 DiskSize:20000 Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.31.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.31.0 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[dashboard:true default-storageclass:true metrics-server:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/mindbowser:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s}
I0924 08:56:50.931995   21492 ssh_runner.go:195] Run: docker ps --filter status=paused --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I0924 08:56:51.015328   21492 ssh_runner.go:195] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
I0924 08:56:51.056313   21492 kubeadm.go:408] found existing configuration files, will attempt cluster restart
I0924 08:56:51.056334   21492 kubeadm.go:593] restartPrimaryControlPlane start ...
I0924 08:56:51.056479   21492 ssh_runner.go:195] Run: sudo test -d /data/minikube
I0924 08:56:51.094384   21492 kubeadm.go:130] /data/minikube skipping compat symlinks: sudo test -d /data/minikube: Process exited with status 1
stdout:

stderr:
I0924 08:56:51.097802   21492 kubeconfig.go:125] found "minikube" server: "https://192.168.49.2:8443"
I0924 08:56:51.112254   21492 ssh_runner.go:195] Run: sudo diff -u /var/tmp/minikube/kubeadm.yaml /var/tmp/minikube/kubeadm.yaml.new
I0924 08:56:51.146336   21492 kubeadm.go:630] The running cluster does not require reconfiguration: 192.168.49.2
I0924 08:56:51.146440   21492 kubeadm.go:597] duration metric: took 90.046437ms to restartPrimaryControlPlane
I0924 08:56:51.146471   21492 kubeadm.go:394] duration metric: took 214.979597ms to StartCluster
I0924 08:56:51.146541   21492 settings.go:142] acquiring lock: {Name:mk6919370d81d116b1c61c1d8d0279cd51cb4b71 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0924 08:56:51.146828   21492 settings.go:150] Updating kubeconfig:  /home/mindbowser/.kube/config
I0924 08:56:51.148654   21492 lock.go:35] WriteFile acquiring /home/mindbowser/.kube/config: {Name:mk0d5ef40bcbe565520969b0ae110d30be9ac406 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0924 08:56:51.149405   21492 start.go:235] Will wait 6m0s for node &{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.31.0 ContainerRuntime:docker ControlPlane:true Worker:true}
I0924 08:56:51.149526   21492 addons.go:507] enable addons start: toEnable=map[ambassador:false auto-pause:false cloud-spanner:false csi-hostpath-driver:false dashboard:true default-storageclass:true efk:false freshpod:false gcp-auth:false gvisor:false headlamp:false helm-tiller:false inaccel:false ingress:false ingress-dns:false inspektor-gadget:false istio:false istio-provisioner:false kong:false kubeflow:false kubevirt:false logviewer:false metallb:false metrics-server:true nvidia-device-plugin:false nvidia-driver-installer:false nvidia-gpu-device-plugin:false olm:false pod-security-policy:false portainer:false registry:false registry-aliases:false registry-creds:false storage-provisioner:true storage-provisioner-gluster:false storage-provisioner-rancher:false volcano:false volumesnapshots:false yakd:false]
I0924 08:56:51.149760   21492 addons.go:69] Setting storage-provisioner=true in profile "minikube"
I0924 08:56:51.149761   21492 addons.go:69] Setting default-storageclass=true in profile "minikube"
I0924 08:56:51.149864   21492 addons_storage_classes.go:33] enableOrDisableStorageClasses default-storageclass=true on "minikube"
I0924 08:56:51.149868   21492 addons.go:234] Setting addon storage-provisioner=true in "minikube"
I0924 08:56:51.149863   21492 addons.go:69] Setting dashboard=true in profile "minikube"
W0924 08:56:51.149893   21492 addons.go:243] addon storage-provisioner should already be in state true
I0924 08:56:51.149982   21492 host.go:66] Checking if "minikube" exists ...
I0924 08:56:51.149984   21492 addons.go:234] Setting addon dashboard=true in "minikube"
I0924 08:56:51.149949   21492 addons.go:69] Setting metrics-server=true in profile "minikube"
W0924 08:56:51.150033   21492 addons.go:243] addon dashboard should already be in state true
I0924 08:56:51.150069   21492 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.31.0
I0924 08:56:51.150101   21492 addons.go:234] Setting addon metrics-server=true in "minikube"
W0924 08:56:51.150135   21492 addons.go:243] addon metrics-server should already be in state true
I0924 08:56:51.150161   21492 host.go:66] Checking if "minikube" exists ...
I0924 08:56:51.150233   21492 host.go:66] Checking if "minikube" exists ...
I0924 08:56:51.151064   21492 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0924 08:56:51.151709   21492 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0924 08:56:51.151819   21492 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0924 08:56:51.152123   21492 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0924 08:56:51.152545   21492 out.go:177] üîé  Verifying Kubernetes components...
I0924 08:56:51.154369   21492 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0924 08:56:51.451907   21492 out.go:177]     ‚ñ™ Using image registry.k8s.io/metrics-server/metrics-server:v0.7.2
I0924 08:56:51.454438   21492 addons.go:431] installing /etc/kubernetes/addons/metrics-apiservice.yaml
I0924 08:56:51.454475   21492 ssh_runner.go:362] scp metrics-server/metrics-apiservice.yaml --> /etc/kubernetes/addons/metrics-apiservice.yaml (424 bytes)
I0924 08:56:51.454693   21492 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0924 08:56:51.466686   21492 out.go:177]     ‚ñ™ Using image docker.io/kubernetesui/metrics-scraper:v1.0.8
I0924 08:56:51.471101   21492 out.go:177]     ‚ñ™ Using image docker.io/kubernetesui/dashboard:v2.7.0
I0924 08:56:51.472808   21492 addons.go:431] installing /etc/kubernetes/addons/dashboard-ns.yaml
I0924 08:56:51.472844   21492 ssh_runner.go:362] scp dashboard/dashboard-ns.yaml --> /etc/kubernetes/addons/dashboard-ns.yaml (759 bytes)
I0924 08:56:51.473373   21492 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0924 08:56:51.475670   21492 addons.go:234] Setting addon default-storageclass=true in "minikube"
W0924 08:56:51.475708   21492 addons.go:243] addon default-storageclass should already be in state true
I0924 08:56:51.475810   21492 host.go:66] Checking if "minikube" exists ...
I0924 08:56:51.477645   21492 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0924 08:56:51.478796   21492 out.go:177]     ‚ñ™ Using image gcr.io/k8s-minikube/storage-provisioner:v5
I0924 08:56:51.480194   21492 addons.go:431] installing /etc/kubernetes/addons/storage-provisioner.yaml
I0924 08:56:51.480223   21492 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storage-provisioner.yaml (2676 bytes)
I0924 08:56:51.480396   21492 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0924 08:56:51.524967   21492 ssh_runner.go:195] Run: sudo systemctl start kubelet
I0924 08:56:51.694211   21492 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32772 SSHKeyPath:/home/mindbowser/.minikube/machines/minikube/id_rsa Username:docker}
I0924 08:56:51.710496   21492 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32772 SSHKeyPath:/home/mindbowser/.minikube/machines/minikube/id_rsa Username:docker}
I0924 08:56:51.751124   21492 addons.go:431] installing /etc/kubernetes/addons/storageclass.yaml
I0924 08:56:51.751161   21492 ssh_runner.go:362] scp storageclass/storageclass.yaml --> /etc/kubernetes/addons/storageclass.yaml (271 bytes)
I0924 08:56:51.751353   21492 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0924 08:56:51.761388   21492 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32772 SSHKeyPath:/home/mindbowser/.minikube/machines/minikube/id_rsa Username:docker}
I0924 08:56:51.910254   21492 api_server.go:52] waiting for apiserver process to appear ...
I0924 08:56:51.910474   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:56:51.920043   21492 addons.go:431] installing /etc/kubernetes/addons/metrics-server-deployment.yaml
I0924 08:56:51.920076   21492 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/metrics-server-deployment.yaml (1907 bytes)
I0924 08:56:51.937193   21492 addons.go:431] installing /etc/kubernetes/addons/dashboard-clusterrole.yaml
I0924 08:56:51.937232   21492 ssh_runner.go:362] scp dashboard/dashboard-clusterrole.yaml --> /etc/kubernetes/addons/dashboard-clusterrole.yaml (1001 bytes)
I0924 08:56:51.956633   21492 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32772 SSHKeyPath:/home/mindbowser/.minikube/machines/minikube/id_rsa Username:docker}
I0924 08:56:51.989481   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml
I0924 08:56:52.012963   21492 addons.go:431] installing /etc/kubernetes/addons/metrics-server-rbac.yaml
I0924 08:56:52.013005   21492 ssh_runner.go:362] scp metrics-server/metrics-server-rbac.yaml --> /etc/kubernetes/addons/metrics-server-rbac.yaml (2175 bytes)
I0924 08:56:52.034992   21492 addons.go:431] installing /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml
I0924 08:56:52.035029   21492 ssh_runner.go:362] scp dashboard/dashboard-clusterrolebinding.yaml --> /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml (1018 bytes)
I0924 08:56:52.107754   21492 addons.go:431] installing /etc/kubernetes/addons/metrics-server-service.yaml
I0924 08:56:52.108170   21492 ssh_runner.go:362] scp metrics-server/metrics-server-service.yaml --> /etc/kubernetes/addons/metrics-server-service.yaml (446 bytes)
I0924 08:56:52.133336   21492 addons.go:431] installing /etc/kubernetes/addons/dashboard-configmap.yaml
I0924 08:56:52.133375   21492 ssh_runner.go:362] scp dashboard/dashboard-configmap.yaml --> /etc/kubernetes/addons/dashboard-configmap.yaml (837 bytes)
I0924 08:56:52.203084   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml
I0924 08:56:52.220840   21492 addons.go:431] installing /etc/kubernetes/addons/dashboard-dp.yaml
I0924 08:56:52.220880   21492 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-dp.yaml (4288 bytes)
I0924 08:56:52.232193   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml
I0924 08:56:52.304879   21492 addons.go:431] installing /etc/kubernetes/addons/dashboard-role.yaml
I0924 08:56:52.304921   21492 ssh_runner.go:362] scp dashboard/dashboard-role.yaml --> /etc/kubernetes/addons/dashboard-role.yaml (1724 bytes)
I0924 08:56:52.392022   21492 addons.go:431] installing /etc/kubernetes/addons/dashboard-rolebinding.yaml
I0924 08:56:52.392070   21492 ssh_runner.go:362] scp dashboard/dashboard-rolebinding.yaml --> /etc/kubernetes/addons/dashboard-rolebinding.yaml (1046 bytes)
I0924 08:56:52.411525   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0924 08:56:52.465811   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:52.465906   21492 retry.go:31] will retry after 127.749901ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
W0924 08:56:52.469607   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/metrics-apiservice.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-deployment.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-rbac.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-service.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:52.469672   21492 retry.go:31] will retry after 268.251603ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/metrics-apiservice.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-deployment.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-rbac.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-service.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:52.479810   21492 addons.go:431] installing /etc/kubernetes/addons/dashboard-sa.yaml
I0924 08:56:52.479851   21492 ssh_runner.go:362] scp dashboard/dashboard-sa.yaml --> /etc/kubernetes/addons/dashboard-sa.yaml (837 bytes)
W0924 08:56:52.491613   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:52.491664   21492 retry.go:31] will retry after 202.102095ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:52.544705   21492 addons.go:431] installing /etc/kubernetes/addons/dashboard-secret.yaml
I0924 08:56:52.544749   21492 ssh_runner.go:362] scp dashboard/dashboard-secret.yaml --> /etc/kubernetes/addons/dashboard-secret.yaml (1389 bytes)
I0924 08:56:52.594877   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
I0924 08:56:52.607564   21492 addons.go:431] installing /etc/kubernetes/addons/dashboard-svc.yaml
I0924 08:56:52.607594   21492 ssh_runner.go:362] scp dashboard/dashboard-svc.yaml --> /etc/kubernetes/addons/dashboard-svc.yaml (1294 bytes)
I0924 08:56:52.672145   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml
I0924 08:56:52.694435   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
I0924 08:56:52.739195   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml
W0924 08:56:52.793092   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:52.793158   21492 retry.go:31] will retry after 253.07024ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
W0924 08:56:52.868116   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/dashboard-ns.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrole.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-configmap.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-dp.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-role.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-rolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-sa.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-secret.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-svc.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:52.868186   21492 retry.go:31] will retry after 226.951519ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/dashboard-ns.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrole.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-configmap.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-dp.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-role.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-rolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-sa.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-secret.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-svc.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
W0924 08:56:52.895080   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:52.895125   21492 retry.go:31] will retry after 280.960423ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:52.911365   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0924 08:56:52.980613   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/metrics-apiservice.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-deployment.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-rbac.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-service.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:52.980664   21492 retry.go:31] will retry after 422.956553ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/metrics-apiservice.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-deployment.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-rbac.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-service.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:53.046982   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
I0924 08:56:53.096407   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml
I0924 08:56:53.177359   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
W0924 08:56:53.308179   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:53.308227   21492 retry.go:31] will retry after 537.999067ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
W0924 08:56:53.380740   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/dashboard-ns.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrole.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-configmap.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-dp.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-role.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-rolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-sa.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-secret.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-svc.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:53.380894   21492 retry.go:31] will retry after 217.011825ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/dashboard-ns.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrole.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-configmap.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-dp.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-role.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-rolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-sa.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-secret.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-svc.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:53.404538   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml
I0924 08:56:53.411345   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0924 08:56:53.481189   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:53.481232   21492 retry.go:31] will retry after 623.160133ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:53.599894   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml
W0924 08:56:53.708722   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/metrics-apiservice.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-deployment.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-rbac.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-service.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:53.708765   21492 retry.go:31] will retry after 649.308851ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/metrics-apiservice.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-deployment.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-rbac.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-service.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:53.847664   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
I0924 08:56:53.911141   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0924 08:56:54.000243   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/dashboard-ns.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrole.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-configmap.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-dp.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-role.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-rolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-sa.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-secret.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-svc.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:54.000316   21492 retry.go:31] will retry after 688.4974ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/dashboard-ns.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrole.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-configmap.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-dp.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-role.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-rolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-sa.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-secret.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-svc.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:54.104869   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
W0924 08:56:54.179223   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:54.179292   21492 retry.go:31] will retry after 1.186733309s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:54.359244   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml
W0924 08:56:54.363477   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:54.363536   21492 retry.go:31] will retry after 1.0705737s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:54.411148   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0924 08:56:54.654733   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/metrics-apiservice.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-deployment.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-rbac.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-service.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:54.654828   21492 retry.go:31] will retry after 1.006642752s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/metrics-apiservice.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-deployment.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-rbac.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-service.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:54.689722   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml
I0924 08:56:54.917286   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0924 08:56:55.101187   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/dashboard-ns.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrole.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-configmap.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-dp.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-role.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-rolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-sa.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-secret.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-svc.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:55.101299   21492 retry.go:31] will retry after 567.466151ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/dashboard-ns.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrole.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-configmap.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-dp.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-role.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-rolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-sa.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-secret.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-svc.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:55.367251   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
I0924 08:56:55.411579   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:56:55.435389   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
I0924 08:56:55.662673   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml
I0924 08:56:55.671250   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml
W0924 08:56:55.817949   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:55.818023   21492 retry.go:31] will retry after 1.239986032s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
W0924 08:56:55.878032   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:55.878090   21492 retry.go:31] will retry after 1.129496396s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:55.911566   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0924 08:56:56.028909   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/metrics-apiservice.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-deployment.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-rbac.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-service.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:56.029000   21492 retry.go:31] will retry after 1.166050244s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/metrics-apiservice.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-deployment.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-rbac.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-service.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
W0924 08:56:56.097037   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/dashboard-ns.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrole.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-configmap.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-dp.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-role.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-rolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-sa.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-secret.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-svc.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:56.097336   21492 retry.go:31] will retry after 1.17795178s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/dashboard-ns.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrole.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-configmap.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-dp.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-role.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-rolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-sa.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-secret.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-svc.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:56.410664   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:56:56.911399   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:56:57.012481   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
I0924 08:56:57.058563   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
I0924 08:56:57.195658   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml
I0924 08:56:57.276613   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml
W0924 08:56:57.281149   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:57.281194   21492 retry.go:31] will retry after 2.577420809s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:57.411555   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0924 08:56:57.521372   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/dashboard-ns.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrole.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-configmap.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-dp.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-role.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-rolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-sa.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-secret.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-svc.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:57.521447   21492 retry.go:31] will retry after 1.723017861s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/dashboard-ns.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrole.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-configmap.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-dp.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-role.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-rolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-sa.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-secret.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-svc.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
W0924 08:56:57.521744   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/metrics-apiservice.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-deployment.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-rbac.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-service.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:57.521817   21492 retry.go:31] will retry after 1.655190054s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/metrics-apiservice.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-deployment.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-rbac.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-service.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
W0924 08:56:57.521894   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:57.521924   21492 retry.go:31] will retry after 1.425149649s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:57.911226   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:56:58.411143   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:56:58.911243   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:56:58.947364   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
I0924 08:56:59.177382   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml
W0924 08:56:59.177613   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:59.177653   21492 retry.go:31] will retry after 4.14279836s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:59.245152   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml
I0924 08:56:59.410874   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0924 08:56:59.416315   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/metrics-apiservice.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-deployment.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-rbac.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-service.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:59.416379   21492 retry.go:31] will retry after 3.766341286s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/metrics-apiservice.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-deployment.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-rbac.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-service.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
W0924 08:56:59.454091   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/dashboard-ns.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrole.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-configmap.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-dp.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-role.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-rolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-sa.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-secret.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-svc.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:59.454155   21492 retry.go:31] will retry after 1.487263507s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/dashboard-ns.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrole.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-configmap.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-dp.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-role.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-rolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-sa.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-secret.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-svc.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:56:59.859821   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
I0924 08:56:59.911381   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0924 08:57:00.158279   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:00.158334   21492 retry.go:31] will retry after 3.040461346s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:00.410661   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:00.913097   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:00.943945   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml
W0924 08:57:01.199925   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/dashboard-ns.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrole.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-configmap.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-dp.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-role.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-rolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-sa.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-secret.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-svc.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:01.199978   21492 retry.go:31] will retry after 2.354932621s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/dashboard-ns.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrole.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-configmap.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-dp.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-role.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-rolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-sa.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-secret.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-svc.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:01.411199   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:01.910556   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:02.411237   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:02.910801   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:03.183942   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml
I0924 08:57:03.199911   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
I0924 08:57:03.321827   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
W0924 08:57:03.391031   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/metrics-apiservice.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-deployment.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-rbac.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-service.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:03.391084   21492 retry.go:31] will retry after 2.963487425s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/metrics-apiservice.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-deployment.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-rbac.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-service.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
W0924 08:57:03.397838   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:03.397885   21492 retry.go:31] will retry after 3.408940428s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:03.411130   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0924 08:57:03.513024   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:03.513071   21492 retry.go:31] will retry after 5.157478949s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:03.555313   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml
W0924 08:57:03.716380   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/dashboard-ns.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrole.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-configmap.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-dp.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-role.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-rolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-sa.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-secret.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-svc.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:03.716428   21492 retry.go:31] will retry after 5.719738255s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/dashboard-ns.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrole.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-configmap.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-dp.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-role.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-rolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-sa.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-secret.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-svc.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:03.910767   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:04.411273   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:04.911169   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:05.410736   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:05.911169   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:06.355691   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml
I0924 08:57:06.411508   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0924 08:57:06.524712   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/metrics-apiservice.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-deployment.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-rbac.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-service.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:06.524757   21492 retry.go:31] will retry after 6.994307287s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/metrics-apiservice.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-deployment.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-rbac.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-service.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:06.807519   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
I0924 08:57:06.911291   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0924 08:57:06.994497   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:06.994539   21492 retry.go:31] will retry after 3.501327952s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:07.411415   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:07.911130   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:08.410884   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:08.671240   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
W0924 08:57:08.884144   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:08.884188   21492 retry.go:31] will retry after 4.154803241s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:08.911520   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:09.411200   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:09.437086   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml
W0924 08:57:09.603494   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/dashboard-ns.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrole.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-configmap.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-dp.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-role.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-rolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-sa.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-secret.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-svc.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:09.603540   21492 retry.go:31] will retry after 6.675241404s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/dashboard-ns.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrole.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-configmap.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-dp.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-role.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-rolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-sa.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-secret.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-svc.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:09.911551   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:10.411003   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:10.496715   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
W0924 08:57:10.673668   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:10.673702   21492 retry.go:31] will retry after 13.552323764s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:10.911074   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:11.410676   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:11.911054   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:12.411168   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:12.911131   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:13.040245   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
W0924 08:57:13.184495   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:13.184527   21492 retry.go:31] will retry after 11.210082103s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:13.411054   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:13.519554   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml
W0924 08:57:13.683802   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/metrics-apiservice.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-deployment.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-rbac.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-service.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:13.683847   21492 retry.go:31] will retry after 13.605453514s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/metrics-apiservice.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-deployment.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-rbac.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-service.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:13.911255   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:14.411141   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:14.910619   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:15.410643   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:15.910965   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:16.279236   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml
I0924 08:57:16.410665   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0924 08:57:16.437272   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/dashboard-ns.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrole.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-configmap.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-dp.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-role.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-rolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-sa.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-secret.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-svc.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:16.437320   21492 retry.go:31] will retry after 14.977849848s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/dashboard-ns.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrole.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-configmap.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-dp.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-role.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-rolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-sa.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-secret.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-svc.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:16.911077   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:17.411032   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:17.911173   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:18.411125   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:18.911507   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:19.411163   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:19.911225   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:20.410583   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:20.910851   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:21.410732   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:21.910761   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:22.411116   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:22.911296   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:23.411165   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:23.911189   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:24.226650   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
I0924 08:57:24.395958   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
I0924 08:57:24.411153   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0924 08:57:24.412067   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:24.412105   21492 retry.go:31] will retry after 10.69377476s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
W0924 08:57:24.564091   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:24.564155   21492 retry.go:31] will retry after 19.21436726s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:24.910939   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:25.410739   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:25.911368   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:26.410601   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:26.911191   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:27.290162   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml
I0924 08:57:27.411056   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0924 08:57:27.468697   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/metrics-apiservice.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-deployment.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-rbac.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-service.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:27.468742   21492 retry.go:31] will retry after 15.778066437s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/metrics-apiservice.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-deployment.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-rbac.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-service.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:27.911123   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:28.411172   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:28.910889   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:29.411033   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:29.910694   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:30.411021   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:30.910505   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:31.411323   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:31.416039   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml
W0924 08:57:31.627166   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/dashboard-ns.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrole.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-configmap.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-dp.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-role.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-rolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-sa.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-secret.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-svc.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:31.627208   21492 retry.go:31] will retry after 20.886886319s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/dashboard-ns.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrole.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-configmap.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-dp.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-role.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-rolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-sa.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-secret.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-svc.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:31.910694   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:32.411110   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:32.911200   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:33.410652   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:33.910875   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:34.410934   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:34.911101   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:35.106745   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
W0924 08:57:35.287913   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:35.287957   21492 retry.go:31] will retry after 20.359564406s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:35.411217   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:35.910850   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:36.411193   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:36.911531   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:37.411207   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:37.911135   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:38.411390   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:38.911143   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:39.411045   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:39.910649   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:40.411271   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:40.911667   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:41.410991   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:41.910740   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:42.411208   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:42.911177   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:43.248059   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml
I0924 08:57:43.411123   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0924 08:57:43.427272   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/metrics-apiservice.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-deployment.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-rbac.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-service.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:43.427321   21492 retry.go:31] will retry after 16.337835529s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/metrics-apiservice.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-deployment.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-rbac.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-service.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:43.779886   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
I0924 08:57:43.910932   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0924 08:57:43.952171   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:43.952213   21492 retry.go:31] will retry after 30.063655416s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:44.410862   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:44.911233   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:45.410983   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:45.910697   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:46.411210   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:46.911211   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:47.410980   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:47.911161   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:48.410967   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:48.910873   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:49.410640   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:49.911429   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:50.411198   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:50.911143   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:51.411249   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 08:57:51.478055   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 08:57:51.478282   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 08:57:51.541331   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 08:57:51.541511   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 08:57:51.594552   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 08:57:51.594714   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 08:57:51.646463   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 08:57:51.646658   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 08:57:51.700287   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 08:57:51.700555   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 08:57:51.758301   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 08:57:51.758478   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 08:57:51.809977   21492 logs.go:276] 0 containers: []
W0924 08:57:51.812928   21492 logs.go:278] No container was found matching "kindnet"
I0924 08:57:51.813154   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 08:57:51.894567   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 08:57:51.894808   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 08:57:51.951127   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 08:57:51.951187   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 08:57:51.951223   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 08:57:52.155299   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:27:52.132899    3277 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:27:52.135337    3277 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:27:52.137467    3277 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:27:52.140479    3277 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:27:52.143854    3277 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:27:52.132899    3277 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:27:52.135337    3277 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:27:52.137467    3277 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:27:52.140479    3277 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:27:52.143854    3277 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 08:57:52.155332   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 08:57:52.155363   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 08:57:52.244962   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 08:57:52.245000   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 08:57:52.311531   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 08:57:52.311562   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 08:57:52.422315   21492 logs.go:123] Gathering logs for Docker ...
I0924 08:57:52.422348   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 08:57:52.494796   21492 logs.go:123] Gathering logs for dmesg ...
I0924 08:57:52.494840   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 08:57:52.514836   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml
I0924 08:57:52.588002   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 08:57:52.588039   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
W0924 08:57:52.702867   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/dashboard-ns.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrole.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-configmap.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-dp.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-role.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-rolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-sa.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-secret.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-svc.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:52.702905   21492 retry.go:31] will retry after 46.017113529s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/dashboard-ns.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrole.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-configmap.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-dp.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-role.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-rolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-sa.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-secret.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-svc.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:52.777750   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 08:57:52.777791   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 08:57:52.833516   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 08:57:52.833547   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 08:57:52.886600   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 08:57:52.886633   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 08:57:52.937226   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 08:57:52.937253   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 08:57:52.982974   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 08:57:52.983007   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 08:57:53.038898   21492 logs.go:123] Gathering logs for kubelet ...
I0924 08:57:53.038933   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 08:57:53.162174   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 08:57:53.162203   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 08:57:53.377357   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 08:57:53.377382   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 08:57:53.430443   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 08:57:53.430469   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 08:57:53.528873   21492 logs.go:123] Gathering logs for container status ...
I0924 08:57:53.528906   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 08:57:53.647179   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 08:57:53.647204   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 08:57:53.720973   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 08:57:53.720997   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 08:57:55.648630   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
W0924 08:57:55.805027   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:55.805082   21492 retry.go:31] will retry after 43.670494896s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:56.266952   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:57:56.298361   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 08:57:56.346703   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 08:57:56.346894   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 08:57:56.400869   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 08:57:56.401058   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 08:57:56.452532   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 08:57:56.452711   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 08:57:56.513213   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 08:57:56.513414   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 08:57:56.562036   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 08:57:56.562186   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 08:57:56.612287   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 08:57:56.612478   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 08:57:56.660347   21492 logs.go:276] 0 containers: []
W0924 08:57:56.660376   21492 logs.go:278] No container was found matching "kindnet"
I0924 08:57:56.660486   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 08:57:56.709173   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 08:57:56.709307   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 08:57:56.758593   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 08:57:56.758632   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 08:57:56.758650   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 08:57:56.839276   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 08:57:56.839304   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 08:57:56.910848   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 08:57:56.910881   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 08:57:56.965427   21492 logs.go:123] Gathering logs for dmesg ...
I0924 08:57:56.965453   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 08:57:57.045443   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 08:57:57.045467   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 08:57:57.240102   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:27:57.220818    3737 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:27:57.223480    3737 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:27:57.225899    3737 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:27:57.228104    3737 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:27:57.230399    3737 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:27:57.220818    3737 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:27:57.223480    3737 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:27:57.225899    3737 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:27:57.228104    3737 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:27:57.230399    3737 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 08:57:57.240122   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 08:57:57.240143   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 08:57:57.300712   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 08:57:57.300741   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 08:57:57.414086   21492 logs.go:123] Gathering logs for container status ...
I0924 08:57:57.414130   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 08:57:57.552441   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 08:57:57.552472   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 08:57:57.694686   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 08:57:57.694714   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 08:57:57.750086   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 08:57:57.750129   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 08:57:57.821493   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 08:57:57.821523   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 08:57:57.872465   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 08:57:57.872495   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 08:57:58.078094   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 08:57:58.078119   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 08:57:58.120992   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 08:57:58.121015   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 08:57:58.203435   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 08:57:58.203457   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 08:57:58.243660   21492 logs.go:123] Gathering logs for Docker ...
I0924 08:57:58.243684   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 08:57:58.296628   21492 logs.go:123] Gathering logs for kubelet ...
I0924 08:57:58.296650   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 08:57:58.435299   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 08:57:58.435334   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 08:57:59.766157   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml
W0924 08:57:59.941017   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/metrics-apiservice.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-deployment.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-rbac.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-service.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:57:59.941071   21492 retry.go:31] will retry after 47.522724863s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/metrics-apiservice.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-deployment.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-rbac.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-service.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:58:01.008334   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:58:01.042061   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 08:58:01.095168   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 08:58:01.095308   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 08:58:01.146586   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 08:58:01.146745   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 08:58:01.196643   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 08:58:01.196847   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 08:58:01.247445   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 08:58:01.247603   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 08:58:01.298032   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 08:58:01.298193   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 08:58:01.345745   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 08:58:01.345954   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 08:58:01.393971   21492 logs.go:276] 0 containers: []
W0924 08:58:01.394001   21492 logs.go:278] No container was found matching "kindnet"
I0924 08:58:01.394110   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 08:58:01.442962   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 08:58:01.443107   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 08:58:01.494348   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 08:58:01.494397   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 08:58:01.494417   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 08:58:01.707598   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 08:58:01.707628   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 08:58:01.759652   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 08:58:01.759679   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 08:58:01.852626   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 08:58:01.852651   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 08:58:01.919087   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 08:58:01.919117   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 08:58:02.064010   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 08:58:02.064040   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 08:58:02.115369   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 08:58:02.115401   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 08:58:02.171023   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 08:58:02.171049   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 08:58:02.225304   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 08:58:02.225328   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 08:58:02.323154   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 08:58:02.323183   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 08:58:02.370508   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 08:58:02.370532   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 08:58:02.418297   21492 logs.go:123] Gathering logs for container status ...
I0924 08:58:02.418329   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 08:58:02.536259   21492 logs.go:123] Gathering logs for kubelet ...
I0924 08:58:02.536285   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 08:58:02.651088   21492 logs.go:123] Gathering logs for dmesg ...
I0924 08:58:02.651112   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 08:58:02.730693   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 08:58:02.730728   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 08:58:02.913449   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:28:02.893293    4249 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:02.895649    4249 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:02.898006    4249 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:02.900498    4249 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:02.903051    4249 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:28:02.893293    4249 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:02.895649    4249 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:02.898006    4249 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:02.900498    4249 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:02.903051    4249 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 08:58:02.913494   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 08:58:02.913523   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 08:58:03.050145   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 08:58:03.050195   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 08:58:03.117070   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 08:58:03.117101   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 08:58:03.176844   21492 logs.go:123] Gathering logs for Docker ...
I0924 08:58:03.176885   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 08:58:05.739096   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:58:05.774887   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 08:58:05.835361   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 08:58:05.835513   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 08:58:05.885076   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 08:58:05.885236   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 08:58:05.938538   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 08:58:05.938714   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 08:58:06.019455   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 08:58:06.019640   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 08:58:06.069108   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 08:58:06.069281   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 08:58:06.127469   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 08:58:06.127660   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 08:58:06.178469   21492 logs.go:276] 0 containers: []
W0924 08:58:06.178498   21492 logs.go:278] No container was found matching "kindnet"
I0924 08:58:06.178650   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 08:58:06.229130   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 08:58:06.229305   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 08:58:06.279681   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 08:58:06.279729   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 08:58:06.279757   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 08:58:06.336874   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 08:58:06.336903   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 08:58:06.394802   21492 logs.go:123] Gathering logs for kubelet ...
I0924 08:58:06.394834   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 08:58:06.555706   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 08:58:06.555739   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 08:58:06.732560   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:28:06.712095    4491 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:06.714505    4491 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:06.718736    4491 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:06.720997    4491 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:06.723305    4491 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:28:06.712095    4491 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:06.714505    4491 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:06.718736    4491 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:06.720997    4491 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:06.723305    4491 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 08:58:06.732581   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 08:58:06.732603   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 08:58:06.814914   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 08:58:06.814945   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 08:58:06.884910   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 08:58:06.884937   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 08:58:06.998861   21492 logs.go:123] Gathering logs for dmesg ...
I0924 08:58:06.998886   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 08:58:07.081810   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 08:58:07.081836   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 08:58:07.130883   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 08:58:07.130910   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 08:58:07.194487   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 08:58:07.194517   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 08:58:07.259032   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 08:58:07.259071   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 08:58:07.370251   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 08:58:07.370292   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 08:58:07.421595   21492 logs.go:123] Gathering logs for container status ...
I0924 08:58:07.421621   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 08:58:07.518884   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 08:58:07.518912   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 08:58:07.711500   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 08:58:07.711532   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 08:58:07.784379   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 08:58:07.784458   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 08:58:07.843342   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 08:58:07.843376   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 08:58:07.948490   21492 logs.go:123] Gathering logs for Docker ...
I0924 08:58:07.948518   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 08:58:10.510552   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:58:10.539056   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 08:58:10.586233   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 08:58:10.586417   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 08:58:10.632058   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 08:58:10.632203   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 08:58:10.687117   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 08:58:10.687283   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 08:58:10.740757   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 08:58:10.740925   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 08:58:10.801026   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 08:58:10.801208   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 08:58:10.856337   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 08:58:10.856531   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 08:58:10.904997   21492 logs.go:276] 0 containers: []
W0924 08:58:10.905036   21492 logs.go:278] No container was found matching "kindnet"
I0924 08:58:10.905180   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 08:58:10.955557   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 08:58:10.955719   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 08:58:11.001234   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 08:58:11.001288   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 08:58:11.001316   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 08:58:11.176444   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:28:11.157248    4832 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:11.159678    4832 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:11.163393    4832 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:11.165795    4832 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:11.167981    4832 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:28:11.157248    4832 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:11.159678    4832 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:11.163393    4832 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:11.165795    4832 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:11.167981    4832 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 08:58:11.176471   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 08:58:11.176493   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 08:58:11.274332   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 08:58:11.274366   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 08:58:11.332220   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 08:58:11.332253   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 08:58:11.437013   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 08:58:11.437041   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 08:58:11.512171   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 08:58:11.512202   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 08:58:11.572211   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 08:58:11.572243   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 08:58:11.627545   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 08:58:11.627576   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 08:58:11.776840   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 08:58:11.776871   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 08:58:11.838497   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 08:58:11.838531   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 08:58:11.890071   21492 logs.go:123] Gathering logs for Docker ...
I0924 08:58:11.890097   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 08:58:11.950402   21492 logs.go:123] Gathering logs for container status ...
I0924 08:58:11.950426   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 08:58:12.072434   21492 logs.go:123] Gathering logs for kubelet ...
I0924 08:58:12.072468   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 08:58:12.203003   21492 logs.go:123] Gathering logs for dmesg ...
I0924 08:58:12.203028   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 08:58:12.272240   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 08:58:12.272271   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 08:58:12.448721   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 08:58:12.448744   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 08:58:12.496418   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 08:58:12.496443   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 08:58:12.545544   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 08:58:12.545568   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 08:58:12.596538   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 08:58:12.596575   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 08:58:14.016522   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
W0924 08:58:14.257177   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:58:14.257227   21492 retry.go:31] will retry after 34.244848212s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:58:15.220738   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:58:15.260034   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 08:58:15.313070   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 08:58:15.313235   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 08:58:15.365953   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 08:58:15.366090   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 08:58:15.416053   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 08:58:15.416205   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 08:58:15.464846   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 08:58:15.465023   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 08:58:15.522995   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 08:58:15.523157   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 08:58:15.572421   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 08:58:15.572589   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 08:58:15.621965   21492 logs.go:276] 0 containers: []
W0924 08:58:15.622009   21492 logs.go:278] No container was found matching "kindnet"
I0924 08:58:15.622173   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 08:58:15.674512   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 08:58:15.674677   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 08:58:15.725032   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 08:58:15.725090   21492 logs.go:123] Gathering logs for dmesg ...
I0924 08:58:15.725119   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 08:58:15.812160   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 08:58:15.812192   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 08:58:15.899564   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 08:58:15.899598   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 08:58:16.022237   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 08:58:16.022279   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 08:58:16.158657   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 08:58:16.158689   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 08:58:16.218247   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 08:58:16.218277   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 08:58:16.333382   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 08:58:16.333406   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 08:58:16.385349   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 08:58:16.385376   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 08:58:16.433029   21492 logs.go:123] Gathering logs for kubelet ...
I0924 08:58:16.433057   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 08:58:16.553918   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 08:58:16.553941   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 08:58:16.705431   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:28:16.688274    5315 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:16.690472    5315 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:16.692549    5315 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:16.694671    5315 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:16.696903    5315 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:28:16.688274    5315 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:16.690472    5315 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:16.692549    5315 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:16.694671    5315 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:16.696903    5315 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 08:58:16.705451   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 08:58:16.705474   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 08:58:16.879154   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 08:58:16.879177   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 08:58:16.927328   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 08:58:16.927357   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 08:58:16.986980   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 08:58:16.987017   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 08:58:17.047533   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 08:58:17.047561   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 08:58:17.096053   21492 logs.go:123] Gathering logs for container status ...
I0924 08:58:17.096078   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 08:58:17.199273   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 08:58:17.199297   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 08:58:17.263204   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 08:58:17.263247   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 08:58:17.353700   21492 logs.go:123] Gathering logs for Docker ...
I0924 08:58:17.353727   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 08:58:19.910909   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:58:19.942635   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 08:58:19.992861   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 08:58:19.993053   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 08:58:20.050846   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 08:58:20.051001   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 08:58:20.100801   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 08:58:20.100975   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 08:58:20.156387   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 08:58:20.156526   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 08:58:20.206363   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 08:58:20.206520   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 08:58:20.255890   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 08:58:20.256056   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 08:58:20.302199   21492 logs.go:276] 0 containers: []
W0924 08:58:20.302234   21492 logs.go:278] No container was found matching "kindnet"
I0924 08:58:20.302344   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 08:58:20.349505   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 08:58:20.349637   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 08:58:20.397053   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 08:58:20.397104   21492 logs.go:123] Gathering logs for kubelet ...
I0924 08:58:20.397125   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 08:58:20.530049   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 08:58:20.530079   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 08:58:20.694939   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:28:20.673945    5594 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:20.676603    5594 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:20.678850    5594 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:20.681384    5594 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:20.683810    5594 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:28:20.673945    5594 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:20.676603    5594 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:20.678850    5594 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:20.681384    5594 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:20.683810    5594 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 08:58:20.694963   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 08:58:20.694993   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 08:58:20.924278   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 08:58:20.924305   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 08:58:20.970070   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 08:58:20.970095   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 08:58:21.024890   21492 logs.go:123] Gathering logs for Docker ...
I0924 08:58:21.024919   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 08:58:21.085063   21492 logs.go:123] Gathering logs for container status ...
I0924 08:58:21.085090   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 08:58:21.186294   21492 logs.go:123] Gathering logs for dmesg ...
I0924 08:58:21.186328   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 08:58:21.263080   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 08:58:21.263120   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 08:58:21.342265   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 08:58:21.342293   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 08:58:21.391048   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 08:58:21.391072   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 08:58:21.437836   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 08:58:21.437862   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 08:58:21.528418   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 08:58:21.528445   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 08:58:21.622331   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 08:58:21.622357   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 08:58:21.700306   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 08:58:21.700338   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 08:58:21.825166   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 08:58:21.825203   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 08:58:21.869514   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 08:58:21.869542   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 08:58:21.913032   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 08:58:21.913056   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 08:58:21.959751   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 08:58:21.959786   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 08:58:24.509294   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:58:24.540576   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 08:58:24.593575   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 08:58:24.593737   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 08:58:24.642186   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 08:58:24.642335   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 08:58:24.690264   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 08:58:24.690409   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 08:58:24.741183   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 08:58:24.741338   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 08:58:24.790096   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 08:58:24.790247   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 08:58:24.840308   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 08:58:24.840484   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 08:58:24.888466   21492 logs.go:276] 0 containers: []
W0924 08:58:24.888497   21492 logs.go:278] No container was found matching "kindnet"
I0924 08:58:24.888625   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 08:58:24.937900   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 08:58:24.938053   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 08:58:24.986735   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 08:58:24.986804   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 08:58:24.986830   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 08:58:25.045521   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 08:58:25.045550   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 08:58:25.107355   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 08:58:25.107385   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 08:58:25.165934   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 08:58:25.165966   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 08:58:25.242330   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 08:58:25.242364   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 08:58:25.318733   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 08:58:25.318787   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 08:58:25.382021   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 08:58:25.382052   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 08:58:25.491477   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 08:58:25.491510   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 08:58:25.547836   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 08:58:25.547867   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 08:58:25.638098   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 08:58:25.638131   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 08:58:25.722062   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 08:58:25.722107   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 08:58:25.850339   21492 logs.go:123] Gathering logs for container status ...
I0924 08:58:25.850366   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 08:58:25.971089   21492 logs.go:123] Gathering logs for dmesg ...
I0924 08:58:25.971131   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 08:58:26.060665   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 08:58:26.060694   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 08:58:26.260145   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:28:26.236352    6128 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:26.239252    6128 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:26.243599    6128 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:26.246228    6128 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:26.249215    6128 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:28:26.236352    6128 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:26.239252    6128 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:26.243599    6128 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:26.246228    6128 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:26.249215    6128 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 08:58:26.260179   21492 logs.go:123] Gathering logs for Docker ...
I0924 08:58:26.260209   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 08:58:26.341572   21492 logs.go:123] Gathering logs for kubelet ...
I0924 08:58:26.341600   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 08:58:26.453201   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 08:58:26.453226   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 08:58:26.625979   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 08:58:26.626010   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 08:58:26.723383   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 08:58:26.723413   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 08:58:29.274173   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:58:29.306866   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 08:58:29.359704   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 08:58:29.359884   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 08:58:29.412186   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 08:58:29.412341   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 08:58:29.462643   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 08:58:29.462864   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 08:58:29.515847   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 08:58:29.516029   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 08:58:29.569050   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 08:58:29.569234   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 08:58:29.623342   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 08:58:29.623511   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 08:58:29.676150   21492 logs.go:276] 0 containers: []
W0924 08:58:29.676182   21492 logs.go:278] No container was found matching "kindnet"
I0924 08:58:29.676312   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 08:58:29.732745   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 08:58:29.732921   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 08:58:29.793821   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 08:58:29.793875   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 08:58:29.793900   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 08:58:29.852046   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 08:58:29.852075   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 08:58:29.941438   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 08:58:29.941477   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 08:58:30.008811   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 08:58:30.008848   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 08:58:30.067737   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 08:58:30.067816   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 08:58:30.132030   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 08:58:30.132062   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 08:58:30.211706   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 08:58:30.211736   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 08:58:30.269085   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 08:58:30.269128   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 08:58:30.328277   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 08:58:30.328310   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 08:58:30.436139   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 08:58:30.436168   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 08:58:30.487193   21492 logs.go:123] Gathering logs for container status ...
I0924 08:58:30.487221   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 08:58:30.609917   21492 logs.go:123] Gathering logs for dmesg ...
I0924 08:58:30.609945   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 08:58:30.701734   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 08:58:30.701767   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 08:58:30.908220   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:28:30.885107    6494 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:30.888216    6494 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:30.890763    6494 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:30.893377    6494 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:30.896160    6494 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:28:30.885107    6494 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:30.888216    6494 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:30.890763    6494 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:30.893377    6494 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:30.896160    6494 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 08:58:30.908247   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 08:58:30.908277   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 08:58:31.166236   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 08:58:31.166266   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 08:58:31.292880   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 08:58:31.292922   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 08:58:31.406928   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 08:58:31.406960   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 08:58:31.454924   21492 logs.go:123] Gathering logs for Docker ...
I0924 08:58:31.454950   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 08:58:31.507827   21492 logs.go:123] Gathering logs for kubelet ...
I0924 08:58:31.507850   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 08:58:34.110585   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:58:34.145086   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 08:58:34.199822   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 08:58:34.199998   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 08:58:34.257044   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 08:58:34.257226   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 08:58:34.309310   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 08:58:34.309495   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 08:58:34.383380   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 08:58:34.383518   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 08:58:34.433095   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 08:58:34.433235   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 08:58:34.482495   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 08:58:34.482645   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 08:58:34.530070   21492 logs.go:276] 0 containers: []
W0924 08:58:34.530101   21492 logs.go:278] No container was found matching "kindnet"
I0924 08:58:34.530230   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 08:58:34.580587   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 08:58:34.580727   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 08:58:34.631054   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 08:58:34.631096   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 08:58:34.631114   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 08:58:34.805240   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:28:34.784892    6715 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:34.787605    6715 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:34.791748    6715 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:34.794111    6715 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:34.796383    6715 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:28:34.784892    6715 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:34.787605    6715 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:34.791748    6715 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:34.794111    6715 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:34.796383    6715 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 08:58:34.805261   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 08:58:34.805282   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 08:58:34.873202   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 08:58:34.873228   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 08:58:34.933205   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 08:58:34.933247   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 08:58:35.064091   21492 logs.go:123] Gathering logs for dmesg ...
I0924 08:58:35.064126   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 08:58:35.146460   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 08:58:35.146489   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 08:58:35.257228   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 08:58:35.257258   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 08:58:35.305948   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 08:58:35.305976   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 08:58:35.411357   21492 logs.go:123] Gathering logs for kubelet ...
I0924 08:58:35.411384   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 08:58:35.526053   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 08:58:35.526077   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 08:58:35.573497   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 08:58:35.573522   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 08:58:35.620481   21492 logs.go:123] Gathering logs for Docker ...
I0924 08:58:35.620511   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 08:58:35.679281   21492 logs.go:123] Gathering logs for container status ...
I0924 08:58:35.679307   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 08:58:35.772059   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 08:58:35.772085   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 08:58:36.023923   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 08:58:36.023971   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 08:58:36.112211   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 08:58:36.112241   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 08:58:36.181094   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 08:58:36.181124   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 08:58:36.235511   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 08:58:36.235539   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 08:58:36.284259   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 08:58:36.284285   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 08:58:38.721188   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml
I0924 08:58:38.832812   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0924 08:58:38.895151   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/dashboard-ns.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrole.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-configmap.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-dp.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-role.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-rolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-sa.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-secret.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-svc.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:58:38.895254   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
W0924 08:58:38.895384   21492 out.go:270] ‚ùó  Enabling 'dashboard' returned an error: running callbacks: [sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/dashboard-ns.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrole.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-clusterrolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-configmap.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-dp.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-role.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-rolebinding.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-sa.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-secret.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/dashboard-svc.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
]
I0924 08:58:38.956582   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 08:58:38.956768   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 08:58:39.026652   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 08:58:39.026894   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 08:58:39.091166   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 08:58:39.091409   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 08:58:39.145548   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 08:58:39.145691   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 08:58:39.195427   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 08:58:39.195579   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 08:58:39.245661   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 08:58:39.245838   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 08:58:39.290256   21492 logs.go:276] 0 containers: []
W0924 08:58:39.290283   21492 logs.go:278] No container was found matching "kindnet"
I0924 08:58:39.290393   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 08:58:39.334209   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 08:58:39.334366   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 08:58:39.381638   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 08:58:39.381679   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 08:58:39.381697   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 08:58:39.443788   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 08:58:39.443831   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 08:58:39.476679   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
I0924 08:58:39.508619   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 08:58:39.508667   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
W0924 08:58:39.656082   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
W0924 08:58:39.656239   21492 out.go:270] ‚ùó  Enabling 'default-storageclass' returned an error: running callbacks: [sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
]
I0924 08:58:39.659017   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 08:58:39.659045   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 08:58:39.765233   21492 logs.go:123] Gathering logs for Docker ...
I0924 08:58:39.765261   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 08:58:39.820596   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 08:58:39.820625   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 08:58:39.903275   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 08:58:39.903305   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 08:58:40.062270   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:28:40.045382    7181 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:40.047737    7181 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:40.049699    7181 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:40.051636    7181 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:40.053876    7181 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:28:40.045382    7181 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:40.047737    7181 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:40.049699    7181 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:40.051636    7181 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:40.053876    7181 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 08:58:40.062316   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 08:58:40.062344   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 08:58:40.265689   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 08:58:40.265718   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 08:58:40.329643   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 08:58:40.329668   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 08:58:40.379414   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 08:58:40.379439   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 08:58:40.443279   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 08:58:40.443314   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 08:58:40.504880   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 08:58:40.504915   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 08:58:40.559882   21492 logs.go:123] Gathering logs for kubelet ...
I0924 08:58:40.559909   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 08:58:40.683551   21492 logs.go:123] Gathering logs for container status ...
I0924 08:58:40.683575   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 08:58:40.781986   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 08:58:40.782014   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 08:58:40.829596   21492 logs.go:123] Gathering logs for dmesg ...
I0924 08:58:40.829623   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 08:58:40.895304   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 08:58:40.895326   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 08:58:40.986018   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 08:58:40.986041   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 08:58:43.592208   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:58:43.622937   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 08:58:43.673912   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 08:58:43.674080   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 08:58:43.729129   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 08:58:43.729370   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 08:58:43.784534   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 08:58:43.784722   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 08:58:43.834165   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 08:58:43.834305   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 08:58:43.882509   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 08:58:43.882701   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 08:58:43.932219   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 08:58:43.932391   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 08:58:43.981146   21492 logs.go:276] 0 containers: []
W0924 08:58:43.981182   21492 logs.go:278] No container was found matching "kindnet"
I0924 08:58:43.981306   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 08:58:44.035107   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 08:58:44.035288   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 08:58:44.107679   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 08:58:44.107740   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 08:58:44.107791   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 08:58:44.256139   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 08:58:44.256181   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 08:58:44.315294   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 08:58:44.315329   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 08:58:44.411767   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 08:58:44.411808   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 08:58:44.467320   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 08:58:44.467346   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 08:58:44.519003   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 08:58:44.519036   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 08:58:44.569229   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 08:58:44.569283   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 08:58:44.620983   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 08:58:44.621011   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 08:58:44.726273   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 08:58:44.726307   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 08:58:44.785560   21492 logs.go:123] Gathering logs for Docker ...
I0924 08:58:44.785591   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 08:58:44.849711   21492 logs.go:123] Gathering logs for dmesg ...
I0924 08:58:44.849736   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 08:58:44.918046   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 08:58:44.918067   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 08:58:44.969808   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 08:58:44.969837   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 08:58:45.157438   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 08:58:45.157463   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 08:58:45.207488   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 08:58:45.207515   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 08:58:45.277527   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 08:58:45.277555   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 08:58:45.400268   21492 logs.go:123] Gathering logs for container status ...
I0924 08:58:45.400295   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 08:58:45.493895   21492 logs.go:123] Gathering logs for kubelet ...
I0924 08:58:45.493920   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 08:58:45.606538   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 08:58:45.606569   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 08:58:45.768368   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:28:45.743541    7693 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:45.746338    7693 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:45.748714    7693 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:45.751300    7693 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:45.755870    7693 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:28:45.743541    7693 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:45.746338    7693 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:45.748714    7693 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:45.751300    7693 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:45.755870    7693 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 08:58:47.464818   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml
W0924 08:58:47.648542   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/metrics-apiservice.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-deployment.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-rbac.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-service.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:58:47.648590   21492 addons.go:475] Verifying addon metrics-server=true in "minikube"
W0924 08:58:47.648730   21492 out.go:270] ‚ùó  Enabling 'metrics-server' returned an error: running callbacks: [sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml: Process exited with status 1
stdout:

stderr:
error validating "/etc/kubernetes/addons/metrics-apiservice.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-deployment.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-rbac.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
error validating "/etc/kubernetes/addons/metrics-server-service.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
]
I0924 08:58:48.269006   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:58:48.300235   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 08:58:48.353649   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 08:58:48.353890   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 08:58:48.424096   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 08:58:48.424275   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 08:58:48.487135   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 08:58:48.487330   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 08:58:48.502814   21492 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
I0924 08:58:48.547828   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 08:58:48.548040   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
W0924 08:58:48.716010   21492 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0924 08:58:48.716001   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 08:58:48.716166   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
W0924 08:58:48.716187   21492 out.go:270] ‚ùó  Enabling 'storage-provisioner' returned an error: running callbacks: [sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
]
I0924 08:58:48.724506   21492 out.go:177] üåü  Enabled addons: 
I0924 08:58:48.725410   21492 addons.go:510] duration metric: took 1m57.575922206s for enable addons: enabled=[]
I0924 08:58:48.767922   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 08:58:48.768081   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 08:58:48.825918   21492 logs.go:276] 0 containers: []
W0924 08:58:48.825954   21492 logs.go:278] No container was found matching "kindnet"
I0924 08:58:48.826139   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 08:58:48.876177   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 08:58:48.876313   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 08:58:48.927743   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 08:58:48.927813   21492 logs.go:123] Gathering logs for Docker ...
I0924 08:58:48.927835   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 08:58:49.010883   21492 logs.go:123] Gathering logs for container status ...
I0924 08:58:49.010948   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 08:58:49.130375   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 08:58:49.130411   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 08:58:49.208128   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 08:58:49.208160   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 08:58:49.267465   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 08:58:49.267502   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 08:58:49.352789   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 08:58:49.352817   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 08:58:49.471778   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 08:58:49.471832   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 08:58:49.525567   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 08:58:49.525595   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 08:58:49.582160   21492 logs.go:123] Gathering logs for kubelet ...
I0924 08:58:49.582190   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 08:58:49.716997   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 08:58:49.717022   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 08:58:49.874480   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:28:49.858178    7989 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:49.860255    7989 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:49.862306    7989 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:49.864379    7989 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:49.866428    7989 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:28:49.858178    7989 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:49.860255    7989 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:49.862306    7989 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:49.864379    7989 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:49.866428    7989 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 08:58:49.874503   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 08:58:49.874524   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 08:58:49.931161   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 08:58:49.931196   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 08:58:49.994865   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 08:58:49.994906   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 08:58:50.104879   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 08:58:50.104905   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 08:58:50.198482   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 08:58:50.198513   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 08:58:50.246372   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 08:58:50.246399   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 08:58:50.442588   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 08:58:50.442613   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 08:58:50.492599   21492 logs.go:123] Gathering logs for dmesg ...
I0924 08:58:50.492624   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 08:58:50.559479   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 08:58:50.559501   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 08:58:53.107900   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:58:53.142089   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 08:58:53.200994   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 08:58:53.201244   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 08:58:53.258100   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 08:58:53.258280   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 08:58:53.316023   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 08:58:53.316213   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 08:58:53.368669   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 08:58:53.368868   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 08:58:53.427908   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 08:58:53.428070   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 08:58:53.481799   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 08:58:53.481966   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 08:58:53.536022   21492 logs.go:276] 0 containers: []
W0924 08:58:53.536052   21492 logs.go:278] No container was found matching "kindnet"
I0924 08:58:53.536161   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 08:58:53.588682   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 08:58:53.588843   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 08:58:53.644570   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 08:58:53.644614   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 08:58:53.644637   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 08:58:53.707500   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 08:58:53.707530   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 08:58:53.764360   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 08:58:53.764391   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 08:58:53.865650   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 08:58:53.865678   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 08:58:53.918286   21492 logs.go:123] Gathering logs for kubelet ...
I0924 08:58:53.918314   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 08:58:54.053064   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 08:58:54.053092   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 08:58:54.277410   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:28:54.257516    8321 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:54.260242    8321 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:54.262718    8321 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:54.265063    8321 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:54.267383    8321 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:28:54.257516    8321 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:54.260242    8321 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:54.262718    8321 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:54.265063    8321 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:54.267383    8321 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 08:58:54.277445   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 08:58:54.277476   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 08:58:54.357627   21492 logs.go:123] Gathering logs for container status ...
I0924 08:58:54.357655   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 08:58:54.472300   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 08:58:54.472327   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 08:58:54.521839   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 08:58:54.521866   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 08:58:54.571277   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 08:58:54.571302   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 08:58:54.620121   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 08:58:54.620145   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 08:58:54.670781   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 08:58:54.670815   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 08:58:54.717878   21492 logs.go:123] Gathering logs for Docker ...
I0924 08:58:54.717904   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 08:58:54.772858   21492 logs.go:123] Gathering logs for dmesg ...
I0924 08:58:54.772881   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 08:58:54.840289   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 08:58:54.840312   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 08:58:54.906718   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 08:58:54.906742   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 08:58:55.008832   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 08:58:55.008857   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 08:58:55.175188   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 08:58:55.175216   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 08:58:57.785736   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:58:57.818716   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 08:58:57.869246   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 08:58:57.869440   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 08:58:57.922607   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 08:58:57.922803   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 08:58:57.979864   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 08:58:57.980045   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 08:58:58.043950   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 08:58:58.044099   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 08:58:58.094329   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 08:58:58.094472   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 08:58:58.144653   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 08:58:58.144834   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 08:58:58.192326   21492 logs.go:276] 0 containers: []
W0924 08:58:58.192356   21492 logs.go:278] No container was found matching "kindnet"
I0924 08:58:58.192475   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 08:58:58.241235   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 08:58:58.241376   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 08:58:58.290551   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 08:58:58.290600   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 08:58:58.290620   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 08:58:58.384513   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 08:58:58.384562   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 08:58:58.476664   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 08:58:58.476705   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 08:58:58.548692   21492 logs.go:123] Gathering logs for Docker ...
I0924 08:58:58.548758   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 08:58:58.619395   21492 logs.go:123] Gathering logs for container status ...
I0924 08:58:58.619430   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 08:58:58.779491   21492 logs.go:123] Gathering logs for kubelet ...
I0924 08:58:58.779536   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 08:58:58.940050   21492 logs.go:123] Gathering logs for dmesg ...
I0924 08:58:58.940094   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 08:58:59.042480   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 08:58:59.042512   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 08:58:59.127632   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 08:58:59.127661   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 08:58:59.179826   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 08:58:59.179853   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 08:58:59.231239   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 08:58:59.231266   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 08:58:59.295064   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 08:58:59.295094   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 08:58:59.387134   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 08:58:59.387158   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 08:58:59.525282   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:28:59.508535    8771 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:59.510842    8771 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:59.512957    8771 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:59.515087    8771 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:59.517277    8771 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:28:59.508535    8771 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:59.510842    8771 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:59.512957    8771 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:59.515087    8771 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:28:59.517277    8771 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 08:58:59.525305   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 08:58:59.525322   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 08:58:59.711092   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 08:58:59.711117   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 08:58:59.820713   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 08:58:59.820736   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 08:58:59.865184   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 08:58:59.865219   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 08:58:59.914157   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 08:58:59.914182   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 08:59:00.040535   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 08:59:00.040574   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 08:59:02.588453   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:59:02.619312   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 08:59:02.670528   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 08:59:02.670670   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 08:59:02.720714   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 08:59:02.720909   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 08:59:02.770850   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 08:59:02.771028   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 08:59:02.819073   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 08:59:02.819250   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 08:59:02.866867   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 08:59:02.867008   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 08:59:02.921566   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 08:59:02.921793   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 08:59:02.970387   21492 logs.go:276] 0 containers: []
W0924 08:59:02.970420   21492 logs.go:278] No container was found matching "kindnet"
I0924 08:59:02.970563   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 08:59:03.028452   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 08:59:03.028597   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 08:59:03.075922   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 08:59:03.075962   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 08:59:03.075980   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 08:59:03.135959   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 08:59:03.135989   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 08:59:03.194450   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 08:59:03.194480   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 08:59:03.262197   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 08:59:03.262236   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 08:59:03.381276   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 08:59:03.381302   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 08:59:03.506622   21492 logs.go:123] Gathering logs for Docker ...
I0924 08:59:03.506653   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 08:59:03.572086   21492 logs.go:123] Gathering logs for container status ...
I0924 08:59:03.572111   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 08:59:03.677891   21492 logs.go:123] Gathering logs for kubelet ...
I0924 08:59:03.677925   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 08:59:03.799453   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 08:59:03.799477   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 08:59:03.847428   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 08:59:03.847456   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 08:59:03.893430   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 08:59:03.893453   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 08:59:04.042467   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:29:04.026296    9129 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:04.028494    9129 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:04.030505    9129 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:04.032369    9129 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:04.034201    9129 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:29:04.026296    9129 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:04.028494    9129 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:04.030505    9129 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:04.032369    9129 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:04.034201    9129 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 08:59:04.042490   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 08:59:04.042508   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 08:59:04.153765   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 08:59:04.153820   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 08:59:04.262870   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 08:59:04.262913   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 08:59:04.417404   21492 logs.go:123] Gathering logs for dmesg ...
I0924 08:59:04.417440   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 08:59:04.504847   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 08:59:04.504877   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 08:59:04.714951   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 08:59:04.714980   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 08:59:04.774516   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 08:59:04.774543   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 08:59:04.830228   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 08:59:04.830263   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 08:59:07.379087   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:59:07.410918   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 08:59:07.469888   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 08:59:07.470028   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 08:59:07.519965   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 08:59:07.520103   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 08:59:07.568516   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 08:59:07.568673   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 08:59:07.614966   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 08:59:07.615088   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 08:59:07.666602   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 08:59:07.666813   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 08:59:07.722631   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 08:59:07.722792   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 08:59:07.806986   21492 logs.go:276] 0 containers: []
W0924 08:59:07.807016   21492 logs.go:278] No container was found matching "kindnet"
I0924 08:59:07.807140   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 08:59:07.860224   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 08:59:07.860402   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 08:59:07.912041   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 08:59:07.912085   21492 logs.go:123] Gathering logs for dmesg ...
I0924 08:59:07.912104   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 08:59:08.003152   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 08:59:08.003179   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 08:59:08.173826   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:29:08.154720    9393 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:08.158174    9393 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:08.160681    9393 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:08.162636    9393 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:08.164870    9393 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:29:08.154720    9393 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:08.158174    9393 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:08.160681    9393 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:08.162636    9393 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:08.164870    9393 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 08:59:08.173850   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 08:59:08.173876   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 08:59:08.229692   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 08:59:08.229722   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 08:59:08.281897   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 08:59:08.281923   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 08:59:08.420022   21492 logs.go:123] Gathering logs for kubelet ...
I0924 08:59:08.420067   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 08:59:08.599707   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 08:59:08.599747   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 08:59:08.656037   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 08:59:08.656084   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 08:59:08.725904   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 08:59:08.725944   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 08:59:08.807921   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 08:59:08.807954   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 08:59:08.916576   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 08:59:08.916601   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 08:59:08.963058   21492 logs.go:123] Gathering logs for container status ...
I0924 08:59:08.963085   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 08:59:09.059015   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 08:59:09.059039   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 08:59:09.102635   21492 logs.go:123] Gathering logs for Docker ...
I0924 08:59:09.102658   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 08:59:09.155933   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 08:59:09.155957   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 08:59:09.320814   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 08:59:09.320847   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 08:59:09.384768   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 08:59:09.384801   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 08:59:09.428138   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 08:59:09.428161   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 08:59:09.474300   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 08:59:09.474338   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 08:59:12.060103   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:59:12.090540   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 08:59:12.138684   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 08:59:12.138890   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 08:59:12.186958   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 08:59:12.187139   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 08:59:12.232564   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 08:59:12.232716   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 08:59:12.277844   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 08:59:12.277970   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 08:59:12.326296   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 08:59:12.326452   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 08:59:12.378212   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 08:59:12.378386   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 08:59:12.427176   21492 logs.go:276] 0 containers: []
W0924 08:59:12.427206   21492 logs.go:278] No container was found matching "kindnet"
I0924 08:59:12.427332   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 08:59:12.476929   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 08:59:12.477111   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 08:59:12.532664   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 08:59:12.532709   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 08:59:12.532729   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 08:59:12.595056   21492 logs.go:123] Gathering logs for kubelet ...
I0924 08:59:12.595095   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 08:59:12.741352   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 08:59:12.741385   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 08:59:12.944610   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 08:59:12.944635   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 08:59:12.992363   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 08:59:12.992390   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 08:59:13.048265   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 08:59:13.048293   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 08:59:13.142451   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 08:59:13.142476   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 08:59:13.234971   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 08:59:13.234998   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 08:59:13.279408   21492 logs.go:123] Gathering logs for Docker ...
I0924 08:59:13.279432   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 08:59:13.337907   21492 logs.go:123] Gathering logs for dmesg ...
I0924 08:59:13.337931   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 08:59:13.406039   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 08:59:13.406066   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 08:59:13.494498   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 08:59:13.494528   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 08:59:13.574896   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 08:59:13.574924   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 08:59:13.677078   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 08:59:13.677102   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 08:59:13.720324   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 08:59:13.720346   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 08:59:13.767898   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 08:59:13.767924   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 08:59:13.909559   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:29:13.893060    9944 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:13.895341    9944 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:13.897484    9944 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:13.899473    9944 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:13.901597    9944 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:29:13.893060    9944 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:13.895341    9944 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:13.897484    9944 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:13.899473    9944 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:13.901597    9944 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 08:59:13.909576   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 08:59:13.909593   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 08:59:13.954137   21492 logs.go:123] Gathering logs for container status ...
I0924 08:59:13.954162   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 08:59:14.055682   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 08:59:14.055722   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 08:59:16.630881   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:59:16.659103   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 08:59:16.703882   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 08:59:16.704029   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 08:59:16.747461   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 08:59:16.747584   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 08:59:16.791312   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 08:59:16.791465   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 08:59:16.836639   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 08:59:16.836838   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 08:59:16.881480   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 08:59:16.881604   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 08:59:16.925440   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 08:59:16.925589   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 08:59:16.974752   21492 logs.go:276] 0 containers: []
W0924 08:59:16.974809   21492 logs.go:278] No container was found matching "kindnet"
I0924 08:59:16.974952   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 08:59:17.023425   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 08:59:17.023549   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 08:59:17.072017   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 08:59:17.072058   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 08:59:17.072079   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 08:59:17.141915   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 08:59:17.141943   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 08:59:17.205166   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 08:59:17.205196   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 08:59:17.323581   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 08:59:17.323611   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 08:59:17.371225   21492 logs.go:123] Gathering logs for container status ...
I0924 08:59:17.371250   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 08:59:17.483383   21492 logs.go:123] Gathering logs for kubelet ...
I0924 08:59:17.483413   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 08:59:17.621076   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 08:59:17.621101   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 08:59:17.778935   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:29:17.749687   10222 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:17.758484   10222 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:17.761559   10222 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:17.764328   10222 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:17.766838   10222 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:29:17.749687   10222 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:17.758484   10222 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:17.761559   10222 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:17.764328   10222 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:17.766838   10222 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 08:59:17.778964   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 08:59:17.778997   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 08:59:17.846375   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 08:59:17.846415   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 08:59:17.899415   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 08:59:17.899446   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 08:59:18.048489   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 08:59:18.048523   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 08:59:18.103177   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 08:59:18.103202   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 08:59:18.150487   21492 logs.go:123] Gathering logs for Docker ...
I0924 08:59:18.150511   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 08:59:18.207581   21492 logs.go:123] Gathering logs for dmesg ...
I0924 08:59:18.207610   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 08:59:18.273936   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 08:59:18.273963   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 08:59:18.347817   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 08:59:18.347894   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 08:59:18.419880   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 08:59:18.419917   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 08:59:18.534824   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 08:59:18.534867   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 08:59:18.753591   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 08:59:18.753621   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 08:59:21.298481   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:59:21.332004   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 08:59:21.384747   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 08:59:21.384920   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 08:59:21.442536   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 08:59:21.442701   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 08:59:21.492614   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 08:59:21.492797   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 08:59:21.540057   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 08:59:21.540184   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 08:59:21.584793   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 08:59:21.584920   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 08:59:21.629379   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 08:59:21.629507   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 08:59:21.673507   21492 logs.go:276] 0 containers: []
W0924 08:59:21.673535   21492 logs.go:278] No container was found matching "kindnet"
I0924 08:59:21.673648   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 08:59:21.716622   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 08:59:21.716746   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 08:59:21.761255   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 08:59:21.761294   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 08:59:21.761312   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 08:59:21.865493   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 08:59:21.865524   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 08:59:21.914061   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 08:59:21.914085   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 08:59:22.099062   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 08:59:22.099088   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 08:59:22.149796   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 08:59:22.149820   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 08:59:22.205384   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 08:59:22.205426   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 08:59:22.269157   21492 logs.go:123] Gathering logs for Docker ...
I0924 08:59:22.269184   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 08:59:22.330448   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 08:59:22.330474   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 08:59:22.415836   21492 logs.go:123] Gathering logs for kubelet ...
I0924 08:59:22.415869   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 08:59:22.519652   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 08:59:22.519678   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 08:59:22.587263   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 08:59:22.587289   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 08:59:22.650064   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 08:59:22.650093   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 08:59:22.700848   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 08:59:22.700873   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 08:59:22.745106   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 08:59:22.745130   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 08:59:22.789231   21492 logs.go:123] Gathering logs for container status ...
I0924 08:59:22.789253   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 08:59:22.885012   21492 logs.go:123] Gathering logs for dmesg ...
I0924 08:59:22.885035   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 08:59:22.959366   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 08:59:22.959401   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 08:59:23.117205   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:29:23.099847   10715 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:23.101939   10715 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:23.103988   10715 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:23.106662   10715 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:23.108963   10715 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:29:23.099847   10715 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:23.101939   10715 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:23.103988   10715 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:23.106662   10715 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:23.108963   10715 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 08:59:23.117231   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 08:59:23.117257   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 08:59:23.215825   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 08:59:23.215850   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 08:59:25.756623   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:59:25.788178   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 08:59:25.835129   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 08:59:25.835299   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 08:59:25.886812   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 08:59:25.886973   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 08:59:25.942478   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 08:59:25.942677   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 08:59:26.037657   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 08:59:26.037875   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 08:59:26.090236   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 08:59:26.090423   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 08:59:26.142862   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 08:59:26.143019   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 08:59:26.196556   21492 logs.go:276] 0 containers: []
W0924 08:59:26.196594   21492 logs.go:278] No container was found matching "kindnet"
I0924 08:59:26.196745   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 08:59:26.251429   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 08:59:26.251619   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 08:59:26.303935   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 08:59:26.303977   21492 logs.go:123] Gathering logs for container status ...
I0924 08:59:26.304002   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 08:59:26.418690   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 08:59:26.418719   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 08:59:26.471689   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 08:59:26.471717   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 08:59:26.536800   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 08:59:26.536831   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 08:59:26.634379   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 08:59:26.634413   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 08:59:26.761698   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 08:59:26.761734   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 08:59:26.827928   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 08:59:26.827964   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 08:59:26.888295   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 08:59:26.888327   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 08:59:26.948953   21492 logs.go:123] Gathering logs for Docker ...
I0924 08:59:26.948990   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 08:59:27.028198   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 08:59:27.028236   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 08:59:27.193720   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:29:27.176467   11021 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:27.178645   11021 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:27.180610   11021 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:27.182581   11021 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:27.185793   11021 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:29:27.176467   11021 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:27.178645   11021 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:27.180610   11021 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:27.182581   11021 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:27.185793   11021 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 08:59:27.193745   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 08:59:27.193812   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 08:59:27.379808   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 08:59:27.379832   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 08:59:27.471802   21492 logs.go:123] Gathering logs for dmesg ...
I0924 08:59:27.471832   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 08:59:27.537656   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 08:59:27.537679   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 08:59:27.596117   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 08:59:27.596144   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 08:59:27.638114   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 08:59:27.638144   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 08:59:27.747151   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 08:59:27.747188   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 08:59:27.819237   21492 logs.go:123] Gathering logs for kubelet ...
I0924 08:59:27.819273   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 08:59:27.957027   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 08:59:27.957057   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 08:59:30.551460   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:59:30.584759   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 08:59:30.634031   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 08:59:30.634214   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 08:59:30.683260   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 08:59:30.683400   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 08:59:30.735493   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 08:59:30.735656   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 08:59:30.783930   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 08:59:30.784081   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 08:59:30.835111   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 08:59:30.835349   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 08:59:30.885271   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 08:59:30.885451   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 08:59:30.934551   21492 logs.go:276] 0 containers: []
W0924 08:59:30.934581   21492 logs.go:278] No container was found matching "kindnet"
I0924 08:59:30.934689   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 08:59:30.984472   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 08:59:30.984640   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 08:59:31.039042   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 08:59:31.039083   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 08:59:31.039103   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 08:59:31.099985   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 08:59:31.100015   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 08:59:31.159245   21492 logs.go:123] Gathering logs for Docker ...
I0924 08:59:31.159282   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 08:59:31.233848   21492 logs.go:123] Gathering logs for kubelet ...
I0924 08:59:31.233880   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 08:59:31.387398   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 08:59:31.387435   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 08:59:31.551009   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:29:31.532265   11322 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:31.535004   11322 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:31.537262   11322 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:31.539483   11322 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:31.541736   11322 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:29:31.532265   11322 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:31.535004   11322 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:31.537262   11322 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:31.539483   11322 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:31.541736   11322 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 08:59:31.551032   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 08:59:31.551053   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 08:59:31.629677   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 08:59:31.629704   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 08:59:31.750382   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 08:59:31.750413   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 08:59:31.799942   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 08:59:31.799968   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 08:59:31.895546   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 08:59:31.895572   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 08:59:31.942207   21492 logs.go:123] Gathering logs for container status ...
I0924 08:59:31.942236   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 08:59:32.060239   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 08:59:32.060273   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 08:59:32.119251   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 08:59:32.119279   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 08:59:32.186899   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 08:59:32.186944   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 08:59:32.253166   21492 logs.go:123] Gathering logs for dmesg ...
I0924 08:59:32.253198   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 08:59:32.354936   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 08:59:32.354970   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 08:59:32.564832   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 08:59:32.564860   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 08:59:32.639370   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 08:59:32.639401   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 08:59:32.697838   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 08:59:32.697864   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 08:59:35.296747   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:59:35.329230   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 08:59:35.380525   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 08:59:35.380665   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 08:59:35.429435   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 08:59:35.429574   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 08:59:35.478117   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 08:59:35.478271   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 08:59:35.527753   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 08:59:35.527917   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 08:59:35.576233   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 08:59:35.576374   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 08:59:35.626551   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 08:59:35.626700   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 08:59:35.676630   21492 logs.go:276] 0 containers: []
W0924 08:59:35.676669   21492 logs.go:278] No container was found matching "kindnet"
I0924 08:59:35.676859   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 08:59:35.732830   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 08:59:35.733013   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 08:59:35.787231   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 08:59:35.787274   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 08:59:35.787303   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 08:59:35.850922   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 08:59:35.850954   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 08:59:35.906472   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 08:59:35.906498   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 08:59:35.984838   21492 logs.go:123] Gathering logs for kubelet ...
I0924 08:59:35.984893   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 08:59:36.135743   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 08:59:36.135778   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 08:59:36.344900   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 08:59:36.344928   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 08:59:36.414278   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 08:59:36.414306   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 08:59:36.468420   21492 logs.go:123] Gathering logs for Docker ...
I0924 08:59:36.468445   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 08:59:36.525624   21492 logs.go:123] Gathering logs for container status ...
I0924 08:59:36.525651   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 08:59:36.620493   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 08:59:36.620520   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 08:59:36.703849   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 08:59:36.703881   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 08:59:36.837698   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 08:59:36.837726   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 08:59:36.886482   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 08:59:36.886507   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 08:59:36.933175   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 08:59:36.933204   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 08:59:37.020493   21492 logs.go:123] Gathering logs for dmesg ...
I0924 08:59:37.020518   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 08:59:37.085698   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 08:59:37.085720   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 08:59:37.213938   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:29:37.198596   11833 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:37.200693   11833 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:37.202607   11833 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:37.204588   11833 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:37.206639   11833 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:29:37.198596   11833 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:37.200693   11833 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:37.202607   11833 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:37.204588   11833 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:37.206639   11833 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 08:59:37.213953   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 08:59:37.213969   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 08:59:37.259031   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 08:59:37.259059   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 08:59:37.355388   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 08:59:37.355416   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 08:59:39.900236   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:59:39.930897   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 08:59:39.977622   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 08:59:39.977763   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 08:59:40.029223   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 08:59:40.029377   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 08:59:40.078586   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 08:59:40.078807   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 08:59:40.127850   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 08:59:40.127988   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 08:59:40.175238   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 08:59:40.175378   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 08:59:40.223153   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 08:59:40.223305   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 08:59:40.268984   21492 logs.go:276] 0 containers: []
W0924 08:59:40.269011   21492 logs.go:278] No container was found matching "kindnet"
I0924 08:59:40.269111   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 08:59:40.321407   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 08:59:40.321542   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 08:59:40.371696   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 08:59:40.371745   21492 logs.go:123] Gathering logs for kubelet ...
I0924 08:59:40.371811   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 08:59:40.536341   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 08:59:40.536381   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 08:59:40.654950   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 08:59:40.654978   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 08:59:40.705187   21492 logs.go:123] Gathering logs for Docker ...
I0924 08:59:40.705212   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 08:59:40.757419   21492 logs.go:123] Gathering logs for container status ...
I0924 08:59:40.757443   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 08:59:40.853162   21492 logs.go:123] Gathering logs for dmesg ...
I0924 08:59:40.853191   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 08:59:40.928410   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 08:59:40.928438   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 08:59:40.988091   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 08:59:40.988114   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 08:59:41.038326   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 08:59:41.038352   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 08:59:41.123039   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 08:59:41.123062   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 08:59:41.224892   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 08:59:41.224922   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 08:59:41.384363   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:29:41.367705   12166 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:41.369821   12166 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:41.371748   12166 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:41.373702   12166 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:41.375671   12166 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:29:41.367705   12166 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:41.369821   12166 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:41.371748   12166 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:41.373702   12166 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:41.375671   12166 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 08:59:41.384380   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 08:59:41.384400   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 08:59:41.564118   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 08:59:41.564144   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 08:59:41.607792   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 08:59:41.607819   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 08:59:41.651066   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 08:59:41.651091   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 08:59:41.692219   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 08:59:41.692243   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 08:59:41.760353   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 08:59:41.760379   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 08:59:41.806317   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 08:59:41.806340   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 08:59:41.854200   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 08:59:41.854226   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 08:59:44.407140   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:59:44.443275   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 08:59:44.499123   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 08:59:44.499313   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 08:59:44.558931   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 08:59:44.559097   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 08:59:44.610021   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 08:59:44.610186   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 08:59:44.659663   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 08:59:44.659835   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 08:59:44.713579   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 08:59:44.713731   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 08:59:44.764275   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 08:59:44.764460   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 08:59:44.813193   21492 logs.go:276] 0 containers: []
W0924 08:59:44.813223   21492 logs.go:278] No container was found matching "kindnet"
I0924 08:59:44.813346   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 08:59:44.862335   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 08:59:44.862466   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 08:59:44.910537   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 08:59:44.910575   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 08:59:44.910592   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 08:59:44.963311   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 08:59:44.963341   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 08:59:45.017992   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 08:59:45.018019   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 08:59:45.072357   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 08:59:45.072384   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 08:59:45.122524   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 08:59:45.122551   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 08:59:45.197375   21492 logs.go:123] Gathering logs for dmesg ...
I0924 08:59:45.197403   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 08:59:45.269791   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 08:59:45.269818   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 08:59:45.472640   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 08:59:45.472671   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 08:59:45.592347   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 08:59:45.592371   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 08:59:45.635327   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 08:59:45.635351   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 08:59:45.689093   21492 logs.go:123] Gathering logs for Docker ...
I0924 08:59:45.689117   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 08:59:45.742755   21492 logs.go:123] Gathering logs for container status ...
I0924 08:59:45.742791   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 08:59:45.839928   21492 logs.go:123] Gathering logs for kubelet ...
I0924 08:59:45.839953   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 08:59:45.979296   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 08:59:45.979337   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 08:59:46.056407   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 08:59:46.056441   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 08:59:46.113379   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 08:59:46.113418   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 08:59:46.230492   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 08:59:46.230530   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 08:59:46.333834   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 08:59:46.333864   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 08:59:46.375345   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 08:59:46.375374   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 08:59:46.514422   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:29:46.498195   12649 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:46.500330   12649 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:46.502554   12649 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:46.504486   12649 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:46.506541   12649 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:29:46.498195   12649 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:46.500330   12649 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:46.502554   12649 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:46.504486   12649 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:46.506541   12649 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 08:59:49.015411   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:59:49.048998   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 08:59:49.100643   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 08:59:49.100834   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 08:59:49.152085   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 08:59:49.152233   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 08:59:49.204024   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 08:59:49.204193   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 08:59:49.262721   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 08:59:49.262937   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 08:59:49.312320   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 08:59:49.312506   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 08:59:49.371098   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 08:59:49.371287   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 08:59:49.425569   21492 logs.go:276] 0 containers: []
W0924 08:59:49.425599   21492 logs.go:278] No container was found matching "kindnet"
I0924 08:59:49.425753   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 08:59:49.486889   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 08:59:49.487029   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 08:59:49.541310   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 08:59:49.541355   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 08:59:49.541380   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 08:59:49.601024   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 08:59:49.601055   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 08:59:49.654224   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 08:59:49.654251   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 08:59:49.704030   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 08:59:49.704060   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 08:59:49.783401   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 08:59:49.783437   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 08:59:49.838404   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 08:59:49.838430   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 08:59:49.893615   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 08:59:49.893645   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 08:59:49.991632   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 08:59:49.991696   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 08:59:50.044147   21492 logs.go:123] Gathering logs for kubelet ...
I0924 08:59:50.044178   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 08:59:50.157174   21492 logs.go:123] Gathering logs for dmesg ...
I0924 08:59:50.157199   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 08:59:50.222947   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 08:59:50.222969   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 08:59:50.404205   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 08:59:50.404237   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 08:59:50.453354   21492 logs.go:123] Gathering logs for container status ...
I0924 08:59:50.453386   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 08:59:50.566889   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 08:59:50.566916   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 08:59:50.635271   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 08:59:50.635297   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 08:59:50.737497   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 08:59:50.737522   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 08:59:50.826142   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 08:59:50.826166   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 08:59:50.960896   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:29:50.943124   13011 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:50.946555   13011 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:50.948745   13011 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:50.950762   13011 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:50.952881   13011 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:29:50.943124   13011 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:50.946555   13011 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:50.948745   13011 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:50.950762   13011 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:50.952881   13011 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 08:59:50.960916   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 08:59:50.960933   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 08:59:51.010089   21492 logs.go:123] Gathering logs for Docker ...
I0924 08:59:51.010115   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 08:59:53.565956   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:59:53.596761   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 08:59:53.647095   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 08:59:53.647238   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 08:59:53.695974   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 08:59:53.696125   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 08:59:53.743894   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 08:59:53.744084   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 08:59:53.793977   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 08:59:53.794119   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 08:59:53.844079   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 08:59:53.844251   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 08:59:53.895728   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 08:59:53.895908   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 08:59:53.944489   21492 logs.go:276] 0 containers: []
W0924 08:59:53.944525   21492 logs.go:278] No container was found matching "kindnet"
I0924 08:59:53.944645   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 08:59:53.993553   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 08:59:53.993718   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 08:59:54.047805   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 08:59:54.047854   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 08:59:54.047873   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 08:59:54.120623   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 08:59:54.120664   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 08:59:54.190694   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 08:59:54.190727   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 08:59:54.267563   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 08:59:54.267608   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 08:59:54.343427   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 08:59:54.343457   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 08:59:54.475790   21492 logs.go:123] Gathering logs for kubelet ...
I0924 08:59:54.475835   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 08:59:54.632712   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 08:59:54.632747   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 08:59:54.728743   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 08:59:54.728799   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 08:59:54.983738   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 08:59:54.983806   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 08:59:55.096713   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 08:59:55.096737   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 08:59:55.140959   21492 logs.go:123] Gathering logs for Docker ...
I0924 08:59:55.140984   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 08:59:55.206179   21492 logs.go:123] Gathering logs for container status ...
I0924 08:59:55.206210   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 08:59:55.334092   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 08:59:55.334126   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 08:59:55.477267   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:29:55.459956   13354 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:55.462230   13354 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:55.464763   13354 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:55.467143   13354 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:55.469385   13354 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:29:55.459956   13354 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:55.462230   13354 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:55.464763   13354 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:55.467143   13354 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:29:55.469385   13354 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 08:59:55.477291   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 08:59:55.477309   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 08:59:55.581008   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 08:59:55.581030   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 08:59:55.633211   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 08:59:55.633236   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 08:59:55.683169   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 08:59:55.683194   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 08:59:55.727151   21492 logs.go:123] Gathering logs for dmesg ...
I0924 08:59:55.727174   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 08:59:55.793080   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 08:59:55.793101   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 08:59:58.351042   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 08:59:58.395414   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 08:59:58.452691   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 08:59:58.452904   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 08:59:58.518387   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 08:59:58.518563   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 08:59:58.582815   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 08:59:58.582987   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 08:59:58.637120   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 08:59:58.637302   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 08:59:58.694870   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 08:59:58.695050   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 08:59:58.753097   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 08:59:58.753358   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 08:59:58.806762   21492 logs.go:276] 0 containers: []
W0924 08:59:58.806838   21492 logs.go:278] No container was found matching "kindnet"
I0924 08:59:58.806960   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 08:59:58.857152   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 08:59:58.857315   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 08:59:58.907795   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 08:59:58.907844   21492 logs.go:123] Gathering logs for kubelet ...
I0924 08:59:58.907862   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 08:59:59.080544   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 08:59:59.080587   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 08:59:59.144141   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 08:59:59.144173   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 08:59:59.370615   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 08:59:59.370648   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 08:59:59.507111   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 08:59:59.507144   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 08:59:59.593652   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 08:59:59.593702   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 08:59:59.674849   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 08:59:59.674901   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 08:59:59.746796   21492 logs.go:123] Gathering logs for Docker ...
I0924 08:59:59.746836   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 08:59:59.822058   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 08:59:59.822095   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 08:59:59.899999   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 08:59:59.900033   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 08:59:59.965504   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 08:59:59.965533   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 09:00:00.035736   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 09:00:00.035816   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 09:00:00.182857   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 09:00:00.182896   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 09:00:00.252015   21492 logs.go:123] Gathering logs for container status ...
I0924 09:00:00.252054   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 09:00:00.402460   21492 logs.go:123] Gathering logs for dmesg ...
I0924 09:00:00.402497   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 09:00:00.500501   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 09:00:00.500533   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 09:00:00.729804   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:30:00.700619   13756 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:00.703606   13756 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:00.706456   13756 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:00.713824   13756 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:00.716424   13756 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:30:00.700619   13756 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:00.703606   13756 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:00.706456   13756 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:00.713824   13756 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:00.716424   13756 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 09:00:00.729841   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 09:00:00.729869   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 09:00:00.847978   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 09:00:00.848015   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 09:00:00.911158   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 09:00:00.911190   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 09:00:03.554617   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 09:00:03.604249   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 09:00:03.671171   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 09:00:03.671366   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 09:00:03.736994   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 09:00:03.737179   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 09:00:03.793074   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 09:00:03.793271   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 09:00:03.853963   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 09:00:03.854116   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 09:00:03.910517   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 09:00:03.910675   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 09:00:03.968592   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 09:00:03.968819   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 09:00:04.035213   21492 logs.go:276] 0 containers: []
W0924 09:00:04.035256   21492 logs.go:278] No container was found matching "kindnet"
I0924 09:00:04.035435   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 09:00:04.137358   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 09:00:04.137552   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 09:00:04.217839   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 09:00:04.217917   21492 logs.go:123] Gathering logs for Docker ...
I0924 09:00:04.217949   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 09:00:04.302624   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 09:00:04.302662   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 09:00:04.517843   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:30:04.494504   13967 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:04.497601   13967 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:04.500143   13967 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:04.502626   13967 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:04.505063   13967 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:30:04.494504   13967 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:04.497601   13967 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:04.500143   13967 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:04.502626   13967 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:04.505063   13967 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 09:00:04.517875   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 09:00:04.517906   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 09:00:04.615827   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 09:00:04.615865   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 09:00:04.688017   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 09:00:04.688048   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 09:00:04.753478   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 09:00:04.753513   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 09:00:04.820838   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 09:00:04.820878   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 09:00:04.887086   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 09:00:04.887124   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 09:00:05.132734   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 09:00:05.132766   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 09:00:05.197860   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 09:00:05.197890   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 09:00:05.258281   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 09:00:05.258318   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 09:00:05.363786   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 09:00:05.363819   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 09:00:05.421265   21492 logs.go:123] Gathering logs for container status ...
I0924 09:00:05.421312   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 09:00:05.560930   21492 logs.go:123] Gathering logs for kubelet ...
I0924 09:00:05.560975   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 09:00:05.704188   21492 logs.go:123] Gathering logs for dmesg ...
I0924 09:00:05.704219   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 09:00:05.799114   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 09:00:05.799149   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 09:00:05.898846   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 09:00:05.898879   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 09:00:06.073224   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 09:00:06.073271   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 09:00:06.136292   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 09:00:06.136329   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 09:00:08.790042   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 09:00:08.823216   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 09:00:08.875557   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 09:00:08.875704   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 09:00:08.926864   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 09:00:08.927099   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 09:00:08.987058   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 09:00:08.987297   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 09:00:09.056727   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 09:00:09.056924   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 09:00:09.113959   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 09:00:09.114171   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 09:00:09.166748   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 09:00:09.166925   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 09:00:09.214393   21492 logs.go:276] 0 containers: []
W0924 09:00:09.214424   21492 logs.go:278] No container was found matching "kindnet"
I0924 09:00:09.214563   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 09:00:09.280841   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 09:00:09.281041   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 09:00:09.334435   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 09:00:09.334476   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 09:00:09.334495   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 09:00:09.438291   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 09:00:09.438323   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 09:00:09.493676   21492 logs.go:123] Gathering logs for Docker ...
I0924 09:00:09.493712   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 09:00:09.582941   21492 logs.go:123] Gathering logs for container status ...
I0924 09:00:09.582990   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 09:00:09.725844   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 09:00:09.725878   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 09:00:09.989887   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 09:00:09.989935   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 09:00:10.061599   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 09:00:10.061630   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 09:00:10.122950   21492 logs.go:123] Gathering logs for kubelet ...
I0924 09:00:10.123012   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 09:00:10.276238   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 09:00:10.276272   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 09:00:10.459461   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:30:10.439582   14440 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:10.441962   14440 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:10.444405   14440 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:10.446935   14440 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:10.449337   14440 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:30:10.439582   14440 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:10.441962   14440 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:10.444405   14440 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:10.446935   14440 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:10.449337   14440 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 09:00:10.459513   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 09:00:10.459557   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 09:00:10.517548   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 09:00:10.517578   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 09:00:10.580766   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 09:00:10.580805   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 09:00:10.641324   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 09:00:10.641365   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 09:00:10.699463   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 09:00:10.699493   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 09:00:10.814522   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 09:00:10.814553   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 09:00:10.906662   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 09:00:10.906696   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 09:00:11.016008   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 09:00:11.016045   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 09:00:11.167586   21492 logs.go:123] Gathering logs for dmesg ...
I0924 09:00:11.167642   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 09:00:11.258950   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 09:00:11.259051   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 09:00:13.820689   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 09:00:13.861129   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 09:00:13.922647   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 09:00:13.922872   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 09:00:13.990984   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 09:00:13.991156   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 09:00:14.066137   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 09:00:14.066341   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 09:00:14.152124   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 09:00:14.152384   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 09:00:14.229957   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 09:00:14.230148   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 09:00:14.313522   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 09:00:14.313719   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 09:00:14.379954   21492 logs.go:276] 0 containers: []
W0924 09:00:14.379994   21492 logs.go:278] No container was found matching "kindnet"
I0924 09:00:14.380169   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 09:00:14.442253   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 09:00:14.442439   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 09:00:14.503333   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 09:00:14.503429   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 09:00:14.503458   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 09:00:14.715338   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:30:14.688018   14710 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:14.690675   14710 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:14.693038   14710 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:14.700569   14710 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:14.703097   14710 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:30:14.688018   14710 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:14.690675   14710 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:14.693038   14710 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:14.700569   14710 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:14.703097   14710 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 09:00:14.715368   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 09:00:14.715402   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 09:00:14.786866   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 09:00:14.786899   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 09:00:14.854934   21492 logs.go:123] Gathering logs for Docker ...
I0924 09:00:14.854970   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 09:00:14.938864   21492 logs.go:123] Gathering logs for kubelet ...
I0924 09:00:14.938898   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 09:00:15.092491   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 09:00:15.092518   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 09:00:15.167274   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 09:00:15.167300   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 09:00:15.329025   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 09:00:15.329066   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 09:00:15.398964   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 09:00:15.398999   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 09:00:15.471557   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 09:00:15.471594   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 09:00:15.533079   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 09:00:15.533109   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 09:00:15.583374   21492 logs.go:123] Gathering logs for container status ...
I0924 09:00:15.583416   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 09:00:15.686237   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 09:00:15.686264   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 09:00:15.793034   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 09:00:15.793062   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 09:00:15.839874   21492 logs.go:123] Gathering logs for dmesg ...
I0924 09:00:15.839907   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 09:00:15.907526   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 09:00:15.907554   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 09:00:16.169266   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 09:00:16.169297   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 09:00:16.274025   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 09:00:16.274059   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 09:00:16.341075   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 09:00:16.341122   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 09:00:18.969290   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 09:00:19.009658   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 09:00:19.062876   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 09:00:19.063016   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 09:00:19.114248   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 09:00:19.114390   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 09:00:19.163838   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 09:00:19.164001   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 09:00:19.213650   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 09:00:19.213824   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 09:00:19.266805   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 09:00:19.266997   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 09:00:19.317348   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 09:00:19.317499   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 09:00:19.365497   21492 logs.go:276] 0 containers: []
W0924 09:00:19.365527   21492 logs.go:278] No container was found matching "kindnet"
I0924 09:00:19.365638   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 09:00:19.417373   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 09:00:19.417533   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 09:00:19.469716   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 09:00:19.469806   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 09:00:19.469838   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 09:00:19.565855   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 09:00:19.565888   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 09:00:19.645601   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 09:00:19.645645   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 09:00:19.709866   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 09:00:19.709897   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 09:00:19.828759   21492 logs.go:123] Gathering logs for kubelet ...
I0924 09:00:19.828808   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 09:00:19.975715   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 09:00:19.975756   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 09:00:20.111769   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 09:00:20.111813   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 09:00:20.173836   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 09:00:20.173866   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 09:00:20.231392   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 09:00:20.231425   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 09:00:20.290172   21492 logs.go:123] Gathering logs for Docker ...
I0924 09:00:20.290207   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 09:00:20.356890   21492 logs.go:123] Gathering logs for container status ...
I0924 09:00:20.356932   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 09:00:20.487973   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 09:00:20.488020   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 09:00:20.679876   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:30:20.659653   15211 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:20.662207   15211 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:20.664562   15211 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:20.667735   15211 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:20.670012   15211 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:30:20.659653   15211 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:20.662207   15211 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:20.664562   15211 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:20.667735   15211 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:20.670012   15211 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 09:00:20.679898   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 09:00:20.679920   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 09:00:20.922886   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 09:00:20.922918   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 09:00:20.986643   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 09:00:20.986672   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 09:00:21.105380   21492 logs.go:123] Gathering logs for dmesg ...
I0924 09:00:21.105408   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 09:00:21.184908   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 09:00:21.184937   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 09:00:21.236521   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 09:00:21.236551   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 09:00:21.292273   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 09:00:21.292304   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 09:00:23.852132   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 09:00:23.889081   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 09:00:23.953936   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 09:00:23.954099   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 09:00:24.027881   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 09:00:24.028079   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 09:00:24.097093   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 09:00:24.097311   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 09:00:24.193967   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 09:00:24.194180   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 09:00:24.256987   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 09:00:24.257204   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 09:00:24.349462   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 09:00:24.349645   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 09:00:24.420751   21492 logs.go:276] 0 containers: []
W0924 09:00:24.420849   21492 logs.go:278] No container was found matching "kindnet"
I0924 09:00:24.421059   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 09:00:24.481052   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 09:00:24.481226   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 09:00:24.530210   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 09:00:24.530263   21492 logs.go:123] Gathering logs for kubelet ...
I0924 09:00:24.530293   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 09:00:24.678554   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 09:00:24.678591   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 09:00:24.929171   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 09:00:24.929204   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 09:00:25.077298   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 09:00:25.077335   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 09:00:25.139013   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 09:00:25.139043   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 09:00:25.196438   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 09:00:25.196469   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 09:00:25.253743   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 09:00:25.253806   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 09:00:25.420963   21492 logs.go:123] Gathering logs for container status ...
I0924 09:00:25.420997   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 09:00:25.573568   21492 logs.go:123] Gathering logs for Docker ...
I0924 09:00:25.573636   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 09:00:25.654597   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 09:00:25.654627   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 09:00:25.818562   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:30:25.801199   15556 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:25.803457   15556 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:25.805566   15556 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:25.807848   15556 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:25.809969   15556 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:30:25.801199   15556 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:25.803457   15556 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:25.805566   15556 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:25.807848   15556 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:25.809969   15556 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 09:00:25.818589   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 09:00:25.818623   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 09:00:25.902404   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 09:00:25.902447   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 09:00:26.025681   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 09:00:26.025716   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 09:00:26.105144   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 09:00:26.105182   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 09:00:26.179029   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 09:00:26.179064   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 09:00:26.302973   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 09:00:26.303009   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 09:00:26.360615   21492 logs.go:123] Gathering logs for dmesg ...
I0924 09:00:26.360646   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 09:00:26.465610   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 09:00:26.465653   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 09:00:26.553488   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 09:00:26.553525   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 09:00:29.129606   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 09:00:29.156358   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 09:00:29.202757   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 09:00:29.202925   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 09:00:29.254277   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 09:00:29.254488   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 09:00:29.305955   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 09:00:29.306087   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 09:00:29.348359   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 09:00:29.348508   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 09:00:29.387971   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 09:00:29.388087   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 09:00:29.429054   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 09:00:29.429209   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 09:00:29.468560   21492 logs.go:276] 0 containers: []
W0924 09:00:29.468587   21492 logs.go:278] No container was found matching "kindnet"
I0924 09:00:29.468715   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 09:00:29.512369   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 09:00:29.512510   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 09:00:29.558504   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 09:00:29.558554   21492 logs.go:123] Gathering logs for kubelet ...
I0924 09:00:29.558576   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 09:00:29.689871   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 09:00:29.689898   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 09:00:29.874812   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 09:00:29.874840   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 09:00:29.924331   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 09:00:29.924359   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 09:00:30.051245   21492 logs.go:123] Gathering logs for Docker ...
I0924 09:00:30.051275   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 09:00:30.117391   21492 logs.go:123] Gathering logs for container status ...
I0924 09:00:30.117451   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 09:00:30.219658   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 09:00:30.219682   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 09:00:30.393175   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:30:30.375521   15888 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:30.377816   15888 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:30.379915   15888 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:30.382202   15888 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:30.384491   15888 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:30:30.375521   15888 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:30.377816   15888 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:30.379915   15888 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:30.382202   15888 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:30.384491   15888 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 09:00:30.393202   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 09:00:30.393231   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 09:00:30.504232   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 09:00:30.504258   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 09:00:30.560017   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 09:00:30.560051   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 09:00:30.608333   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 09:00:30.608356   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 09:00:30.653123   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 09:00:30.653150   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 09:00:30.709451   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 09:00:30.709484   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 09:00:30.789990   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 09:00:30.790016   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 09:00:30.884985   21492 logs.go:123] Gathering logs for dmesg ...
I0924 09:00:30.885018   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 09:00:30.971978   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 09:00:30.972013   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 09:00:31.065385   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 09:00:31.065418   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 09:00:31.131138   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 09:00:31.131169   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 09:00:31.186837   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 09:00:31.186865   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 09:00:33.740326   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 09:00:33.773559   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 09:00:33.865763   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 09:00:33.866015   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 09:00:33.973329   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 09:00:33.973555   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 09:00:34.088035   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 09:00:34.088257   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 09:00:34.184860   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 09:00:34.185092   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 09:00:34.269698   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 09:00:34.270317   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 09:00:34.354017   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 09:00:34.354233   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 09:00:34.430794   21492 logs.go:276] 0 containers: []
W0924 09:00:34.430841   21492 logs.go:278] No container was found matching "kindnet"
I0924 09:00:34.431010   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 09:00:34.502961   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 09:00:34.503138   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 09:00:34.557540   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 09:00:34.557593   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 09:00:34.557614   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 09:00:34.706376   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 09:00:34.706420   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"
I0924 09:00:34.835575   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 09:00:34.835622   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 09:00:34.923439   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 09:00:34.923476   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 09:00:35.003184   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 09:00:35.003229   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 09:00:35.261927   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 09:00:35.261962   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 09:00:35.332438   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 09:00:35.332468   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 09:00:35.391589   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 09:00:35.391618   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 09:00:35.499454   21492 logs.go:123] Gathering logs for container status ...
I0924 09:00:35.499481   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 09:00:35.600981   21492 logs.go:123] Gathering logs for dmesg ...
I0924 09:00:35.601008   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 09:00:35.669285   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 09:00:35.669309   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 09:00:35.821354   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:30:35.803756   16298 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:35.806566   16298 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:35.808687   16298 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:35.810915   16298 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:35.813039   16298 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:30:35.803756   16298 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:35.806566   16298 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:35.808687   16298 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:35.810915   16298 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:35.813039   16298 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 09:00:35.821372   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 09:00:35.821392   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 09:00:35.930828   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 09:00:35.930868   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 09:00:36.011538   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 09:00:36.011569   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 09:00:36.081326   21492 logs.go:123] Gathering logs for kubelet ...
I0924 09:00:36.081358   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 09:00:36.210266   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 09:00:36.210291   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 09:00:36.255810   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 09:00:36.255835   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 09:00:36.339704   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 09:00:36.339728   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 09:00:36.381900   21492 logs.go:123] Gathering logs for Docker ...
I0924 09:00:36.381926   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 09:00:38.939321   21492 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0924 09:00:38.992702   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0924 09:00:39.076250   21492 logs.go:276] 2 containers: [b181c5f7b9db 3957ce6e0e5c]
I0924 09:00:39.076494   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0924 09:00:39.147816   21492 logs.go:276] 2 containers: [d479a78946ad f4eedf241c60]
I0924 09:00:39.148038   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0924 09:00:39.207635   21492 logs.go:276] 2 containers: [f69bb1af9b44 3cd975f5922c]
I0924 09:00:39.207878   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0924 09:00:39.264319   21492 logs.go:276] 2 containers: [75893e4b20b3 fd5218609e79]
I0924 09:00:39.264499   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0924 09:00:39.315624   21492 logs.go:276] 2 containers: [e0553e3866cd 2599ffe2f52d]
I0924 09:00:39.315768   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0924 09:00:39.366308   21492 logs.go:276] 2 containers: [840e026f5d7a 8758b53e92b7]
I0924 09:00:39.366479   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0924 09:00:39.453156   21492 logs.go:276] 0 containers: []
W0924 09:00:39.453187   21492 logs.go:278] No container was found matching "kindnet"
I0924 09:00:39.453365   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0924 09:00:39.532357   21492 logs.go:276] 1 containers: [8d2e87db61d9]
I0924 09:00:39.532549   21492 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0924 09:00:39.608266   21492 logs.go:276] 1 containers: [2fd2b8ae66c1]
I0924 09:00:39.608323   21492 logs.go:123] Gathering logs for kube-scheduler [75893e4b20b3] ...
I0924 09:00:39.608350   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 75893e4b20b3"
I0924 09:00:39.672076   21492 logs.go:123] Gathering logs for kubelet ...
I0924 09:00:39.672108   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0924 09:00:39.817010   21492 logs.go:123] Gathering logs for etcd [f4eedf241c60] ...
I0924 09:00:39.817040   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f4eedf241c60"
I0924 09:00:39.981572   21492 logs.go:123] Gathering logs for kube-apiserver [b181c5f7b9db] ...
I0924 09:00:39.981640   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b181c5f7b9db"
I0924 09:00:40.247587   21492 logs.go:123] Gathering logs for coredns [f69bb1af9b44] ...
I0924 09:00:40.247619   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f69bb1af9b44"
I0924 09:00:40.311552   21492 logs.go:123] Gathering logs for kube-scheduler [fd5218609e79] ...
I0924 09:00:40.311586   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fd5218609e79"
I0924 09:00:40.377724   21492 logs.go:123] Gathering logs for kube-proxy [2599ffe2f52d] ...
I0924 09:00:40.377766   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2599ffe2f52d"
I0924 09:00:40.456308   21492 logs.go:123] Gathering logs for kube-controller-manager [840e026f5d7a] ...
I0924 09:00:40.456351   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 840e026f5d7a"
I0924 09:00:40.597469   21492 logs.go:123] Gathering logs for kube-controller-manager [8758b53e92b7] ...
I0924 09:00:40.597504   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8758b53e92b7"
I0924 09:00:40.723687   21492 logs.go:123] Gathering logs for dmesg ...
I0924 09:00:40.723717   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0924 09:00:40.809662   21492 logs.go:123] Gathering logs for describe nodes ...
I0924 09:00:40.809692   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0924 09:00:40.999700   21492 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:30:40.979122   16652 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:40.981934   16652 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:40.984371   16652 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:40.986847   16652 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:40.989316   16652 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0924 03:30:40.979122   16652 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:40.981934   16652 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:40.984371   16652 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:40.986847   16652 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:30:40.989316   16652 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0924 09:00:40.999724   21492 logs.go:123] Gathering logs for Docker ...
I0924 09:00:40.999744   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0924 09:00:41.076253   21492 logs.go:123] Gathering logs for container status ...
I0924 09:00:41.076284   21492 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0924 09:00:41.200918   21492 logs.go:123] Gathering logs for kube-proxy [e0553e3866cd] ...
I0924 09:00:41.200957   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e0553e3866cd"
I0924 09:00:41.264657   21492 logs.go:123] Gathering logs for kubernetes-dashboard [8d2e87db61d9] ...
I0924 09:00:41.264689   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8d2e87db61d9"
I0924 09:00:41.318383   21492 logs.go:123] Gathering logs for coredns [3cd975f5922c] ...
I0924 09:00:41.318419   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3cd975f5922c"
I0924 09:00:41.375803   21492 logs.go:123] Gathering logs for storage-provisioner [2fd2b8ae66c1] ...
I0924 09:00:41.375829   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2fd2b8ae66c1"
I0924 09:00:41.434067   21492 logs.go:123] Gathering logs for kube-apiserver [3957ce6e0e5c] ...
I0924 09:00:41.434102   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3957ce6e0e5c"
I0924 09:00:41.544981   21492 logs.go:123] Gathering logs for etcd [d479a78946ad] ...
I0924 09:00:41.545014   21492 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d479a78946ad"


==> Docker <==
Sep 24 03:26:44 minikube dockerd[609]: time="2024-09-24T03:26:44.856890805Z" level=info msg="Starting up"
Sep 24 03:26:44 minikube dockerd[609]: time="2024-09-24T03:26:44.899448408Z" level=info msg="[graphdriver] trying configured driver: overlay2"
Sep 24 03:26:44 minikube dockerd[609]: time="2024-09-24T03:26:44.949498664Z" level=info msg="Loading containers: start."
Sep 24 03:26:45 minikube dockerd[609]: time="2024-09-24T03:26:45.699949102Z" level=info msg="Processing signal 'terminated'"
Sep 24 03:26:45 minikube dockerd[609]: time="2024-09-24T03:26:45.738341592Z" level=info msg="Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP address"
Sep 24 03:26:45 minikube dockerd[609]: time="2024-09-24T03:26:45.895856606Z" level=warning msg="error locating sandbox id 914d5e578eff6c75d8a60b3ee1f7ed9b5e806c4f62fc6b575e7fbc93429afb13: sandbox 914d5e578eff6c75d8a60b3ee1f7ed9b5e806c4f62fc6b575e7fbc93429afb13 not found"
Sep 24 03:26:45 minikube dockerd[609]: time="2024-09-24T03:26:45.895936761Z" level=warning msg="error locating sandbox id 1e5fa5fd22390bf32c8cf1b0cf7be526f9585aab35277fd1d66aab07cf80cdf3: sandbox 1e5fa5fd22390bf32c8cf1b0cf7be526f9585aab35277fd1d66aab07cf80cdf3 not found"
Sep 24 03:26:45 minikube dockerd[609]: time="2024-09-24T03:26:45.895998118Z" level=warning msg="error locating sandbox id 1247be993f14213c785798c25181050fd5ffc9fe06f17efdb3d0df7c0d7cd368: sandbox 1247be993f14213c785798c25181050fd5ffc9fe06f17efdb3d0df7c0d7cd368 not found"
Sep 24 03:26:45 minikube dockerd[609]: time="2024-09-24T03:26:45.896039401Z" level=warning msg="error locating sandbox id e72b88a97eba067e04f7af1aaf3a32508900ad72ec513295c91bd31fd5d3cc09: sandbox e72b88a97eba067e04f7af1aaf3a32508900ad72ec513295c91bd31fd5d3cc09 not found"
Sep 24 03:26:45 minikube dockerd[609]: time="2024-09-24T03:26:45.896071514Z" level=warning msg="error locating sandbox id 2fc6049a1a25aa6d4ad9204edea80a9b3e95b9f78a266573aaccfbde6e6f45ad: sandbox 2fc6049a1a25aa6d4ad9204edea80a9b3e95b9f78a266573aaccfbde6e6f45ad not found"
Sep 24 03:26:45 minikube dockerd[609]: time="2024-09-24T03:26:45.896105771Z" level=warning msg="error locating sandbox id d498554d9b098a72a32e95afc5389a34b1a3908e8b661b855a7542b489ad7978: sandbox d498554d9b098a72a32e95afc5389a34b1a3908e8b661b855a7542b489ad7978 not found"
Sep 24 03:26:45 minikube dockerd[609]: time="2024-09-24T03:26:45.896137667Z" level=warning msg="error locating sandbox id b5ec75ff7893706944928a4f671a24d75897fca367859e068693149f1af8e0e9: sandbox b5ec75ff7893706944928a4f671a24d75897fca367859e068693149f1af8e0e9 not found"
Sep 24 03:26:45 minikube dockerd[609]: time="2024-09-24T03:26:45.896178222Z" level=warning msg="error locating sandbox id d41f88186d65a7349e88b24fdf801ecbc03c56728e6fac2966393b933d60f8a4: sandbox d41f88186d65a7349e88b24fdf801ecbc03c56728e6fac2966393b933d60f8a4 not found"
Sep 24 03:26:45 minikube dockerd[609]: time="2024-09-24T03:26:45.896218161Z" level=warning msg="error locating sandbox id a214c30c3c13eb8a2eabeb833f1983eb597e592bc042a77d21d0cf19784f6e0d: sandbox a214c30c3c13eb8a2eabeb833f1983eb597e592bc042a77d21d0cf19784f6e0d not found"
Sep 24 03:26:45 minikube dockerd[609]: time="2024-09-24T03:26:45.896252018Z" level=warning msg="error locating sandbox id 50b66f467d8f46c7a66345331845a566a4caab74b376421d5c75bb8ac23f4d62: sandbox 50b66f467d8f46c7a66345331845a566a4caab74b376421d5c75bb8ac23f4d62 not found"
Sep 24 03:26:45 minikube dockerd[609]: time="2024-09-24T03:26:45.896288143Z" level=warning msg="error locating sandbox id 9c07a911c0d21fc093fc49314799d11a774a3d52ec9c074f1e5b4172d79c1732: sandbox 9c07a911c0d21fc093fc49314799d11a774a3d52ec9c074f1e5b4172d79c1732 not found"
Sep 24 03:26:45 minikube dockerd[609]: time="2024-09-24T03:26:45.897513986Z" level=info msg="Loading containers: done."
Sep 24 03:26:45 minikube dockerd[609]: time="2024-09-24T03:26:45.914134978Z" level=info msg="Docker daemon" commit=3ab5c7d containerd-snapshotter=false storage-driver=overlay2 version=27.2.0
Sep 24 03:26:45 minikube dockerd[609]: time="2024-09-24T03:26:45.914282827Z" level=info msg="Daemon has completed initialization"
Sep 24 03:26:45 minikube dockerd[609]: time="2024-09-24T03:26:45.983317811Z" level=info msg="API listen on /var/run/docker.sock"
Sep 24 03:26:45 minikube dockerd[609]: time="2024-09-24T03:26:45.983370388Z" level=info msg="API listen on [::]:2376"
Sep 24 03:26:45 minikube dockerd[609]: time="2024-09-24T03:26:45.985540730Z" level=info msg="stopping event stream following graceful shutdown" error="<nil>" module=libcontainerd namespace=moby
Sep 24 03:26:45 minikube dockerd[609]: time="2024-09-24T03:26:45.986571655Z" level=info msg="Daemon shutdown complete"
Sep 24 03:26:46 minikube systemd[1]: docker.service: Deactivated successfully.
Sep 24 03:26:46 minikube systemd[1]: Stopped Docker Application Container Engine.
Sep 24 03:26:46 minikube systemd[1]: docker.service: Consumed 1.275s CPU time.
Sep 24 03:26:46 minikube systemd[1]: Starting Docker Application Container Engine...
Sep 24 03:26:46 minikube dockerd[889]: time="2024-09-24T03:26:46.105406466Z" level=info msg="Starting up"
Sep 24 03:26:46 minikube dockerd[889]: time="2024-09-24T03:26:46.138373918Z" level=info msg="[graphdriver] trying configured driver: overlay2"
Sep 24 03:26:46 minikube dockerd[889]: time="2024-09-24T03:26:46.176061372Z" level=info msg="Loading containers: start."
Sep 24 03:26:46 minikube dockerd[889]: time="2024-09-24T03:26:46.912109848Z" level=info msg="Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP address"
Sep 24 03:26:47 minikube dockerd[889]: time="2024-09-24T03:26:47.058994614Z" level=warning msg="error locating sandbox id b5ec75ff7893706944928a4f671a24d75897fca367859e068693149f1af8e0e9: sandbox b5ec75ff7893706944928a4f671a24d75897fca367859e068693149f1af8e0e9 not found"
Sep 24 03:26:47 minikube dockerd[889]: time="2024-09-24T03:26:47.059080343Z" level=warning msg="error locating sandbox id 1247be993f14213c785798c25181050fd5ffc9fe06f17efdb3d0df7c0d7cd368: sandbox 1247be993f14213c785798c25181050fd5ffc9fe06f17efdb3d0df7c0d7cd368 not found"
Sep 24 03:26:47 minikube dockerd[889]: time="2024-09-24T03:26:47.059128783Z" level=warning msg="error locating sandbox id a214c30c3c13eb8a2eabeb833f1983eb597e592bc042a77d21d0cf19784f6e0d: sandbox a214c30c3c13eb8a2eabeb833f1983eb597e592bc042a77d21d0cf19784f6e0d not found"
Sep 24 03:26:47 minikube dockerd[889]: time="2024-09-24T03:26:47.059170037Z" level=warning msg="error locating sandbox id 50b66f467d8f46c7a66345331845a566a4caab74b376421d5c75bb8ac23f4d62: sandbox 50b66f467d8f46c7a66345331845a566a4caab74b376421d5c75bb8ac23f4d62 not found"
Sep 24 03:26:47 minikube dockerd[889]: time="2024-09-24T03:26:47.059220865Z" level=warning msg="error locating sandbox id 914d5e578eff6c75d8a60b3ee1f7ed9b5e806c4f62fc6b575e7fbc93429afb13: sandbox 914d5e578eff6c75d8a60b3ee1f7ed9b5e806c4f62fc6b575e7fbc93429afb13 not found"
Sep 24 03:26:47 minikube dockerd[889]: time="2024-09-24T03:26:47.059261484Z" level=warning msg="error locating sandbox id 1e5fa5fd22390bf32c8cf1b0cf7be526f9585aab35277fd1d66aab07cf80cdf3: sandbox 1e5fa5fd22390bf32c8cf1b0cf7be526f9585aab35277fd1d66aab07cf80cdf3 not found"
Sep 24 03:26:47 minikube dockerd[889]: time="2024-09-24T03:26:47.059297979Z" level=warning msg="error locating sandbox id 9c07a911c0d21fc093fc49314799d11a774a3d52ec9c074f1e5b4172d79c1732: sandbox 9c07a911c0d21fc093fc49314799d11a774a3d52ec9c074f1e5b4172d79c1732 not found"
Sep 24 03:26:47 minikube dockerd[889]: time="2024-09-24T03:26:47.059363619Z" level=warning msg="error locating sandbox id 2fc6049a1a25aa6d4ad9204edea80a9b3e95b9f78a266573aaccfbde6e6f45ad: sandbox 2fc6049a1a25aa6d4ad9204edea80a9b3e95b9f78a266573aaccfbde6e6f45ad not found"
Sep 24 03:26:47 minikube dockerd[889]: time="2024-09-24T03:26:47.059413775Z" level=warning msg="error locating sandbox id e72b88a97eba067e04f7af1aaf3a32508900ad72ec513295c91bd31fd5d3cc09: sandbox e72b88a97eba067e04f7af1aaf3a32508900ad72ec513295c91bd31fd5d3cc09 not found"
Sep 24 03:26:47 minikube dockerd[889]: time="2024-09-24T03:26:47.059457698Z" level=warning msg="error locating sandbox id d498554d9b098a72a32e95afc5389a34b1a3908e8b661b855a7542b489ad7978: sandbox d498554d9b098a72a32e95afc5389a34b1a3908e8b661b855a7542b489ad7978 not found"
Sep 24 03:26:47 minikube dockerd[889]: time="2024-09-24T03:26:47.059494753Z" level=warning msg="error locating sandbox id d41f88186d65a7349e88b24fdf801ecbc03c56728e6fac2966393b933d60f8a4: sandbox d41f88186d65a7349e88b24fdf801ecbc03c56728e6fac2966393b933d60f8a4 not found"
Sep 24 03:26:47 minikube dockerd[889]: time="2024-09-24T03:26:47.059955212Z" level=info msg="Loading containers: done."
Sep 24 03:26:47 minikube dockerd[889]: time="2024-09-24T03:26:47.076608429Z" level=info msg="Docker daemon" commit=3ab5c7d containerd-snapshotter=false storage-driver=overlay2 version=27.2.0
Sep 24 03:26:47 minikube dockerd[889]: time="2024-09-24T03:26:47.076812720Z" level=info msg="Daemon has completed initialization"
Sep 24 03:26:47 minikube dockerd[889]: time="2024-09-24T03:26:47.133346665Z" level=info msg="API listen on /var/run/docker.sock"
Sep 24 03:26:47 minikube dockerd[889]: time="2024-09-24T03:26:47.133400629Z" level=info msg="API listen on [::]:2376"
Sep 24 03:26:47 minikube systemd[1]: Started Docker Application Container Engine.
Sep 24 03:26:48 minikube systemd[1]: Starting CRI Interface for Docker Application Container Engine...
Sep 24 03:26:48 minikube cri-dockerd[1171]: time="2024-09-24T03:26:48Z" level=info msg="Starting cri-dockerd dev (HEAD)"
Sep 24 03:26:48 minikube cri-dockerd[1171]: time="2024-09-24T03:26:48Z" level=info msg="Connecting to docker on the Endpoint unix:///var/run/docker.sock"
Sep 24 03:26:48 minikube cri-dockerd[1171]: time="2024-09-24T03:26:48Z" level=info msg="Start docker client with request timeout 0s"
Sep 24 03:26:48 minikube cri-dockerd[1171]: time="2024-09-24T03:26:48Z" level=info msg="Hairpin mode is set to hairpin-veth"
Sep 24 03:26:48 minikube cri-dockerd[1171]: time="2024-09-24T03:26:48Z" level=info msg="Loaded network plugin cni"
Sep 24 03:26:48 minikube cri-dockerd[1171]: time="2024-09-24T03:26:48Z" level=info msg="Docker cri networking managed by network plugin cni"
Sep 24 03:26:48 minikube cri-dockerd[1171]: time="2024-09-24T03:26:48Z" level=info msg="Setting cgroupDriver systemd"
Sep 24 03:26:48 minikube cri-dockerd[1171]: time="2024-09-24T03:26:48Z" level=info msg="Docker cri received runtime config &RuntimeConfig{NetworkConfig:&NetworkConfig{PodCidr:,},}"
Sep 24 03:26:48 minikube cri-dockerd[1171]: time="2024-09-24T03:26:48Z" level=info msg="Starting the GRPC backend for the Docker CRI interface."
Sep 24 03:26:48 minikube cri-dockerd[1171]: time="2024-09-24T03:26:48Z" level=info msg="Start cri-dockerd grpc backend"
Sep 24 03:26:48 minikube systemd[1]: Started CRI Interface for Docker Application Container Engine.


==> container status <==
CONTAINER           IMAGE               CREATED             STATE               NAME                        ATTEMPT             POD ID              POD
e9c580105bdb2       39286ab8a5e14       10 hours ago        Exited              nginx                       2                   da4d2b6ffbdbe       my-nginx-c78685b99-zz5rf
8d2e87db61d9f       07655ddf2eebe       10 hours ago        Exited              kubernetes-dashboard        3                   e44270048bb0e       kubernetes-dashboard-695b96c756-bm62d
a2ca9585f411e       115053965e86b       10 hours ago        Exited              dashboard-metrics-scraper   2                   2d34037cac1f6       dashboard-metrics-scraper-c5db448b4-9jfh8
f69bb1af9b446       cbb01a7bd410d       10 hours ago        Exited              coredns                     2                   bce2061cc4315       coredns-6f6b679f8f-bzg4j
d8eae5308f2f3       48d9cfaaf3904       10 hours ago        Exited              metrics-server              2                   e1d9ba02ac233       metrics-server-84c5f94fbc-nrmk5
2fd2b8ae66c14       6e38f40d628db       10 hours ago        Exited              storage-provisioner         4                   c00c1ba61a410       storage-provisioner
e0553e3866cd9       ad83b2ca7b09e       10 hours ago        Exited              kube-proxy                  2                   810010d5dbe70       kube-proxy-6k4vc
75893e4b20b39       1766f54c897f0       10 hours ago        Exited              kube-scheduler              2                   ff49828a50d92       kube-scheduler-minikube
840e026f5d7a1       045733566833c       10 hours ago        Exited              kube-controller-manager     2                   0e1c6ddda4fd9       kube-controller-manager-minikube
b181c5f7b9db1       604f5db92eaa8       10 hours ago        Exited              kube-apiserver              2                   331da8677aac1       kube-apiserver-minikube
d479a78946ad4       2e96e5913fc06       10 hours ago        Exited              etcd                        2                   0f4995a711f6a       etcd-minikube
5028cbee23293       39286ab8a5e14       17 hours ago        Exited              nginx                       1                   1f140d7738603       my-nginx-c78685b99-zz5rf
3cd975f5922c6       cbb01a7bd410d       17 hours ago        Exited              coredns                     1                   0d6c39d8a34f1       coredns-6f6b679f8f-bzg4j
1b985c25e2a61       48d9cfaaf3904       17 hours ago        Exited              metrics-server              1                   ff07fd0038cb1       metrics-server-84c5f94fbc-nrmk5
d8616c82fef0a       115053965e86b       17 hours ago        Exited              dashboard-metrics-scraper   1                   e307daa821d89       dashboard-metrics-scraper-c5db448b4-9jfh8
2599ffe2f52d3       ad83b2ca7b09e       17 hours ago        Exited              kube-proxy                  1                   14987532db157       kube-proxy-6k4vc
f4eedf241c608       2e96e5913fc06       17 hours ago        Exited              etcd                        1                   f816c7079c9cf       etcd-minikube
fd5218609e799       1766f54c897f0       17 hours ago        Exited              kube-scheduler              1                   cf8a8326733ed       kube-scheduler-minikube
8758b53e92b7f       045733566833c       17 hours ago        Exited              kube-controller-manager     1                   7ac98e8af5d76       kube-controller-manager-minikube
3957ce6e0e5c8       604f5db92eaa8       17 hours ago        Exited              kube-apiserver              1                   c66a6b829bf56       kube-apiserver-minikube


==> coredns [3cd975f5922c] <==
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = 05e3eaddc414b2d71a69b2e2bc6f2681fc1f4d04bcdd3acc1a41457bb7db518208b95ddfc4c9fffedc59c25a8faf458be1af4915a4a3c0d6777cb7a346bc5d86
CoreDNS-1.11.1
linux/amd64, go1.20.7, ae2bbc2
[INFO] 127.0.0.1:58202 - 15828 "HINFO IN 611988277775597825.270214725868523886. udp 55 false 512" NXDOMAIN qr,rd,ra 130 0.132844104s
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.27.4/tools/cache/reflector.go:231: failed to list *v1.Service: Get "https://10.96.0.1:443/api/v1/services?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[INFO] plugin/kubernetes: Trace[1969396598]: "Reflector ListAndWatch" name:pkg/mod/k8s.io/client-go@v0.27.4/tools/cache/reflector.go:231 (23-Sep-2024 10:38:55.809) (total time: 30003ms):
Trace[1969396598]: ---"Objects listed" error:Get "https://10.96.0.1:443/api/v1/services?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout 30002ms (10:39:25.811)
Trace[1969396598]: [30.00322304s] [30.00322304s] END
[ERROR] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.27.4/tools/cache/reflector.go:231: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://10.96.0.1:443/api/v1/services?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.27.4/tools/cache/reflector.go:231: failed to list *v1.Namespace: Get "https://10.96.0.1:443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[INFO] plugin/kubernetes: Trace[1970987832]: "Reflector ListAndWatch" name:pkg/mod/k8s.io/client-go@v0.27.4/tools/cache/reflector.go:231 (23-Sep-2024 10:38:55.808) (total time: 30003ms):
Trace[1970987832]: ---"Objects listed" error:Get "https://10.96.0.1:443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout 30003ms (10:39:25.811)
Trace[1970987832]: [30.003436328s] [30.003436328s] END
[ERROR] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.27.4/tools/cache/reflector.go:231: Failed to watch *v1.Namespace: failed to list *v1.Namespace: Get "https://10.96.0.1:443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.27.4/tools/cache/reflector.go:231: failed to list *v1.EndpointSlice: Get "https://10.96.0.1:443/apis/discovery.k8s.io/v1/endpointslices?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[INFO] plugin/kubernetes: Trace[140076305]: "Reflector ListAndWatch" name:pkg/mod/k8s.io/client-go@v0.27.4/tools/cache/reflector.go:231 (23-Sep-2024 10:38:55.808) (total time: 30003ms):
Trace[140076305]: ---"Objects listed" error:Get "https://10.96.0.1:443/apis/discovery.k8s.io/v1/endpointslices?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout 30003ms (10:39:25.812)
Trace[140076305]: [30.003502471s] [30.003502471s] END
[ERROR] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.27.4/tools/cache/reflector.go:231: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: Get "https://10.96.0.1:443/apis/discovery.k8s.io/v1/endpointslices?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout


==> coredns [f69bb1af9b44] <==
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = 05e3eaddc414b2d71a69b2e2bc6f2681fc1f4d04bcdd3acc1a41457bb7db518208b95ddfc4c9fffedc59c25a8faf458be1af4915a4a3c0d6777cb7a346bc5d86
CoreDNS-1.11.1
linux/amd64, go1.20.7, ae2bbc2
[INFO] 127.0.0.1:37727 - 44956 "HINFO IN 9047372127048268260.4427111416166004755. udp 57 false 512" NXDOMAIN qr,rd,ra 132 0.058749219s
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.27.4/tools/cache/reflector.go:231: failed to list *v1.EndpointSlice: Get "https://10.96.0.1:443/apis/discovery.k8s.io/v1/endpointslices?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[INFO] plugin/kubernetes: Trace[44267262]: "Reflector ListAndWatch" name:pkg/mod/k8s.io/client-go@v0.27.4/tools/cache/reflector.go:231 (23-Sep-2024 17:56:44.077) (total time: 30005ms):
Trace[44267262]: ---"Objects listed" error:Get "https://10.96.0.1:443/apis/discovery.k8s.io/v1/endpointslices?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout 30004ms (17:57:14.081)
Trace[44267262]: [30.005265077s] [30.005265077s] END
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.27.4/tools/cache/reflector.go:231: failed to list *v1.Namespace: Get "https://10.96.0.1:443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[ERROR] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.27.4/tools/cache/reflector.go:231: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: Get "https://10.96.0.1:443/apis/discovery.k8s.io/v1/endpointslices?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[INFO] plugin/kubernetes: Trace[2139308455]: "Reflector ListAndWatch" name:pkg/mod/k8s.io/client-go@v0.27.4/tools/cache/reflector.go:231 (23-Sep-2024 17:56:44.077) (total time: 30005ms):
Trace[2139308455]: ---"Objects listed" error:Get "https://10.96.0.1:443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout 30004ms (17:57:14.082)
Trace[2139308455]: [30.005566263s] [30.005566263s] END
[ERROR] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.27.4/tools/cache/reflector.go:231: Failed to watch *v1.Namespace: failed to list *v1.Namespace: Get "https://10.96.0.1:443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.27.4/tools/cache/reflector.go:231: failed to list *v1.Service: Get "https://10.96.0.1:443/api/v1/services?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[INFO] plugin/kubernetes: Trace[449697516]: "Reflector ListAndWatch" name:pkg/mod/k8s.io/client-go@v0.27.4/tools/cache/reflector.go:231 (23-Sep-2024 17:56:44.077) (total time: 30005ms):
Trace[449697516]: ---"Objects listed" error:Get "https://10.96.0.1:443/api/v1/services?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout 30004ms (17:57:14.081)
Trace[449697516]: [30.005831305s] [30.005831305s] END
[ERROR] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.27.4/tools/cache/reflector.go:231: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://10.96.0.1:443/api/v1/services?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[INFO] SIGTERM: Shutting down servers then terminating
[INFO] plugin/health: Going into lameduck mode for 5s


==> describe nodes <==
command /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" failed with error: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0924 03:32:49.880484   19094 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:32:49.883130   19094 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:32:49.887444   19094 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:32:49.889912   19094 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
E0924 03:32:49.892212   19094 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp 127.0.0.1:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?


==> dmesg <==
[  +0.000010] CPU: 2 PID: 2339 Comm: modprobe Tainted: G           OE      6.8.0-40-generic #40~22.04.3-Ubuntu
[  +0.000011] Hardware name: Dell Inc. Latitude 5300/0932VT, BIOS 1.26.0 04/11/2023
[  +0.000005] Call Trace:
[  +0.000005]  <TASK>
[  +0.000005]  dump_stack_lvl+0x76/0xa0
[  +0.000018]  dump_stack+0x10/0x20
[  +0.000012]  __ubsan_handle_out_of_bounds+0xc6/0x110
[  +0.000013]  VBoxHost_RTLogLoggerExV+0x3d8/0x580 [vboxdrv]
[  +0.000166]  ? vprintk_default+0x1d/0x30
[  +0.000013]  ? vprintk+0x42/0x80
[  +0.000011]  ? _printk+0x60/0x90
[  +0.000014]  VBoxHost_RTLogLoggerEx+0x51/0x80 [vboxdrv]
[  +0.000161]  ? VBoxHost_RTLogRelGetDefaultInstanceEx+0xa2/0xb0 [vboxdrv]
[  +0.000158]  VBoxNetFltLinuxInit+0x65/0xff0 [vboxnetflt]
[  +0.000029]  ? __pfx_VBoxNetFltLinuxInit+0x10/0x10 [vboxnetflt]
[  +0.000025]  do_one_initcall+0x5b/0x340
[  +0.000020]  do_init_module+0x97/0x290
[  +0.000011]  load_module+0xb85/0xcd0
[  +0.000014]  ? security_kernel_post_read_file+0x75/0x90
[  +0.000018]  init_module_from_file+0x96/0x100
[  +0.000010]  ? init_module_from_file+0x96/0x100
[  +0.000019]  idempotent_init_module+0x11c/0x2b0
[  +0.000015]  __x64_sys_finit_module+0x64/0xd0
[  +0.000011]  x64_sys_call+0x169c/0x24b0
[  +0.000010]  do_syscall_64+0x81/0x170
[  +0.000012]  ? vfs_read+0x2c0/0x390
[  +0.000010]  ? vfs_read+0x2c0/0x390
[  +0.000009]  ? rseq_get_rseq_cs+0x22/0x280
[  +0.000014]  ? rseq_ip_fixup+0x90/0x1f0
[  +0.000014]  ? restore_fpregs_from_fpstate+0x47/0xf0
[  +0.000015]  ? switch_fpu_return+0x55/0xf0
[  +0.000013]  ? syscall_exit_to_user_mode+0x89/0x260
[  +0.000015]  ? do_syscall_64+0x8d/0x170
[  +0.000012]  ? syscall_exit_to_user_mode+0x89/0x260
[  +0.000013]  ? do_syscall_64+0x8d/0x170
[  +0.000013]  ? nvme_irq+0x73/0x80 [nvme]
[  +0.000031]  ? __pfx_nvme_pci_complete_batch+0x10/0x10 [nvme]
[  +0.000031]  ? handle_irq_event+0x52/0x80
[  +0.000013]  ? irqentry_exit_to_user_mode+0x7e/0x260
[  +0.000015]  ? clear_bhb_loop+0x15/0x70
[  +0.000009]  ? clear_bhb_loop+0x15/0x70
[  +0.000009]  ? clear_bhb_loop+0x15/0x70
[  +0.000009]  entry_SYSCALL_64_after_hwframe+0x78/0x80
[  +0.000013] RIP: 0033:0x7cff0d91e88d
[  +0.000043] Code: 5b 41 5c c3 66 0f 1f 84 00 00 00 00 00 f3 0f 1e fa 48 89 f8 48 89 f7 48 89 d6 48 89 ca 4d 89 c2 4d 89 c8 4c 8b 4c 24 08 0f 05 <48> 3d 01 f0 ff ff 73 01 c3 48 8b 0d 73 b5 0f 00 f7 d8 64 89 01 48
[  +0.000009] RSP: 002b:00007ffe863c3098 EFLAGS: 00000246 ORIG_RAX: 0000000000000139
[  +0.000012] RAX: ffffffffffffffda RBX: 000060e91e3bed40 RCX: 00007cff0d91e88d
[  +0.000007] RDX: 0000000000000000 RSI: 000060e91c993cd2 RDI: 0000000000000003
[  +0.000007] RBP: 0000000000040000 R08: 0000000000000000 R09: 0000000000000002
[  +0.000007] R10: 0000000000000003 R11: 0000000000000246 R12: 000060e91c993cd2
[  +0.000006] R13: 000060e91e3bedc0 R14: 000060e91e3be610 R15: 000060e91e3bf210
[  +0.000013]  </TASK>
[  +0.000023] ---[ end trace ]---
[  +0.000009] VBoxNetFlt: Successfully started.
[  +0.069202] VBoxNetAdp: Successfully started.
[  +3.614495] kauditd_printk_skb: 20 callbacks suppressed
[ +19.954511] kauditd_printk_skb: 17 callbacks suppressed
[Sep24 03:19] warning: `sssd' uses wireless extensions which will stop working for Wi-Fi 7 hardware; use nl80211
[ +16.939676] kauditd_printk_skb: 38 callbacks suppressed
[Sep24 03:26] kauditd_printk_skb: 37 callbacks suppressed


==> etcd [d479a78946ad] <==
{"level":"info","ts":"2024-09-23T17:56:36.224434Z","caller":"etcdmain/etcd.go:73","msg":"Running: ","args":["etcd","--advertise-client-urls=https://192.168.49.2:2379","--cert-file=/var/lib/minikube/certs/etcd/server.crt","--client-cert-auth=true","--data-dir=/var/lib/minikube/etcd","--experimental-initial-corrupt-check=true","--experimental-watch-progress-notify-interval=5s","--initial-advertise-peer-urls=https://192.168.49.2:2380","--initial-cluster=minikube=https://192.168.49.2:2380","--key-file=/var/lib/minikube/certs/etcd/server.key","--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379","--listen-metrics-urls=http://127.0.0.1:2381","--listen-peer-urls=https://192.168.49.2:2380","--name=minikube","--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt","--peer-client-cert-auth=true","--peer-key-file=/var/lib/minikube/certs/etcd/peer.key","--peer-trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt","--proxy-refresh-interval=70000","--snapshot-count=10000","--trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt"]}
{"level":"info","ts":"2024-09-23T17:56:36.224719Z","caller":"etcdmain/etcd.go:116","msg":"server has been already initialized","data-dir":"/var/lib/minikube/etcd","dir-type":"member"}
{"level":"warn","ts":"2024-09-23T17:56:36.225153Z","caller":"embed/config.go:687","msg":"Running http and grpc server on single port. This is not recommended for production."}
{"level":"info","ts":"2024-09-23T17:56:36.225221Z","caller":"embed/etcd.go:128","msg":"configuring peer listeners","listen-peer-urls":["https://192.168.49.2:2380"]}
{"level":"info","ts":"2024-09-23T17:56:36.225340Z","caller":"embed/etcd.go:496","msg":"starting with peer TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/peer.crt, key = /var/lib/minikube/certs/etcd/peer.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2024-09-23T17:56:36.232248Z","caller":"embed/etcd.go:136","msg":"configuring client listeners","listen-client-urls":["https://127.0.0.1:2379","https://192.168.49.2:2379"]}
{"level":"info","ts":"2024-09-23T17:56:36.234070Z","caller":"embed/etcd.go:310","msg":"starting an etcd server","etcd-version":"3.5.15","git-sha":"9a5533382","go-version":"go1.21.12","go-os":"linux","go-arch":"amd64","max-cpu-set":8,"max-cpu-available":8,"member-initialized":true,"name":"minikube","data-dir":"/var/lib/minikube/etcd","wal-dir":"","wal-dir-dedicated":"","member-dir":"/var/lib/minikube/etcd/member","force-new-cluster":false,"heartbeat-interval":"100ms","election-timeout":"1s","initial-election-tick-advance":true,"snapshot-count":10000,"max-wals":5,"max-snapshots":5,"snapshot-catchup-entries":5000,"initial-advertise-peer-urls":["https://192.168.49.2:2380"],"listen-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"],"listen-client-urls":["https://127.0.0.1:2379","https://192.168.49.2:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"],"cors":["*"],"host-whitelist":["*"],"initial-cluster":"","initial-cluster-state":"new","initial-cluster-token":"","quota-backend-bytes":2147483648,"max-request-bytes":1572864,"max-concurrent-streams":4294967295,"pre-vote":true,"initial-corrupt-check":true,"corrupt-check-time-interval":"0s","compact-check-time-enabled":false,"compact-check-time-interval":"1m0s","auto-compaction-mode":"periodic","auto-compaction-retention":"0s","auto-compaction-interval":"0s","discovery-url":"","discovery-proxy":"","downgrade-check-interval":"5s"}
{"level":"info","ts":"2024-09-23T17:56:36.286169Z","caller":"etcdserver/backend.go:81","msg":"opened backend db","path":"/var/lib/minikube/etcd/member/snap/db","took":"49.75906ms"}
{"level":"info","ts":"2024-09-23T17:56:36.456046Z","caller":"etcdserver/server.go:511","msg":"recovered v2 store from snapshot","snapshot-index":10001,"snapshot-size":"7.5 kB"}
{"level":"info","ts":"2024-09-23T17:56:36.456288Z","caller":"etcdserver/server.go:524","msg":"recovered v3 backend from snapshot","backend-size-bytes":3264512,"backend-size":"3.3 MB","backend-size-in-use-bytes":1335296,"backend-size-in-use":"1.3 MB"}
{"level":"info","ts":"2024-09-23T17:56:36.653929Z","caller":"etcdserver/raft.go:530","msg":"restarting local member","cluster-id":"fa54960ea34d58be","local-member-id":"aec36adc501070cc","commit-index":13726}
{"level":"info","ts":"2024-09-23T17:56:36.655504Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc switched to configuration voters=(12593026477526642892)"}
{"level":"info","ts":"2024-09-23T17:56:36.655727Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became follower at term 3"}
{"level":"info","ts":"2024-09-23T17:56:36.655788Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"newRaft aec36adc501070cc [peers: [aec36adc501070cc], term: 3, commit: 13726, applied: 10001, lastindex: 13726, lastterm: 3]"}
{"level":"info","ts":"2024-09-23T17:56:36.656144Z","caller":"api/capability.go:75","msg":"enabled capabilities for version","cluster-version":"3.5"}
{"level":"info","ts":"2024-09-23T17:56:36.656220Z","caller":"membership/cluster.go:278","msg":"recovered/added member from store","cluster-id":"fa54960ea34d58be","local-member-id":"aec36adc501070cc","recovered-remote-peer-id":"aec36adc501070cc","recovered-remote-peer-urls":["https://192.168.49.2:2380"]}
{"level":"info","ts":"2024-09-23T17:56:36.656274Z","caller":"membership/cluster.go:287","msg":"set cluster version from store","cluster-version":"3.5"}
{"level":"warn","ts":"2024-09-23T17:56:36.657800Z","caller":"auth/store.go:1241","msg":"simple token is not cryptographically signed"}
{"level":"info","ts":"2024-09-23T17:56:36.659084Z","caller":"mvcc/kvstore.go:341","msg":"restored last compact revision","meta-bucket-name":"meta","meta-bucket-name-key":"finishedCompactRev","restored-compact-revision":10718}
{"level":"info","ts":"2024-09-23T17:56:36.669707Z","caller":"mvcc/kvstore.go:418","msg":"kvstore restored","current-rev":11069}
{"level":"info","ts":"2024-09-23T17:56:36.671632Z","caller":"etcdserver/quota.go:94","msg":"enabled backend quota with default value","quota-name":"v3-applier","quota-size-bytes":2147483648,"quota-size":"2.1 GB"}
{"level":"info","ts":"2024-09-23T17:56:36.677130Z","caller":"etcdserver/corrupt.go:96","msg":"starting initial corruption check","local-member-id":"aec36adc501070cc","timeout":"7s"}
{"level":"info","ts":"2024-09-23T17:56:36.678267Z","caller":"etcdserver/corrupt.go:177","msg":"initial corruption checking passed; no corruption","local-member-id":"aec36adc501070cc"}
{"level":"info","ts":"2024-09-23T17:56:36.678772Z","caller":"etcdserver/server.go:858","msg":"starting etcd server","local-member-id":"aec36adc501070cc","local-server-version":"3.5.15","cluster-id":"fa54960ea34d58be","cluster-version":"3.5"}
{"level":"info","ts":"2024-09-23T17:56:36.679502Z","caller":"etcdserver/server.go:751","msg":"started as single-node; fast-forwarding election ticks","local-member-id":"aec36adc501070cc","forward-ticks":9,"forward-duration":"900ms","election-ticks":10,"election-timeout":"1s"}
{"level":"info","ts":"2024-09-23T17:56:36.679923Z","caller":"fileutil/purge.go:50","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/snap","suffix":"snap.db","max":5,"interval":"30s"}
{"level":"info","ts":"2024-09-23T17:56:36.680294Z","caller":"fileutil/purge.go:50","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/snap","suffix":"snap","max":5,"interval":"30s"}
{"level":"info","ts":"2024-09-23T17:56:36.680458Z","caller":"fileutil/purge.go:50","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/wal","suffix":"wal","max":5,"interval":"30s"}
{"level":"info","ts":"2024-09-23T17:56:36.685365Z","caller":"v3rpc/health.go:61","msg":"grpc service status changed","service":"","status":"SERVING"}
{"level":"info","ts":"2024-09-23T17:56:36.697169Z","caller":"embed/etcd.go:728","msg":"starting with client TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/server.crt, key = /var/lib/minikube/certs/etcd/server.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2024-09-23T17:56:36.697779Z","caller":"embed/etcd.go:599","msg":"serving peer traffic","address":"192.168.49.2:2380"}
{"level":"info","ts":"2024-09-23T17:56:36.697935Z","caller":"embed/etcd.go:571","msg":"cmux::serve","address":"192.168.49.2:2380"}
{"level":"info","ts":"2024-09-23T17:56:36.698848Z","caller":"embed/etcd.go:279","msg":"now serving peer/client/metrics","local-member-id":"aec36adc501070cc","initial-advertise-peer-urls":["https://192.168.49.2:2380"],"listen-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"],"listen-client-urls":["https://127.0.0.1:2379","https://192.168.49.2:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"]}
{"level":"info","ts":"2024-09-23T17:56:36.698930Z","caller":"embed/etcd.go:870","msg":"serving metrics","address":"http://127.0.0.1:2381"}
{"level":"info","ts":"2024-09-23T17:56:37.157899Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc is starting a new election at term 3"}
{"level":"info","ts":"2024-09-23T17:56:37.158025Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became pre-candidate at term 3"}
{"level":"info","ts":"2024-09-23T17:56:37.158156Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc received MsgPreVoteResp from aec36adc501070cc at term 3"}
{"level":"info","ts":"2024-09-23T17:56:37.158212Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became candidate at term 4"}
{"level":"info","ts":"2024-09-23T17:56:37.158238Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc received MsgVoteResp from aec36adc501070cc at term 4"}
{"level":"info","ts":"2024-09-23T17:56:37.158269Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became leader at term 4"}
{"level":"info","ts":"2024-09-23T17:56:37.158442Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"raft.node: aec36adc501070cc elected leader aec36adc501070cc at term 4"}
{"level":"info","ts":"2024-09-23T17:56:37.169129Z","caller":"etcdserver/server.go:2118","msg":"published local member to cluster through raft","local-member-id":"aec36adc501070cc","local-member-attributes":"{Name:minikube ClientURLs:[https://192.168.49.2:2379]}","request-path":"/0/members/aec36adc501070cc/attributes","cluster-id":"fa54960ea34d58be","publish-timeout":"7s"}
{"level":"info","ts":"2024-09-23T17:56:37.169170Z","caller":"embed/serve.go:103","msg":"ready to serve client requests"}
{"level":"info","ts":"2024-09-23T17:56:37.169202Z","caller":"embed/serve.go:103","msg":"ready to serve client requests"}
{"level":"info","ts":"2024-09-23T17:56:37.169494Z","caller":"etcdmain/main.go:44","msg":"notifying init daemon"}
{"level":"info","ts":"2024-09-23T17:56:37.169590Z","caller":"etcdmain/main.go:50","msg":"successfully notified init daemon"}
{"level":"info","ts":"2024-09-23T17:56:37.172485Z","caller":"v3rpc/health.go:61","msg":"grpc service status changed","service":"","status":"SERVING"}
{"level":"info","ts":"2024-09-23T17:56:37.172488Z","caller":"v3rpc/health.go:61","msg":"grpc service status changed","service":"","status":"SERVING"}
{"level":"info","ts":"2024-09-23T17:56:37.175916Z","caller":"embed/serve.go:250","msg":"serving client traffic securely","traffic":"grpc+http","address":"192.168.49.2:2379"}
{"level":"info","ts":"2024-09-23T17:56:37.175987Z","caller":"embed/serve.go:250","msg":"serving client traffic securely","traffic":"grpc+http","address":"127.0.0.1:2379"}
{"level":"info","ts":"2024-09-23T17:57:20.638630Z","caller":"osutil/interrupt_unix.go:64","msg":"received signal; shutting down","signal":"terminated"}
{"level":"info","ts":"2024-09-23T17:57:20.638824Z","caller":"embed/etcd.go:377","msg":"closing etcd server","name":"minikube","data-dir":"/var/lib/minikube/etcd","advertise-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"]}
{"level":"warn","ts":"2024-09-23T17:57:20.639120Z","caller":"embed/serve.go:212","msg":"stopping secure grpc server due to error","error":"accept tcp 127.0.0.1:2379: use of closed network connection"}
{"level":"warn","ts":"2024-09-23T17:57:20.645715Z","caller":"embed/serve.go:214","msg":"stopped secure grpc server due to error","error":"accept tcp 127.0.0.1:2379: use of closed network connection"}
{"level":"warn","ts":"2024-09-23T17:57:20.695002Z","caller":"embed/serve.go:212","msg":"stopping secure grpc server due to error","error":"accept tcp 192.168.49.2:2379: use of closed network connection"}
{"level":"warn","ts":"2024-09-23T17:57:20.695161Z","caller":"embed/serve.go:214","msg":"stopped secure grpc server due to error","error":"accept tcp 192.168.49.2:2379: use of closed network connection"}
{"level":"info","ts":"2024-09-23T17:57:20.695770Z","caller":"etcdserver/server.go:1521","msg":"skipped leadership transfer for single voting member cluster","local-member-id":"aec36adc501070cc","current-leader-member-id":"aec36adc501070cc"}
{"level":"info","ts":"2024-09-23T17:57:20.703931Z","caller":"embed/etcd.go:581","msg":"stopping serving peer traffic","address":"192.168.49.2:2380"}
{"level":"info","ts":"2024-09-23T17:57:20.704292Z","caller":"embed/etcd.go:586","msg":"stopped serving peer traffic","address":"192.168.49.2:2380"}
{"level":"info","ts":"2024-09-23T17:57:20.704823Z","caller":"embed/etcd.go:379","msg":"closed etcd server","name":"minikube","data-dir":"/var/lib/minikube/etcd","advertise-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"]}


==> etcd [f4eedf241c60] <==
{"level":"info","ts":"2024-09-23T12:58:53.848162Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":8083}
{"level":"info","ts":"2024-09-23T12:58:53.849639Z","caller":"mvcc/kvstore_compaction.go:69","msg":"finished scheduled compaction","compact-revision":8083,"took":"1.333792ms","hash":3350955963,"current-db-size-bytes":3264512,"current-db-size":"3.3 MB","current-db-size-in-use-bytes":1626112,"current-db-size-in-use":"1.6 MB"}
{"level":"info","ts":"2024-09-23T12:58:53.849665Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":3350955963,"revision":8083,"compact-revision":7845}
{"level":"info","ts":"2024-09-23T13:03:53.861583Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":8324}
{"level":"info","ts":"2024-09-23T13:03:53.865516Z","caller":"mvcc/kvstore_compaction.go:69","msg":"finished scheduled compaction","compact-revision":8324,"took":"3.472439ms","hash":4212144027,"current-db-size-bytes":3264512,"current-db-size":"3.3 MB","current-db-size-in-use-bytes":1634304,"current-db-size-in-use":"1.6 MB"}
{"level":"info","ts":"2024-09-23T13:03:53.865586Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":4212144027,"revision":8324,"compact-revision":8083}
{"level":"info","ts":"2024-09-23T13:08:53.875989Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":8563}
{"level":"info","ts":"2024-09-23T13:08:53.880038Z","caller":"mvcc/kvstore_compaction.go:69","msg":"finished scheduled compaction","compact-revision":8563,"took":"3.602394ms","hash":3597822405,"current-db-size-bytes":3264512,"current-db-size":"3.3 MB","current-db-size-in-use-bytes":1609728,"current-db-size-in-use":"1.6 MB"}
{"level":"info","ts":"2024-09-23T13:08:53.880115Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":3597822405,"revision":8563,"compact-revision":8324}
{"level":"info","ts":"2024-09-23T13:13:53.890014Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":8802}
{"level":"info","ts":"2024-09-23T13:13:53.893729Z","caller":"mvcc/kvstore_compaction.go:69","msg":"finished scheduled compaction","compact-revision":8802,"took":"3.292012ms","hash":2034295653,"current-db-size-bytes":3264512,"current-db-size":"3.3 MB","current-db-size-in-use-bytes":1601536,"current-db-size-in-use":"1.6 MB"}
{"level":"info","ts":"2024-09-23T13:13:53.893792Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":2034295653,"revision":8802,"compact-revision":8563}
{"level":"info","ts":"2024-09-23T13:18:53.901167Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":9042}
{"level":"info","ts":"2024-09-23T13:18:53.902676Z","caller":"mvcc/kvstore_compaction.go:69","msg":"finished scheduled compaction","compact-revision":9042,"took":"1.355464ms","hash":4160486810,"current-db-size-bytes":3264512,"current-db-size":"3.3 MB","current-db-size-in-use-bytes":1617920,"current-db-size-in-use":"1.6 MB"}
{"level":"info","ts":"2024-09-23T13:18:53.902695Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":4160486810,"revision":9042,"compact-revision":8802}
{"level":"info","ts":"2024-09-23T13:23:53.912381Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":9281}
{"level":"info","ts":"2024-09-23T13:23:53.914227Z","caller":"mvcc/kvstore_compaction.go:69","msg":"finished scheduled compaction","compact-revision":9281,"took":"1.631847ms","hash":4142411362,"current-db-size-bytes":3264512,"current-db-size":"3.3 MB","current-db-size-in-use-bytes":1597440,"current-db-size-in-use":"1.6 MB"}
{"level":"info","ts":"2024-09-23T13:23:53.914255Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":4142411362,"revision":9281,"compact-revision":9042}
{"level":"info","ts":"2024-09-23T13:28:53.916182Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":9521}
{"level":"info","ts":"2024-09-23T13:28:53.917597Z","caller":"mvcc/kvstore_compaction.go:69","msg":"finished scheduled compaction","compact-revision":9521,"took":"1.267619ms","hash":2809855840,"current-db-size-bytes":3264512,"current-db-size":"3.3 MB","current-db-size-in-use-bytes":1622016,"current-db-size-in-use":"1.6 MB"}
{"level":"info","ts":"2024-09-23T13:28:53.917615Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":2809855840,"revision":9521,"compact-revision":9281}
{"level":"info","ts":"2024-09-23T13:33:53.926476Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":9760}
{"level":"info","ts":"2024-09-23T13:33:53.927857Z","caller":"mvcc/kvstore_compaction.go:69","msg":"finished scheduled compaction","compact-revision":9760,"took":"1.241991ms","hash":270696022,"current-db-size-bytes":3264512,"current-db-size":"3.3 MB","current-db-size-in-use-bytes":1634304,"current-db-size-in-use":"1.6 MB"}
{"level":"info","ts":"2024-09-23T13:33:53.927877Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":270696022,"revision":9760,"compact-revision":9521}
{"level":"info","ts":"2024-09-23T13:38:53.930305Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":10000}
{"level":"info","ts":"2024-09-23T13:38:53.932553Z","caller":"mvcc/kvstore_compaction.go:69","msg":"finished scheduled compaction","compact-revision":10000,"took":"1.966126ms","hash":2978194660,"current-db-size-bytes":3264512,"current-db-size":"3.3 MB","current-db-size-in-use-bytes":1634304,"current-db-size-in-use":"1.6 MB"}
{"level":"info","ts":"2024-09-23T13:38:53.932648Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":2978194660,"revision":10000,"compact-revision":9760}
{"level":"info","ts":"2024-09-23T13:43:53.942710Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":10239}
{"level":"info","ts":"2024-09-23T13:43:53.946637Z","caller":"mvcc/kvstore_compaction.go:69","msg":"finished scheduled compaction","compact-revision":10239,"took":"3.446267ms","hash":3234473971,"current-db-size-bytes":3264512,"current-db-size":"3.3 MB","current-db-size-in-use-bytes":1650688,"current-db-size-in-use":"1.7 MB"}
{"level":"info","ts":"2024-09-23T13:43:53.946733Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":3234473971,"revision":10239,"compact-revision":10000}
{"level":"info","ts":"2024-09-23T13:48:53.951539Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":10478}
{"level":"info","ts":"2024-09-23T13:48:53.957240Z","caller":"mvcc/kvstore_compaction.go:69","msg":"finished scheduled compaction","compact-revision":10478,"took":"5.084453ms","hash":1472707817,"current-db-size-bytes":3264512,"current-db-size":"3.3 MB","current-db-size-in-use-bytes":1642496,"current-db-size-in-use":"1.6 MB"}
{"level":"info","ts":"2024-09-23T13:48:53.957380Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":1472707817,"revision":10478,"compact-revision":10239}
{"level":"info","ts":"2024-09-23T13:53:53.967352Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":10718}
{"level":"info","ts":"2024-09-23T13:53:54.002352Z","caller":"mvcc/kvstore_compaction.go:69","msg":"finished scheduled compaction","compact-revision":10718,"took":"34.413804ms","hash":2178739482,"current-db-size-bytes":3264512,"current-db-size":"3.3 MB","current-db-size-in-use-bytes":1638400,"current-db-size-in-use":"1.6 MB"}
{"level":"info","ts":"2024-09-23T13:53:54.002485Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":2178739482,"revision":10718,"compact-revision":10478}
{"level":"warn","ts":"2024-09-23T13:57:28.460438Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"155.373223ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/runtimeclasses/\" range_end:\"/registry/runtimeclasses0\" count_only:true ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2024-09-23T13:57:28.465850Z","caller":"traceutil/trace.go:171","msg":"trace[413425551] range","detail":"{range_begin:/registry/runtimeclasses/; range_end:/registry/runtimeclasses0; response_count:0; response_revision:11005; }","duration":"157.74893ms","start":"2024-09-23T13:57:28.302889Z","end":"2024-09-23T13:57:28.460638Z","steps":["trace[413425551] 'agreement among raft nodes before linearized reading'  (duration: 155.299736ms)"],"step_count":1}
{"level":"info","ts":"2024-09-23T13:57:28.469566Z","caller":"traceutil/trace.go:171","msg":"trace[250116084] linearizableReadLoop","detail":"{readStateIndex:13644; appliedIndex:13643; }","duration":"154.889255ms","start":"2024-09-23T13:57:28.302899Z","end":"2024-09-23T13:57:28.457788Z","steps":["trace[250116084] 'read index received'  (duration: 81.766186ms)","trace[250116084] 'applied index is now lower than readState.Index'  (duration: 73.111141ms)"],"step_count":2}
{"level":"info","ts":"2024-09-23T13:57:28.479538Z","caller":"traceutil/trace.go:171","msg":"trace[967462916] transaction","detail":"{read_only:false; response_revision:11005; number_of_response:1; }","duration":"129.194218ms","start":"2024-09-23T13:57:28.318760Z","end":"2024-09-23T13:57:28.447954Z","steps":["trace[967462916] 'process raft request'  (duration: 128.926577ms)"],"step_count":1}
{"level":"warn","ts":"2024-09-23T13:57:28.486513Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"183.025915ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/events/\" range_end:\"/registry/events0\" count_only:true ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2024-09-23T13:57:28.486663Z","caller":"traceutil/trace.go:171","msg":"trace[1504243511] range","detail":"{range_begin:/registry/events/; range_end:/registry/events0; response_count:0; response_revision:11006; }","duration":"183.203642ms","start":"2024-09-23T13:57:28.303422Z","end":"2024-09-23T13:57:28.486626Z","steps":["trace[1504243511] 'agreement among raft nodes before linearized reading'  (duration: 182.916755ms)"],"step_count":1}
{"level":"warn","ts":"2024-09-23T13:57:28.488017Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"176.17137ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/controllers/\" range_end:\"/registry/controllers0\" count_only:true ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2024-09-23T13:57:28.488122Z","caller":"traceutil/trace.go:171","msg":"trace[514241435] range","detail":"{range_begin:/registry/controllers/; range_end:/registry/controllers0; response_count:0; response_revision:11006; }","duration":"176.296293ms","start":"2024-09-23T13:57:28.311796Z","end":"2024-09-23T13:57:28.488092Z","steps":["trace[514241435] 'agreement among raft nodes before linearized reading'  (duration: 176.119827ms)"],"step_count":1}
{"level":"warn","ts":"2024-09-23T13:57:28.488614Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"177.251809ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/services/endpoints/\" range_end:\"/registry/services/endpoints0\" count_only:true ","response":"range_response_count:0 size:7"}
{"level":"info","ts":"2024-09-23T13:57:28.488709Z","caller":"traceutil/trace.go:171","msg":"trace[175717554] range","detail":"{range_begin:/registry/services/endpoints/; range_end:/registry/services/endpoints0; response_count:0; response_revision:11006; }","duration":"177.349379ms","start":"2024-09-23T13:57:28.311329Z","end":"2024-09-23T13:57:28.488679Z","steps":["trace[175717554] 'agreement among raft nodes before linearized reading'  (duration: 177.204426ms)"],"step_count":1}
{"level":"warn","ts":"2024-09-23T13:57:28.492897Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"189.061869ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/controllerrevisions/\" range_end:\"/registry/controllerrevisions0\" count_only:true ","response":"range_response_count:0 size:7"}
{"level":"info","ts":"2024-09-23T13:57:28.493038Z","caller":"traceutil/trace.go:171","msg":"trace[2039208156] range","detail":"{range_begin:/registry/controllerrevisions/; range_end:/registry/controllerrevisions0; response_count:0; response_revision:11006; }","duration":"189.22959ms","start":"2024-09-23T13:57:28.303768Z","end":"2024-09-23T13:57:28.492997Z","steps":["trace[2039208156] 'agreement among raft nodes before linearized reading'  (duration: 188.98213ms)"],"step_count":1}
{"level":"warn","ts":"2024-09-23T13:57:28.493632Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"182.487725ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/podtemplates/\" range_end:\"/registry/podtemplates0\" count_only:true ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2024-09-23T13:57:28.493727Z","caller":"traceutil/trace.go:171","msg":"trace[1683578086] range","detail":"{range_begin:/registry/podtemplates/; range_end:/registry/podtemplates0; response_count:0; response_revision:11006; }","duration":"182.597349ms","start":"2024-09-23T13:57:28.311101Z","end":"2024-09-23T13:57:28.493698Z","steps":["trace[1683578086] 'agreement among raft nodes before linearized reading'  (duration: 182.439147ms)"],"step_count":1}
{"level":"warn","ts":"2024-09-23T13:57:28.508382Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"198.625727ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/volumeattachments/\" range_end:\"/registry/volumeattachments0\" count_only:true ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2024-09-23T13:57:28.508524Z","caller":"traceutil/trace.go:171","msg":"trace[1941727817] range","detail":"{range_begin:/registry/volumeattachments/; range_end:/registry/volumeattachments0; response_count:0; response_revision:11006; }","duration":"198.782033ms","start":"2024-09-23T13:57:28.309698Z","end":"2024-09-23T13:57:28.508480Z","steps":["trace[1941727817] 'agreement among raft nodes before linearized reading'  (duration: 198.552079ms)"],"step_count":1}
{"level":"warn","ts":"2024-09-23T13:57:28.509051Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"199.140536ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/masterleases/192.168.49.2\" ","response":"range_response_count:1 size:133"}
{"level":"warn","ts":"2024-09-23T13:57:28.567469Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"183.136841ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/flowschemas/\" range_end:\"/registry/flowschemas0\" count_only:true ","response":"range_response_count:0 size:7"}
{"level":"info","ts":"2024-09-23T13:57:28.567652Z","caller":"traceutil/trace.go:171","msg":"trace[2127211539] range","detail":"{range_begin:/registry/flowschemas/; range_end:/registry/flowschemas0; response_count:0; response_revision:11006; }","duration":"256.617063ms","start":"2024-09-23T13:57:28.310991Z","end":"2024-09-23T13:57:28.567608Z","steps":["trace[2127211539] 'agreement among raft nodes before linearized reading'  (duration: 183.090433ms)"],"step_count":1}
{"level":"info","ts":"2024-09-23T13:57:28.509139Z","caller":"traceutil/trace.go:171","msg":"trace[297718638] range","detail":"{range_begin:/registry/masterleases/192.168.49.2; range_end:; response_count:1; response_revision:11006; }","duration":"199.23512ms","start":"2024-09-23T13:57:28.309878Z","end":"2024-09-23T13:57:28.509113Z","steps":["trace[297718638] 'agreement among raft nodes before linearized reading'  (duration: 199.048345ms)"],"step_count":1}
{"level":"warn","ts":"2024-09-23T13:57:28.576342Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"265.042689ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/statefulsets/\" range_end:\"/registry/statefulsets0\" count_only:true ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2024-09-23T13:57:28.576474Z","caller":"traceutil/trace.go:171","msg":"trace[762565995] range","detail":"{range_begin:/registry/statefulsets/; range_end:/registry/statefulsets0; response_count:0; response_revision:11006; }","duration":"265.196176ms","start":"2024-09-23T13:57:28.311235Z","end":"2024-09-23T13:57:28.576431Z","steps":["trace[762565995] 'agreement among raft nodes before linearized reading'  (duration: 177.817144ms)","trace[762565995] 'count revisions from in-memory index tree'  (duration: 87.172856ms)"],"step_count":2}
{"level":"info","ts":"2024-09-23T13:57:28.910012Z","caller":"traceutil/trace.go:171","msg":"trace[1292526754] transaction","detail":"{read_only:false; response_revision:11007; number_of_response:1; }","duration":"169.531996ms","start":"2024-09-23T13:57:28.740382Z","end":"2024-09-23T13:57:28.909914Z","steps":["trace[1292526754] 'process raft request'  (duration: 117.165525ms)","trace[1292526754] 'compare'  (duration: 45.962684ms)"],"step_count":2}
{"level":"info","ts":"2024-09-23T13:57:28.905516Z","caller":"traceutil/trace.go:171","msg":"trace[1036774330] transaction","detail":"{read_only:false; response_revision:11008; number_of_response:1; }","duration":"103.636142ms","start":"2024-09-23T13:57:28.801833Z","end":"2024-09-23T13:57:28.905469Z","steps":["trace[1036774330] 'process raft request'  (duration: 103.424059ms)"],"step_count":1}


==> kernel <==
 03:32:50 up 14 min,  0 users,  load average: 1.68, 2.13, 1.98
Linux minikube 6.8.0-40-generic #40~22.04.3-Ubuntu SMP PREEMPT_DYNAMIC Tue Jul 30 17:30:19 UTC 2 x86_64 x86_64 x86_64 GNU/Linux
PRETTY_NAME="Ubuntu 22.04.4 LTS"


==> kube-apiserver [3957ce6e0e5c] <==
I0923 10:38:54.270163       1 nonstructuralschema_controller.go:195] Starting NonStructuralSchemaConditionController
I0923 10:38:54.308969       1 shared_informer.go:320] Caches are synced for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0923 10:38:54.309283       1 policy_source.go:224] refreshing policies
I0923 10:38:54.370096       1 apf_controller.go:382] Running API Priority and Fairness config worker
I0923 10:38:54.370112       1 shared_informer.go:320] Caches are synced for cluster_authentication_trust_controller
I0923 10:38:54.370119       1 apf_controller.go:385] Running API Priority and Fairness periodic rebalancing process
I0923 10:38:54.370093       1 cache.go:39] Caches are synced for APIServiceRegistrationController controller
I0923 10:38:54.370875       1 shared_informer.go:320] Caches are synced for configmaps
I0923 10:38:54.370917       1 cache.go:39] Caches are synced for LocalAvailability controller
I0923 10:38:54.370969       1 cache.go:39] Caches are synced for RemoteAvailability controller
I0923 10:38:54.371039       1 shared_informer.go:320] Caches are synced for crd-autoregister
I0923 10:38:54.371066       1 aggregator.go:171] initial CRD sync complete...
I0923 10:38:54.371074       1 autoregister_controller.go:144] Starting autoregister controller
I0923 10:38:54.371080       1 cache.go:32] Waiting for caches to sync for autoregister controller
I0923 10:38:54.371086       1 cache.go:39] Caches are synced for autoregister controller
I0923 10:38:54.380872       1 handler_discovery.go:450] Starting ResourceDiscoveryManager
I0923 10:38:54.384650       1 shared_informer.go:320] Caches are synced for node_authorizer
I0923 10:38:54.392300       1 controller.go:615] quota admission added evaluator for: leases.coordination.k8s.io
E0923 10:38:54.394474       1 controller.go:195] "Failed to update lease" err="Operation cannot be fulfilled on leases.coordination.k8s.io \"apiserver-eqt674mfxb4j56mrjjkoe7b7ii\": StorageError: invalid object, Code: 4, Key: /registry/leases/kube-system/apiserver-eqt674mfxb4j56mrjjkoe7b7ii, ResourceVersion: 0, AdditionalErrorMsg: Precondition failed: UID in precondition: 655a7e5e-15c0-49c9-b2a5-dcecd5a2e790, UID in object meta: "
I0923 10:38:54.584248       1 controller.go:615] quota admission added evaluator for: deployments.apps
I0923 10:38:54.730676       1 controller.go:615] quota admission added evaluator for: endpoints
I0923 10:38:55.281274       1 storage_scheduling.go:111] all system priority classes are created successfully or already exist.
I0923 10:38:59.381042       1 handler.go:286] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
E0923 10:38:59.388490       1 remote_available_controller.go:448] "Unhandled Error" err="v1beta1.metrics.k8s.io failed with: failing or missing response from https://10.111.240.187:443/apis/metrics.k8s.io/v1beta1: Get \"https://10.111.240.187:443/apis/metrics.k8s.io/v1beta1\": dial tcp 10.111.240.187:443: i/o timeout" logger="UnhandledError"
I0923 10:39:02.216633       1 controller.go:615] quota admission added evaluator for: endpointslices.discovery.k8s.io
E0923 10:39:02.494897       1 remote_available_controller.go:448] "Unhandled Error" err="v1beta1.metrics.k8s.io failed with: failing or missing response from https://10.111.240.187:443/apis/metrics.k8s.io/v1beta1: Get \"https://10.111.240.187:443/apis/metrics.k8s.io/v1beta1\": dial tcp 10.111.240.187:443: connect: no route to host" logger="UnhandledError"
E0923 10:39:02.540393       1 controller.go:113] "Unhandled Error" err="loading OpenAPI spec for \"v1beta1.metrics.k8s.io\" failed with: Error, could not get list of group versions for APIService" logger="UnhandledError"
I0923 10:39:02.541614       1 controller.go:126] OpenAPI AggregationController: action for item v1beta1.metrics.k8s.io: Rate Limited Requeue.
E0923 10:39:05.612580       1 controller.go:146] "Unhandled Error" err=<
	Error updating APIService "v1beta1.metrics.k8s.io" with err: failed to download v1beta1.metrics.k8s.io: failed to retrieve openAPI spec, http error: ResponseCode: 503, Body: error trying to reach service: dial tcp 10.111.240.187:443: connect: connection refused
	, Header: map[Content-Type:[text/plain; charset=utf-8] X-Content-Type-Options:[nosniff]]
 > logger="UnhandledError"
E0923 10:39:05.613598       1 controller.go:102] "Unhandled Error" err=<
	loading OpenAPI spec for "v1beta1.metrics.k8s.io" failed with: failed to download v1beta1.metrics.k8s.io: failed to retrieve openAPI spec, http error: ResponseCode: 503, Body: error trying to reach service: dial tcp 10.111.240.187:443: connect: connection refused
	, Header: map[Content-Type:[text/plain; charset=utf-8] X-Content-Type-Options:[nosniff]]
 > logger="UnhandledError"
W0923 10:39:05.613857       1 handler_proxy.go:99] no RequestInfo found in the context
E0923 10:39:05.613974       1 controller.go:146] "Unhandled Error" err=<
	Error updating APIService "v1beta1.metrics.k8s.io" with err: failed to download v1beta1.metrics.k8s.io: failed to retrieve openAPI spec, http error: ResponseCode: 503, Body: service unavailable
	, Header: map[Content-Type:[text/plain; charset=utf-8] X-Content-Type-Options:[nosniff]]
 > logger="UnhandledError"
I0923 10:39:05.614713       1 controller.go:109] OpenAPI AggregationController: action for item v1beta1.metrics.k8s.io: Rate Limited Requeue.
W0923 10:39:06.614115       1 handler_proxy.go:99] no RequestInfo found in the context
E0923 10:39:06.614148       1 controller.go:113] "Unhandled Error" err="loading OpenAPI spec for \"v1beta1.metrics.k8s.io\" failed with: Error, could not get list of group versions for APIService" logger="UnhandledError"
I0923 10:39:06.615282       1 controller.go:126] OpenAPI AggregationController: action for item v1beta1.metrics.k8s.io: Rate Limited Requeue.
W0923 10:39:06.616416       1 handler_proxy.go:99] no RequestInfo found in the context
E0923 10:39:06.616456       1 controller.go:102] "Unhandled Error" err=<
	loading OpenAPI spec for "v1beta1.metrics.k8s.io" failed with: failed to download v1beta1.metrics.k8s.io: failed to retrieve openAPI spec, http error: ResponseCode: 503, Body: service unavailable
	, Header: map[Content-Type:[text/plain; charset=utf-8] X-Content-Type-Options:[nosniff]]
 > logger="UnhandledError"
I0923 10:39:06.617555       1 controller.go:109] OpenAPI AggregationController: action for item v1beta1.metrics.k8s.io: Rate Limited Requeue.
W0923 10:39:57.972565       1 handler_proxy.go:99] no RequestInfo found in the context
E0923 10:39:57.972779       1 controller.go:146] "Unhandled Error" err=<
	Error updating APIService "v1beta1.metrics.k8s.io" with err: failed to download v1beta1.metrics.k8s.io: failed to retrieve openAPI spec, http error: ResponseCode: 503, Body: service unavailable
	, Header: map[Content-Type:[text/plain; charset=utf-8] X-Content-Type-Options:[nosniff]]
 > logger="UnhandledError"
E0923 10:39:57.973167       1 remote_available_controller.go:448] "Unhandled Error" err="v1beta1.metrics.k8s.io failed with: failing or missing response from https://10.111.240.187:443/apis/metrics.k8s.io/v1beta1: Get \"https://10.111.240.187:443/apis/metrics.k8s.io/v1beta1\": dial tcp 10.111.240.187:443: connect: connection refused" logger="UnhandledError"
E0923 10:39:57.977314       1 remote_available_controller.go:448] "Unhandled Error" err="v1beta1.metrics.k8s.io failed with: failing or missing response from https://10.111.240.187:443/apis/metrics.k8s.io/v1beta1: Get \"https://10.111.240.187:443/apis/metrics.k8s.io/v1beta1\": dial tcp 10.111.240.187:443: connect: connection refused" logger="UnhandledError"
E0923 10:39:57.982560       1 remote_available_controller.go:448] "Unhandled Error" err="v1beta1.metrics.k8s.io failed with: failing or missing response from https://10.111.240.187:443/apis/metrics.k8s.io/v1beta1: Get \"https://10.111.240.187:443/apis/metrics.k8s.io/v1beta1\": dial tcp 10.111.240.187:443: connect: connection refused" logger="UnhandledError"
I0923 10:39:58.101182       1 handler.go:286] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager


==> kube-apiserver [b181c5f7b9db] <==
W0923 17:57:26.363749       1 logging.go:55] [core] [Channel #178 SubChannel #179]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:26.391354       1 logging.go:55] [core] [Channel #109 SubChannel #110]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:26.530083       1 logging.go:55] [core] [Channel #58 SubChannel #59]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:28.529262       1 logging.go:55] [core] [Channel #103 SubChannel #104]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:28.987952       1 logging.go:55] [core] [Channel #28 SubChannel #29]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:29.032393       1 logging.go:55] [core] [Channel #112 SubChannel #113]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:29.059078       1 logging.go:55] [core] [Channel #160 SubChannel #161]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:29.237716       1 logging.go:55] [core] [Channel #166 SubChannel #167]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:29.258550       1 logging.go:55] [core] [Channel #22 SubChannel #23]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:29.259154       1 logging.go:55] [core] [Channel #142 SubChannel #143]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:29.266843       1 logging.go:55] [core] [Channel #34 SubChannel #35]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:29.272557       1 logging.go:55] [core] [Channel #85 SubChannel #86]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:29.290296       1 logging.go:55] [core] [Channel #94 SubChannel #95]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:29.300510       1 logging.go:55] [core] [Channel #40 SubChannel #41]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:29.364500       1 logging.go:55] [core] [Channel #76 SubChannel #77]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:29.389030       1 logging.go:55] [core] [Channel #151 SubChannel #152]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:29.505134       1 logging.go:55] [core] [Channel #79 SubChannel #80]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:29.510885       1 logging.go:55] [core] [Channel #181 SubChannel #182]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:29.511077       1 logging.go:55] [core] [Channel #133 SubChannel #134]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:29.563093       1 logging.go:55] [core] [Channel #7 SubChannel #8]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:29.596410       1 logging.go:55] [core] [Channel #52 SubChannel #53]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:29.600734       1 logging.go:55] [core] [Channel #121 SubChannel #122]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:29.711468       1 logging.go:55] [core] [Channel #184 SubChannel #185]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:29.749411       1 logging.go:55] [core] [Channel #175 SubChannel #176]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:29.828394       1 logging.go:55] [core] [Channel #130 SubChannel #131]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:29.851444       1 logging.go:55] [core] [Channel #88 SubChannel #89]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:29.852016       1 logging.go:55] [core] [Channel #70 SubChannel #71]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:29.874718       1 logging.go:55] [core] [Channel #115 SubChannel #116]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:29.920811       1 logging.go:55] [core] [Channel #169 SubChannel #170]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:29.940722       1 logging.go:55] [core] [Channel #64 SubChannel #65]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:29.960448       1 logging.go:55] [core] [Channel #97 SubChannel #98]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:29.969358       1 logging.go:55] [core] [Channel #37 SubChannel #38]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:30.000352       1 logging.go:55] [core] [Channel #82 SubChannel #83]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:30.048319       1 logging.go:55] [core] [Channel #136 SubChannel #137]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:30.054488       1 logging.go:55] [core] [Channel #25 SubChannel #26]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:30.060523       1 logging.go:55] [core] [Channel #61 SubChannel #62]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:30.095336       1 logging.go:55] [core] [Channel #49 SubChannel #50]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:30.100124       1 logging.go:55] [core] [Channel #73 SubChannel #74]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:30.166407       1 logging.go:55] [core] [Channel #91 SubChannel #92]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:30.264880       1 logging.go:55] [core] [Channel #106 SubChannel #107]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:30.266460       1 logging.go:55] [core] [Channel #178 SubChannel #179]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:30.297749       1 logging.go:55] [core] [Channel #139 SubChannel #140]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:30.314546       1 logging.go:55] [core] [Channel #145 SubChannel #146]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:30.316085       1 logging.go:55] [core] [Channel #2 SubChannel #4]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:30.333840       1 logging.go:55] [core] [Channel #163 SubChannel #164]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:30.338692       1 logging.go:55] [core] [Channel #172 SubChannel #173]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:30.351766       1 logging.go:55] [core] [Channel #100 SubChannel #101]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:30.366344       1 logging.go:55] [core] [Channel #124 SubChannel #125]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:30.384717       1 logging.go:55] [core] [Channel #10 SubChannel #11]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:30.384891       1 logging.go:55] [core] [Channel #46 SubChannel #47]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:30.406708       1 logging.go:55] [core] [Channel #17 SubChannel #18]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:30.466963       1 logging.go:55] [core] [Channel #67 SubChannel #68]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:30.554501       1 logging.go:55] [core] [Channel #127 SubChannel #128]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:30.569979       1 logging.go:55] [core] [Channel #109 SubChannel #110]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:30.590799       1 logging.go:55] [core] [Channel #31 SubChannel #32]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:30.605550       1 logging.go:55] [core] [Channel #58 SubChannel #59]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:30.631502       1 logging.go:55] [core] [Channel #55 SubChannel #56]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:30.645270       1 logging.go:55] [core] [Channel #157 SubChannel #158]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:30.655047       1 logging.go:55] [core] [Channel #154 SubChannel #155]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0923 17:57:30.687986       1 logging.go:55] [core] [Channel #118 SubChannel #119]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"


==> kube-controller-manager [840e026f5d7a] <==
I0923 17:56:47.242234       1 actual_state_of_world.go:540] "Failed to update statusUpdateNeeded field in actual state of world" logger="persistentvolume-attach-detach-controller" err="Failed to set statusUpdateNeeded to needed true, because nodeName=\"minikube\" does not exist"
I0923 17:56:47.248286       1 shared_informer.go:320] Caches are synced for namespace
I0923 17:56:47.256674       1 shared_informer.go:320] Caches are synced for daemon sets
I0923 17:56:47.258092       1 shared_informer.go:320] Caches are synced for ReplicaSet
I0923 17:56:47.259949       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/metrics-server-84c5f94fbc" duration="161.622¬µs"
I0923 17:56:47.260149       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kubernetes-dashboard/kubernetes-dashboard-695b96c756" duration="92.131¬µs"
I0923 17:56:47.260159       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kubernetes-dashboard/dashboard-metrics-scraper-c5db448b4" duration="249.56¬µs"
I0923 17:56:47.264551       1 shared_informer.go:320] Caches are synced for node
I0923 17:56:47.268943       1 range_allocator.go:171] "Sending events to api server" logger="node-ipam-controller"
I0923 17:56:47.269365       1 shared_informer.go:320] Caches are synced for TTL after finished
I0923 17:56:47.269717       1 range_allocator.go:177] "Starting range CIDR allocator" logger="node-ipam-controller"
I0923 17:56:47.269755       1 shared_informer.go:313] Waiting for caches to sync for cidrallocator
I0923 17:56:47.269890       1 shared_informer.go:320] Caches are synced for cidrallocator
I0923 17:56:47.270366       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 17:56:47.274041       1 shared_informer.go:320] Caches are synced for TTL
I0923 17:56:47.275423       1 shared_informer.go:320] Caches are synced for ClusterRoleAggregator
I0923 17:56:47.280808       1 shared_informer.go:320] Caches are synced for HPA
I0923 17:56:47.281055       1 shared_informer.go:320] Caches are synced for taint-eviction-controller
I0923 17:56:47.283064       1 shared_informer.go:320] Caches are synced for cronjob
I0923 17:56:47.283173       1 shared_informer.go:320] Caches are synced for job
I0923 17:56:47.283910       1 shared_informer.go:320] Caches are synced for endpoint_slice
I0923 17:56:47.284003       1 shared_informer.go:320] Caches are synced for bootstrap_signer
I0923 17:56:47.284172       1 shared_informer.go:320] Caches are synced for legacy-service-account-token-cleaner
I0923 17:56:47.284224       1 shared_informer.go:320] Caches are synced for ephemeral
I0923 17:56:47.285630       1 shared_informer.go:320] Caches are synced for PVC protection
I0923 17:56:47.297853       1 shared_informer.go:313] Waiting for caches to sync for garbage collector
I0923 17:56:47.314797       1 shared_informer.go:320] Caches are synced for validatingadmissionpolicy-status
I0923 17:56:47.316118       1 shared_informer.go:320] Caches are synced for GC
I0923 17:56:47.318486       1 shared_informer.go:320] Caches are synced for crt configmap
I0923 17:56:47.327156       1 shared_informer.go:320] Caches are synced for endpoint
I0923 17:56:47.328653       1 shared_informer.go:320] Caches are synced for expand
I0923 17:56:47.328824       1 shared_informer.go:320] Caches are synced for deployment
I0923 17:56:47.329043       1 shared_informer.go:320] Caches are synced for PV protection
I0923 17:56:47.329159       1 shared_informer.go:320] Caches are synced for persistent volume
I0923 17:56:47.330277       1 shared_informer.go:320] Caches are synced for ReplicationController
I0923 17:56:47.330353       1 shared_informer.go:320] Caches are synced for endpoint_slice_mirroring
I0923 17:56:47.332855       1 shared_informer.go:320] Caches are synced for service account
I0923 17:56:47.392292       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/my-nginx-c78685b99" duration="134.063149ms"
I0923 17:56:47.392769       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/my-nginx-c78685b99" duration="181.632¬µs"
I0923 17:56:47.395772       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="136.972855ms"
I0923 17:56:47.395985       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="127.736¬µs"
I0923 17:56:47.401138       1 shared_informer.go:320] Caches are synced for taint
I0923 17:56:47.401345       1 node_lifecycle_controller.go:1232] "Initializing eviction metric for zone" logger="node-lifecycle-controller" zone=""
I0923 17:56:47.401615       1 node_lifecycle_controller.go:884] "Missing timestamp for Node. Assuming now as a timestamp" logger="node-lifecycle-controller" node="minikube"
I0923 17:56:47.401719       1 node_lifecycle_controller.go:1078] "Controller detected that zone is now in new state" logger="node-lifecycle-controller" zone="" newState="Normal"
I0923 17:56:47.412018       1 shared_informer.go:320] Caches are synced for attach detach
I0923 17:56:47.468179       1 shared_informer.go:320] Caches are synced for disruption
I0923 17:56:47.476723       1 shared_informer.go:320] Caches are synced for resource quota
I0923 17:56:47.494438       1 shared_informer.go:320] Caches are synced for resource quota
I0923 17:56:47.530064       1 shared_informer.go:320] Caches are synced for stateful set
I0923 17:56:47.898363       1 shared_informer.go:320] Caches are synced for garbage collector
I0923 17:56:47.986862       1 shared_informer.go:320] Caches are synced for garbage collector
I0923 17:56:47.986924       1 garbagecollector.go:157] "All resource monitors have synced. Proceeding to collect garbage" logger="garbage-collector-controller"
I0923 17:56:49.467970       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/my-nginx-c78685b99" duration="10.792118ms"
I0923 17:56:49.468184       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/my-nginx-c78685b99" duration="119.72¬µs"
I0923 17:57:15.207855       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kubernetes-dashboard/kubernetes-dashboard-695b96c756" duration="17.566483ms"
I0923 17:57:15.208106       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kubernetes-dashboard/kubernetes-dashboard-695b96c756" duration="141.465¬µs"
I0923 17:57:17.082336       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kubernetes-dashboard/kubernetes-dashboard-695b96c756" duration="104.277¬µs"
I0923 17:57:20.280276       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="38.328116ms"
I0923 17:57:20.280597       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="170.008¬µs"


==> kube-controller-manager [8758b53e92b7] <==
I0923 10:39:01.956468       1 shared_informer.go:320] Caches are synced for HPA
I0923 10:39:01.973091       1 shared_informer.go:320] Caches are synced for resource quota
I0923 10:39:02.004942       1 shared_informer.go:320] Caches are synced for certificate-csrsigning-kubelet-serving
I0923 10:39:02.005116       1 shared_informer.go:320] Caches are synced for certificate-csrsigning-kube-apiserver-client
I0923 10:39:02.005223       1 shared_informer.go:320] Caches are synced for certificate-csrsigning-legacy-unknown
I0923 10:39:02.005237       1 shared_informer.go:320] Caches are synced for certificate-csrsigning-kubelet-client
I0923 10:39:02.007416       1 shared_informer.go:320] Caches are synced for certificate-csrapproving
I0923 10:39:02.405956       1 shared_informer.go:320] Caches are synced for garbage collector
I0923 10:39:02.406007       1 garbagecollector.go:157] "All resource monitors have synced. Proceeding to collect garbage" logger="garbage-collector-controller"
I0923 10:39:02.420705       1 shared_informer.go:320] Caches are synced for garbage collector
I0923 10:39:26.736563       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kubernetes-dashboard/kubernetes-dashboard-695b96c756" duration="15.929962ms"
I0923 10:39:26.736773       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kubernetes-dashboard/kubernetes-dashboard-695b96c756" duration="121.525¬µs"
I0923 10:39:27.797332       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kubernetes-dashboard/kubernetes-dashboard-695b96c756" duration="130.044¬µs"
E0923 10:39:31.985910       1 resource_quota_controller.go:446] "Unhandled Error" err="unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: stale GroupVersion discovery: metrics.k8s.io/v1beta1" logger="UnhandledError"
I0923 10:39:32.440690       1 garbagecollector.go:826] "failed to discover some groups" logger="garbage-collector-controller" groups="<internal error: json: unsupported type: map[schema.GroupVersion]error>"
I0923 10:39:33.821631       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="18.621031ms"
I0923 10:39:33.821925       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="188.385¬µs"
I0923 10:39:42.242237       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kubernetes-dashboard/kubernetes-dashboard-695b96c756" duration="25.846625ms"
I0923 10:39:42.242447       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kubernetes-dashboard/kubernetes-dashboard-695b96c756" duration="112.178¬µs"
I0923 10:39:57.969323       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/metrics-server-84c5f94fbc" duration="18.518532ms"
I0923 10:39:57.969606       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/metrics-server-84c5f94fbc" duration="147.799¬µs"
I0923 10:44:00.332971       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 10:49:07.163204       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 10:54:14.126297       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 10:59:20.195224       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 11:04:26.162444       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 11:09:32.264400       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 11:14:39.094763       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 11:19:44.232541       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 11:24:50.887117       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 11:29:57.217263       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 11:35:03.407552       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 11:39:01.505263       1 cleaner.go:175] "Cleaning CSR as it is more than approvedExpiration duration old and approved." logger="certificatesigningrequest-cleaner-controller" csr="csr-hqrw6" approvedExpiration="1h0m0s"
I0923 11:40:08.765593       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 11:45:14.937186       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 11:50:21.154504       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 11:55:26.863698       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 12:00:31.740582       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 12:05:36.501226       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 12:10:43.253653       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 12:15:50.527305       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 12:20:55.683661       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 12:26:01.241168       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 12:31:06.541680       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 12:36:13.249090       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 12:41:18.271231       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 12:46:24.623526       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 12:51:30.265972       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 12:56:35.692415       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 13:01:40.813165       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 13:06:46.369339       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 13:11:51.849463       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 13:16:57.833730       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 13:22:03.657871       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 13:27:10.112189       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 13:32:16.705304       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 13:37:23.172162       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 13:42:30.274697       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 13:47:36.858062       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0923 13:52:43.801240       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="minikube"


==> kube-proxy [2599ffe2f52d] <==
I0923 10:38:55.629386       1 server_linux.go:66] "Using iptables proxy"
I0923 10:38:55.742176       1 server.go:677] "Successfully retrieved node IP(s)" IPs=["192.168.49.2"]
E0923 10:38:55.742235       1 server.go:234] "Kube-proxy configuration may be incomplete or incorrect" err="nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`"
I0923 10:38:55.764996       1 server.go:243] "kube-proxy running in dual-stack mode" primary ipFamily="IPv4"
I0923 10:38:55.765185       1 server_linux.go:169] "Using iptables Proxier"
I0923 10:38:55.769574       1 proxier.go:255] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses" ipFamily="IPv4"
I0923 10:38:55.770097       1 server.go:483] "Version info" version="v1.31.0"
I0923 10:38:55.770244       1 server.go:485] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0923 10:38:55.774587       1 config.go:197] "Starting service config controller"
I0923 10:38:55.774651       1 config.go:104] "Starting endpoint slice config controller"
I0923 10:38:55.774785       1 config.go:326] "Starting node config controller"
I0923 10:38:55.775035       1 shared_informer.go:313] Waiting for caches to sync for service config
I0923 10:38:55.775058       1 shared_informer.go:313] Waiting for caches to sync for endpoint slice config
I0923 10:38:55.775080       1 shared_informer.go:313] Waiting for caches to sync for node config
I0923 10:38:55.875621       1 shared_informer.go:320] Caches are synced for node config
I0923 10:38:55.878097       1 shared_informer.go:320] Caches are synced for endpoint slice config
I0923 10:38:55.878324       1 shared_informer.go:320] Caches are synced for service config


==> kube-proxy [e0553e3866cd] <==
I0923 17:56:42.980917       1 server_linux.go:66] "Using iptables proxy"
I0923 17:56:43.538551       1 server.go:677] "Successfully retrieved node IP(s)" IPs=["192.168.49.2"]
E0923 17:56:43.538941       1 server.go:234] "Kube-proxy configuration may be incomplete or incorrect" err="nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`"
I0923 17:56:43.729036       1 server.go:243] "kube-proxy running in dual-stack mode" primary ipFamily="IPv4"
I0923 17:56:43.730470       1 server_linux.go:169] "Using iptables Proxier"
I0923 17:56:43.758199       1 proxier.go:255] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses" ipFamily="IPv4"
I0923 17:56:43.768985       1 server.go:483] "Version info" version="v1.31.0"
I0923 17:56:43.769093       1 server.go:485] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0923 17:56:43.815863       1 config.go:197] "Starting service config controller"
I0923 17:56:43.817545       1 config.go:326] "Starting node config controller"
I0923 17:56:43.821083       1 shared_informer.go:313] Waiting for caches to sync for node config
I0923 17:56:43.817041       1 config.go:104] "Starting endpoint slice config controller"
I0923 17:56:43.825197       1 shared_informer.go:313] Waiting for caches to sync for endpoint slice config
I0923 17:56:43.834354       1 shared_informer.go:313] Waiting for caches to sync for service config
I0923 17:56:43.922361       1 shared_informer.go:320] Caches are synced for node config
I0923 17:56:43.925798       1 shared_informer.go:320] Caches are synced for endpoint slice config
I0923 17:56:43.935850       1 shared_informer.go:320] Caches are synced for service config


==> kube-scheduler [75893e4b20b3] <==
I0923 17:56:37.276950       1 serving.go:386] Generated self-signed cert in-memory
W0923 17:56:39.910612       1 requestheader_controller.go:196] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0923 17:56:39.910748       1 authentication.go:370] Error looking up in-cluster authentication configuration: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot get resource "configmaps" in API group "" in the namespace "kube-system"
W0923 17:56:39.910797       1 authentication.go:371] Continuing without authentication configuration. This may treat all requests as anonymous.
W0923 17:56:39.910825       1 authentication.go:372] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0923 17:56:40.017262       1 server.go:167] "Starting Kubernetes Scheduler" version="v1.31.0"
I0923 17:56:40.017338       1 server.go:169] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0923 17:56:40.032017       1 configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I0923 17:56:40.035887       1 shared_informer.go:313] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0923 17:56:40.038227       1 secure_serving.go:213] Serving securely on 127.0.0.1:10259
I0923 17:56:40.038643       1 tlsconfig.go:243] "Starting DynamicServingCertificateController"
I0923 17:56:40.138739       1 shared_informer.go:320] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0923 17:57:20.605087       1 tlsconfig.go:258] "Shutting down DynamicServingCertificateController"
I0923 17:57:20.605452       1 configmap_cafile_content.go:226] "Shutting down controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I0923 17:57:20.604146       1 secure_serving.go:258] Stopped listening on 127.0.0.1:10259
E0923 17:57:20.606008       1 run.go:72] "command failed" err="finished without leader elect"


==> kube-scheduler [fd5218609e79] <==
I0923 10:38:51.883506       1 serving.go:386] Generated self-signed cert in-memory
W0923 10:38:54.297390       1 requestheader_controller.go:196] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0923 10:38:54.297850       1 authentication.go:370] Error looking up in-cluster authentication configuration: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot get resource "configmaps" in API group "" in the namespace "kube-system"
W0923 10:38:54.297931       1 authentication.go:371] Continuing without authentication configuration. This may treat all requests as anonymous.
W0923 10:38:54.297960       1 authentication.go:372] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0923 10:38:54.323518       1 server.go:167] "Starting Kubernetes Scheduler" version="v1.31.0"
I0923 10:38:54.323540       1 server.go:169] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0923 10:38:54.326773       1 configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I0923 10:38:54.327000       1 secure_serving.go:213] Serving securely on 127.0.0.1:10259
I0923 10:38:54.327149       1 shared_informer.go:313] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0923 10:38:54.328021       1 tlsconfig.go:243] "Starting DynamicServingCertificateController"
I0923 10:38:54.428258       1 shared_informer.go:320] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file


==> kubelet <==
Sep 24 03:32:43 minikube kubelet[18835]: I0924 03:32:43.787677   18835 server.go:486] "Kubelet version" kubeletVersion="v1.31.0"
Sep 24 03:32:43 minikube kubelet[18835]: I0924 03:32:43.787840   18835 server.go:488] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
Sep 24 03:32:43 minikube kubelet[18835]: I0924 03:32:43.788740   18835 server.go:929] "Client rotation is on, will bootstrap in background"
Sep 24 03:32:43 minikube kubelet[18835]: E0924 03:32:43.788894   18835 run.go:72] "command failed" err="failed to run Kubelet: unable to load bootstrap kubeconfig: stat /etc/kubernetes/bootstrap-kubelet.conf: no such file or directory"
Sep 24 03:32:43 minikube systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE
Sep 24 03:32:43 minikube systemd[1]: kubelet.service: Failed with result 'exit-code'.
Sep 24 03:32:44 minikube systemd[1]: kubelet.service: Scheduled restart job, restart counter is at 401.
Sep 24 03:32:44 minikube systemd[1]: Stopped kubelet: The Kubernetes Node Agent.
Sep 24 03:32:44 minikube systemd[1]: Started kubelet: The Kubernetes Node Agent.
Sep 24 03:32:44 minikube kubelet[18853]: I0924 03:32:44.783433   18853 server.go:486] "Kubelet version" kubeletVersion="v1.31.0"
Sep 24 03:32:44 minikube kubelet[18853]: I0924 03:32:44.783570   18853 server.go:488] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
Sep 24 03:32:44 minikube kubelet[18853]: I0924 03:32:44.784337   18853 server.go:929] "Client rotation is on, will bootstrap in background"
Sep 24 03:32:44 minikube kubelet[18853]: E0924 03:32:44.784459   18853 run.go:72] "command failed" err="failed to run Kubelet: unable to load bootstrap kubeconfig: stat /etc/kubernetes/bootstrap-kubelet.conf: no such file or directory"
Sep 24 03:32:44 minikube systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE
Sep 24 03:32:44 minikube systemd[1]: kubelet.service: Failed with result 'exit-code'.
Sep 24 03:32:45 minikube systemd[1]: kubelet.service: Scheduled restart job, restart counter is at 402.
Sep 24 03:32:45 minikube systemd[1]: Stopped kubelet: The Kubernetes Node Agent.
Sep 24 03:32:45 minikube systemd[1]: Started kubelet: The Kubernetes Node Agent.
Sep 24 03:32:45 minikube kubelet[18865]: I0924 03:32:45.792928   18865 server.go:486] "Kubelet version" kubeletVersion="v1.31.0"
Sep 24 03:32:45 minikube kubelet[18865]: I0924 03:32:45.793102   18865 server.go:488] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
Sep 24 03:32:45 minikube kubelet[18865]: I0924 03:32:45.793916   18865 server.go:929] "Client rotation is on, will bootstrap in background"
Sep 24 03:32:45 minikube kubelet[18865]: E0924 03:32:45.794051   18865 run.go:72] "command failed" err="failed to run Kubelet: unable to load bootstrap kubeconfig: stat /etc/kubernetes/bootstrap-kubelet.conf: no such file or directory"
Sep 24 03:32:45 minikube systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE
Sep 24 03:32:45 minikube systemd[1]: kubelet.service: Failed with result 'exit-code'.
Sep 24 03:32:46 minikube systemd[1]: kubelet.service: Scheduled restart job, restart counter is at 403.
Sep 24 03:32:46 minikube systemd[1]: Stopped kubelet: The Kubernetes Node Agent.
Sep 24 03:32:46 minikube systemd[1]: Started kubelet: The Kubernetes Node Agent.
Sep 24 03:32:46 minikube kubelet[18879]: I0924 03:32:46.784981   18879 server.go:486] "Kubelet version" kubeletVersion="v1.31.0"
Sep 24 03:32:46 minikube kubelet[18879]: I0924 03:32:46.785148   18879 server.go:488] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
Sep 24 03:32:46 minikube kubelet[18879]: I0924 03:32:46.785862   18879 server.go:929] "Client rotation is on, will bootstrap in background"
Sep 24 03:32:46 minikube kubelet[18879]: E0924 03:32:46.786003   18879 run.go:72] "command failed" err="failed to run Kubelet: unable to load bootstrap kubeconfig: stat /etc/kubernetes/bootstrap-kubelet.conf: no such file or directory"
Sep 24 03:32:46 minikube systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE
Sep 24 03:32:46 minikube systemd[1]: kubelet.service: Failed with result 'exit-code'.
Sep 24 03:32:47 minikube systemd[1]: kubelet.service: Scheduled restart job, restart counter is at 404.
Sep 24 03:32:47 minikube systemd[1]: Stopped kubelet: The Kubernetes Node Agent.
Sep 24 03:32:47 minikube systemd[1]: Started kubelet: The Kubernetes Node Agent.
Sep 24 03:32:47 minikube kubelet[18893]: I0924 03:32:47.842465   18893 server.go:486] "Kubelet version" kubeletVersion="v1.31.0"
Sep 24 03:32:47 minikube kubelet[18893]: I0924 03:32:47.842697   18893 server.go:488] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
Sep 24 03:32:47 minikube kubelet[18893]: I0924 03:32:47.845931   18893 server.go:929] "Client rotation is on, will bootstrap in background"
Sep 24 03:32:47 minikube kubelet[18893]: E0924 03:32:47.846216   18893 run.go:72] "command failed" err="failed to run Kubelet: unable to load bootstrap kubeconfig: stat /etc/kubernetes/bootstrap-kubelet.conf: no such file or directory"
Sep 24 03:32:47 minikube systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE
Sep 24 03:32:47 minikube systemd[1]: kubelet.service: Failed with result 'exit-code'.
Sep 24 03:32:48 minikube systemd[1]: kubelet.service: Scheduled restart job, restart counter is at 405.
Sep 24 03:32:48 minikube systemd[1]: Stopped kubelet: The Kubernetes Node Agent.
Sep 24 03:32:48 minikube systemd[1]: Started kubelet: The Kubernetes Node Agent.
Sep 24 03:32:48 minikube kubelet[18907]: I0924 03:32:48.793103   18907 server.go:486] "Kubelet version" kubeletVersion="v1.31.0"
Sep 24 03:32:48 minikube kubelet[18907]: I0924 03:32:48.793281   18907 server.go:488] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
Sep 24 03:32:48 minikube kubelet[18907]: I0924 03:32:48.794295   18907 server.go:929] "Client rotation is on, will bootstrap in background"
Sep 24 03:32:48 minikube kubelet[18907]: E0924 03:32:48.794459   18907 run.go:72] "command failed" err="failed to run Kubelet: unable to load bootstrap kubeconfig: stat /etc/kubernetes/bootstrap-kubelet.conf: no such file or directory"
Sep 24 03:32:48 minikube systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE
Sep 24 03:32:48 minikube systemd[1]: kubelet.service: Failed with result 'exit-code'.
Sep 24 03:32:49 minikube systemd[1]: kubelet.service: Scheduled restart job, restart counter is at 406.
Sep 24 03:32:49 minikube systemd[1]: Stopped kubelet: The Kubernetes Node Agent.
Sep 24 03:32:49 minikube systemd[1]: Started kubelet: The Kubernetes Node Agent.
Sep 24 03:32:49 minikube kubelet[19071]: I0924 03:32:49.795426   19071 server.go:486] "Kubelet version" kubeletVersion="v1.31.0"
Sep 24 03:32:49 minikube kubelet[19071]: I0924 03:32:49.795596   19071 server.go:488] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
Sep 24 03:32:49 minikube kubelet[19071]: I0924 03:32:49.796759   19071 server.go:929] "Client rotation is on, will bootstrap in background"
Sep 24 03:32:49 minikube kubelet[19071]: E0924 03:32:49.796968   19071 run.go:72] "command failed" err="failed to run Kubelet: unable to load bootstrap kubeconfig: stat /etc/kubernetes/bootstrap-kubelet.conf: no such file or directory"
Sep 24 03:32:49 minikube systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE
Sep 24 03:32:49 minikube systemd[1]: kubelet.service: Failed with result 'exit-code'.


==> kubernetes-dashboard [8d2e87db61d9] <==
2024/09/23 17:56:44 Starting overwatch
panic: Get "https://10.96.0.1:443/api/v1/namespaces/kubernetes-dashboard/secrets/kubernetes-dashboard-csrf": dial tcp 10.96.0.1:443: i/o timeout

goroutine 1 [running]:
github.com/kubernetes/dashboard/src/app/backend/client/csrf.(*csrfTokenManager).init(0xc0004dfae8)
	/home/runner/work/dashboard/dashboard/src/app/backend/client/csrf/manager.go:41 +0x30e
github.com/kubernetes/dashboard/src/app/backend/client/csrf.NewCsrfTokenManager(...)
	/home/runner/work/dashboard/dashboard/src/app/backend/client/csrf/manager.go:66
github.com/kubernetes/dashboard/src/app/backend/client.(*clientManager).initCSRFKey(0xc00041f880)
	/home/runner/work/dashboard/dashboard/src/app/backend/client/manager.go:527 +0x94
github.com/kubernetes/dashboard/src/app/backend/client.(*clientManager).init(0x19aba3a?)
	/home/runner/work/dashboard/dashboard/src/app/backend/client/manager.go:495 +0x32
github.com/kubernetes/dashboard/src/app/backend/client.NewClientManager(...)
	/home/runner/work/dashboard/dashboard/src/app/backend/client/manager.go:594
main.main()
	/home/runner/work/dashboard/dashboard/src/app/backend/dashboard.go:96 +0x1cf
2024/09/23 17:56:44 Using namespace: kubernetes-dashboard
2024/09/23 17:56:44 Using in-cluster config to connect to apiserver
2024/09/23 17:56:44 Using secret token for csrf signing
2024/09/23 17:56:44 Initializing csrf token from kubernetes-dashboard-csrf secret


==> storage-provisioner [2fd2b8ae66c1] <==
I0923 17:56:42.627801       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
F0923 17:57:12.653128       1 main.go:39] error getting server version: Get "https://10.96.0.1:443/version?timeout=32s": dial tcp 10.96.0.1:443: i/o timeout

